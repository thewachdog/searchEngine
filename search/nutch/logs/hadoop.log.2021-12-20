2021-12-20 03:59:17,176 INFO  crawl.Injector - Injector: starting at 2021-12-20 03:59:17
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 03:59:17,689 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 03:59:18,628 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 03:59:18,803 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 03:59:20,315 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 03:59:20,316 INFO  mapreduce.Job - Running job: job_local2080166325_0001
2021-12-20 03:59:21,336 INFO  mapreduce.Job - Job job_local2080166325_0001 running in uber mode : false
2021-12-20 03:59:21,338 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 03:59:21,667 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:21,894 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 03:59:21,895 INFO  crawl.Injector - Injector: update: false
2021-12-20 03:59:21,930 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:22,017 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 03:59:22,017 INFO  crawl.Injector - Injector: update: false
2021-12-20 03:59:22,341 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 03:59:22,343 INFO  mapreduce.Job - Job job_local2080166325_0001 completed successfully
2021-12-20 03:59:22,382 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2838013
		FILE: Number of bytes written=4660134
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=28
		Input split bytes=286
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=28
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=619708416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 03:59:22,467 INFO  crawl.Injector - Injector: finished at 2021-12-20 03:59:22, elapsed: 00:00:05
2021-12-20 03:59:24,402 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: starting at 2021-12-20 03:59:25
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 03:59:25,032 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 03:59:25,035 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 03:59:25,186 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 03:59:26,864 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 03:59:26,865 INFO  mapreduce.Job - Running job: job_local1635138310_0001
2021-12-20 03:59:27,723 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 03:59:27,726 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 03:59:27,726 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 03:59:27,874 INFO  mapreduce.Job - Job job_local1635138310_0001 running in uber mode : false
2021-12-20 03:59:27,878 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 03:59:27,953 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 03:59:27,954 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 03:59:27,954 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 03:59:28,033 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:28,243 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:28,922 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 03:59:28,923 INFO  mapreduce.Job - Job job_local1635138310_0001 completed successfully
2021-12-20 03:59:28,954 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 03:59:28,955 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 03:59:28,983 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:13:27,208 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:13:27
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:13:27,496 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:13:28,030 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:13:28,156 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:13:29,530 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:13:29,531 INFO  mapreduce.Job - Running job: job_local362465298_0001
2021-12-20 04:13:30,543 INFO  mapreduce.Job - Job job_local362465298_0001 running in uber mode : false
2021-12-20 04:13:30,548 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:13:30,743 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:30,934 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:13:30,935 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:13:30,962 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:31,057 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:13:31,058 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:13:31,551 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:13:31,553 INFO  mapreduce.Job - Job job_local362465298_0001 completed successfully
2021-12-20 04:13:31,595 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=1030750208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:13:31,660 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:13:31,680 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:13:31, elapsed: 00:00:04
2021-12-20 04:13:33,479 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:13:34,052 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:13:34
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:13:34,055 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:13:34,211 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:13:35,494 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:13:35,495 INFO  mapreduce.Job - Running job: job_local860905576_0001
2021-12-20 04:13:36,387 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:13:36,390 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:13:36,390 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:13:36,526 INFO  mapreduce.Job - Job job_local860905576_0001 running in uber mode : false
2021-12-20 04:13:36,563 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:13:36,593 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:13:36,594 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:13:36,594 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:13:36,680 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:36,882 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:37,570 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:13:37,571 INFO  mapreduce.Job - Job job_local860905576_0001 completed successfully
2021-12-20 04:13:37,595 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6217506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:13:37,595 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:13:37,625 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:19:30,810 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:19:30
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:19:31,080 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:19:31,772 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:19:31,899 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:19:33,193 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:19:33,194 INFO  mapreduce.Job - Running job: job_local1172278039_0001
2021-12-20 04:19:34,202 INFO  mapreduce.Job - Job job_local1172278039_0001 running in uber mode : false
2021-12-20 04:19:34,204 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:19:34,566 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:34,769 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:19:34,770 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:19:34,793 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:34,881 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:19:34,881 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:19:35,207 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:19:35,209 INFO  mapreduce.Job - Job job_local1172278039_0001 completed successfully
2021-12-20 04:19:35,242 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=1038090240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:19:35,305 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:19:35,324 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:19:35, elapsed: 00:00:04
2021-12-20 04:19:37,089 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:19:37
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:19:37,618 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:19:37,773 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:19:39,037 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:19:39,038 INFO  mapreduce.Job - Running job: job_local1924126038_0001
2021-12-20 04:19:39,970 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:19:39,973 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:19:39,973 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:19:40,047 INFO  mapreduce.Job - Job job_local1924126038_0001 running in uber mode : false
2021-12-20 04:19:40,049 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:19:40,159 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:19:40,159 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:19:40,160 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:19:40,243 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:40,442 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:41,052 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:19:41,054 INFO  mapreduce.Job - Job job_local1924126038_0001 completed successfully
2021-12-20 04:19:41,079 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=830472192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:19:41,080 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:19:41,102 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:20:26,825 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:20:26
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:20:27,132 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:27,756 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:20:27,886 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:29,260 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:29,261 INFO  mapreduce.Job - Running job: job_local856695529_0001
2021-12-20 04:20:30,282 INFO  mapreduce.Job - Job job_local856695529_0001 running in uber mode : false
2021-12-20 04:20:30,286 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:30,616 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:30,858 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:20:30,860 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:20:30,886 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:30,988 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:20:30,988 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:20:31,291 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:20:31,292 INFO  mapreduce.Job - Job job_local856695529_0001 completed successfully
2021-12-20 04:20:31,317 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1043333120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:20:31,384 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:20:31,405 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:20:31, elapsed: 00:00:04
2021-12-20 04:20:33,254 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:33,751 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:20:33
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:20:33,756 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:20:33,904 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:35,282 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:35,283 INFO  mapreduce.Job - Running job: job_local2063707495_0001
2021-12-20 04:20:36,135 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:20:36,137 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:20:36,137 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:20:36,295 INFO  mapreduce.Job - Job job_local2063707495_0001 running in uber mode : false
2021-12-20 04:20:36,300 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:36,337 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:20:36,337 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:20:36,337 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:20:36,417 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:36,578 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:37,317 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:20:37,317 INFO  mapreduce.Job - Job job_local2063707495_0001 completed successfully
2021-12-20 04:20:37,352 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=833617920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:20:37,353 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:20:37,372 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:20:56,102 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:20:56
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:20:56,385 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:56,952 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:20:57,070 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:58,478 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:58,479 INFO  mapreduce.Job - Running job: job_local1482060468_0001
2021-12-20 04:20:59,508 INFO  mapreduce.Job - Job job_local1482060468_0001 running in uber mode : false
2021-12-20 04:20:59,555 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:59,768 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:00,005 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:00,006 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:00,078 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:00,181 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:00,181 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:00,558 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:00,560 INFO  mapreduce.Job - Job job_local1482060468_0001 completed successfully
2021-12-20 04:21:00,585 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=1043333120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:21:00,637 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:21:00,656 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:21:00, elapsed: 00:00:04
2021-12-20 04:21:02,502 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:03,090 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:21:03
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:21:03,094 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:21:03,240 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:04,587 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:04,588 INFO  mapreduce.Job - Running job: job_local199458287_0001
2021-12-20 04:21:05,572 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:05,574 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:05,574 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:05,608 INFO  mapreduce.Job - Job job_local199458287_0001 running in uber mode : false
2021-12-20 04:21:05,609 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:05,753 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:05,753 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:05,753 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:05,845 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:06,095 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:06,615 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:06,616 INFO  mapreduce.Job - Job job_local199458287_0001 completed successfully
2021-12-20 04:21:06,639 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6217506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=829423616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:21:06,639 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:21:06,662 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:21:33,989 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:21:33
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:21:34,253 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:34,906 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:21:35,054 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:36,880 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:36,881 INFO  mapreduce.Job - Running job: job_local199372878_0001
2021-12-20 04:21:37,913 INFO  mapreduce.Job - Job job_local199372878_0001 running in uber mode : false
2021-12-20 04:21:37,915 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:38,571 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:38,801 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:38,802 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:38,837 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:38,918 INFO  mapreduce.Job -  map 100% reduce 50%
2021-12-20 04:21:38,933 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:38,934 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:39,920 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:39,920 INFO  mapreduce.Job - Job job_local199372878_0001 completed successfully
2021-12-20 04:21:39,948 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=1039138816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:21:40,036 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:21:40, elapsed: 00:00:06
2021-12-20 04:21:42,025 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:21:42
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:21:42,646 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:21:42,813 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:44,263 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:44,264 INFO  mapreduce.Job - Running job: job_local50371423_0001
2021-12-20 04:21:45,273 INFO  mapreduce.Job - Job job_local50371423_0001 running in uber mode : false
2021-12-20 04:21:45,275 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:45,307 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:45,311 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:45,311 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:45,506 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:45,507 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:45,507 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:45,567 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:45,786 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:46,280 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:46,282 INFO  mapreduce.Job - Job job_local50371423_0001 completed successfully
2021-12-20 04:21:46,324 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6205682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=832569344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:21:46,324 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:21:46,344 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:22:56,534 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:22:56
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:22:56,808 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:22:57,385 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:22:57,520 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:22:58,902 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:22:58,903 INFO  mapreduce.Job - Running job: job_local1368641918_0001
2021-12-20 04:22:59,912 INFO  mapreduce.Job - Job job_local1368641918_0001 running in uber mode : false
2021-12-20 04:22:59,914 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:23:00,238 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:00,420 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:23:00,422 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:23:00,446 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:00,563 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:23:00,563 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:23:00,918 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:23:00,919 INFO  mapreduce.Job - Job job_local1368641918_0001 completed successfully
2021-12-20 04:23:00,958 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=1274019840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:23:01,064 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:23:01,092 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:23:01, elapsed: 00:00:04
2021-12-20 04:23:02,978 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:23:03,527 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:23:03
2021-12-20 04:23:03,528 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:23:03,529 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:23:03,529 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:23:03,531 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:23:03,688 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:23:05,077 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:23:05,078 INFO  mapreduce.Job - Running job: job_local1193165626_0001
2021-12-20 04:23:06,053 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:23:06,055 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:23:06,055 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:23:06,088 INFO  mapreduce.Job - Job job_local1193165626_0001 running in uber mode : false
2021-12-20 04:23:06,090 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:23:06,203 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:23:06,203 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:23:06,203 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:23:06,293 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:06,466 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:07,093 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:23:07,094 INFO  mapreduce.Job - Job job_local1193165626_0001 completed successfully
2021-12-20 04:23:07,139 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=832569344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:23:07,140 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:23:07,158 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 05:47:55,210 INFO  crawl.Injector - Injector: starting at 2021-12-20 05:47:55
2021-12-20 05:47:55,215 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-20 05:47:55,215 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-20 05:47:55,216 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 05:47:55,586 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:47:56,454 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 05:47:56,644 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:47:58,208 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:47:58,209 INFO  mapreduce.Job - Running job: job_local1714956858_0001
2021-12-20 05:47:59,242 INFO  mapreduce.Job - Job job_local1714956858_0001 running in uber mode : false
2021-12-20 05:47:59,252 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:47:59,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-20 05:47:59,681 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:47:59,950 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 05:47:59,951 INFO  crawl.Injector - Injector: update: false
2021-12-20 05:48:00,256 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:00,257 INFO  mapreduce.Job - Job job_local1714956858_0001 completed successfully
2021-12-20 05:48:00,298 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1892034
		FILE: Number of bytes written=3105958
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=55
		Map output materialized bytes=63
		Input split bytes=286
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=63
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=391
2021-12-20 05:48:00,332 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total new urls injected: 1
2021-12-20 05:48:00,361 INFO  crawl.Injector - Injector: finished at 2021-12-20 05:48:00, elapsed: 00:00:05
2021-12-20 05:48:42,039 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:48:42,722 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:48:42
2021-12-20 05:48:42,722 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:48:42,723 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:48:42,723 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:48:42,737 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:48:42,933 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:48:44,396 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:48:44,397 INFO  mapreduce.Job - Running job: job_local947595629_0001
2021-12-20 05:48:45,287 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:48:45,289 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:48:45,289 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:48:45,417 INFO  mapreduce.Job - Job job_local947595629_0001 running in uber mode : false
2021-12-20 05:48:45,421 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:48:45,432 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:45,642 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:48:46,425 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:46,426 INFO  mapreduce.Job - Job job_local947595629_0001 completed successfully
2021-12-20 05:48:46,446 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1892094
		FILE: Number of bytes written=3108012
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=84
		Map output materialized bytes=92
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=92
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=161
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:48:46,447 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:48:46,467 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:48:47,468 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220054847
2021-12-20 05:48:47,484 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:47,900 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:48:47,900 INFO  mapreduce.Job - Running job: job_local1183284572_0002
2021-12-20 05:48:48,096 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:48,901 INFO  mapreduce.Job - Job job_local1183284572_0002 running in uber mode : false
2021-12-20 05:48:48,902 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:48,902 INFO  mapreduce.Job - Job job_local1183284572_0002 completed successfully
2021-12-20 05:48:48,910 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3784622
		FILE: Number of bytes written=6217628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=106
		Map output materialized bytes=114
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=114
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=212
	File Output Format Counters 
		Bytes Written=182
2021-12-20 05:48:48,929 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:48:48, elapsed: 00:00:06
2021-12-20 05:52:31,866 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-20 05:52:31
2021-12-20 05:52:31,867 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211220054847
2021-12-20 05:52:32,287 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:52:32,836 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:52:34,276 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:52:34,277 INFO  mapreduce.Job - Running job: job_local237842719_0001
2021-12-20 05:52:34,689 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-20 05:52:34,690 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-20 05:52:34,789 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-20 05:52:34,835 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - 	1	SUCCESSFULLY_QUEUED
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-20 05:52:34,837 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-20 05:52:34,837 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-20 05:52:35,296 INFO  mapreduce.Job - Job job_local237842719_0001 running in uber mode : false
2021-12-20 05:52:35,298 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:52:35,366 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,505 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,508 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,518 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,519 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:52:35,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,520 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-20 05:52:35,522 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,521 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-20 05:52:35,522 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.host = null
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.port = 8080
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.exception.list = false
2021-12-20 05:52:35,881 INFO  http.Http - http.timeout = 10000
2021-12-20 05:52:35,881 INFO  http.Http - http.content.limit = 1048576
2021-12-20 05:52:35,881 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-20 05:52:35,881 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-20 05:52:35,881 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-20 05:52:35,881 INFO  http.Http - http.enable.cookie.header = true
2021-12-20 05:52:35,882 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,888 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,889 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,898 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,898 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-20 05:52:35,898 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,899 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,904 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,905 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,912 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,917 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,924 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,925 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,927 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,928 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,929 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-20 05:52:35,930 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,930 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-20 05:52:35,931 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,932 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-20 05:52:35,932 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-20 05:52:35,933 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-20 05:52:35,936 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,936 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-20 05:52:35,937 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:36,947 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2021-12-20 05:52:37,963 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2021-12-20 05:52:38,137 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-20 05:52:38,137 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=0
2021-12-20 05:52:38,964 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-20 05:52:38,964 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-20 05:52:39,115 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:52:39,306 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:52:40,307 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:52:40,309 INFO  mapreduce.Job - Job job_local237842719_0001 completed successfully
2021-12-20 05:52:40,327 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1928338
		FILE: Number of bytes written=3160153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=18172
		Map output materialized bytes=18185
		Input split bytes=168
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=18185
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=32
		Total committed heap usage (bytes)=429916160
	FetcherStatus
		bytes_downloaded=17249
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=182
	File Output Format Counters 
		Bytes Written=8594
2021-12-20 05:52:40,334 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-20 05:52:40, elapsed: 00:00:08
2021-12-20 05:53:13,215 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:53:13,748 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:53:13
2021-12-20 05:53:13,749 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220054847
2021-12-20 05:53:13,918 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:53:15,388 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:53:15,389 INFO  mapreduce.Job - Running job: job_local878885184_0001
2021-12-20 05:53:16,413 INFO  mapreduce.Job - Job job_local878885184_0001 running in uber mode : false
2021-12-20 05:53:16,416 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:53:16,789 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-20 05:53:16,798 INFO  parse.ParseSegment - Parsed (489ms): https://nutch.apache.org/
2021-12-20 05:53:16,934 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:53:17,088 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:53:17,234 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-20 05:53:17,420 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:53:17,422 INFO  mapreduce.Job - Job job_local878885184_0001 completed successfully
2021-12-20 05:53:17,452 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1915726
		FILE: Number of bytes written=3116444
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=4232
		Map output materialized bytes=4242
		Input split bytes=166
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=4242
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=406847488
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7810
	File Output Format Counters 
		Bytes Written=0
2021-12-20 05:53:17,477 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-20 05:53:17, elapsed: 00:00:03
2021-12-20 05:53:38,470 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:53:39,108 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:53:39
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220054847]
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:53:39,113 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:53:39,242 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:53:40,873 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:53:40,874 INFO  mapreduce.Job - Running job: job_local1221950224_0001
2021-12-20 05:53:41,688 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:53:41,891 INFO  mapreduce.Job - Job job_local1221950224_0001 running in uber mode : false
2021-12-20 05:53:41,892 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:53:42,369 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:53:42,370 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:53:42,370 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:53:42,894 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:53:42,895 INFO  mapreduce.Job - Job job_local1221950224_0001 completed successfully
2021-12-20 05:53:42,924 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3801588
		FILE: Number of bytes written=6223633
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=2104
		Map output materialized bytes=2175
		Input split bytes=485
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=2175
		Reduce input records=26
		Reduce output records=23
		Spilled Records=52
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=823132160
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:53:42,941 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:53:42, elapsed: 00:00:03
2021-12-20 05:55:15,322 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:55:15
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:55:15,944 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:55:15,946 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:55:15,961 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:55:16,111 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:17,595 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:17,596 INFO  mapreduce.Job - Running job: job_local160341921_0001
2021-12-20 05:55:18,589 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:55:18,591 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:55:18,591 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:55:18,623 INFO  mapreduce.Job - Job job_local160341921_0001 running in uber mode : false
2021-12-20 05:55:18,625 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:55:18,780 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:18,960 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:55:19,627 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:19,629 INFO  mapreduce.Job - Job job_local160341921_0001 completed successfully
2021-12-20 05:55:19,655 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3117376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:55:19,656 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:55:19,664 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:55:19,674 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:55:20,675 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055520
2021-12-20 05:55:20,691 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:21,089 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:21,089 INFO  mapreduce.Job - Running job: job_local1722723080_0002
2021-12-20 05:55:21,280 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:22,090 INFO  mapreduce.Job - Job job_local1722723080_0002 running in uber mode : false
2021-12-20 05:55:22,091 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:22,092 INFO  mapreduce.Job - Job job_local1722723080_0002 completed successfully
2021-12-20 05:55:22,114 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6243942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:55:22,139 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:55:22, elapsed: 00:00:06
2021-12-20 05:55:24,185 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:24,743 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:55:24
2021-12-20 05:55:24,743 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055520
2021-12-20 05:55:24,907 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:25,459 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:255)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:303)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:274)

2021-12-20 05:55:27,458 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:28,033 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:55:28
2021-12-20 05:55:28,033 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055520]
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:55:28,036 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:55:28,036 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:55:28,037 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055520
2021-12-20 05:55:28,037 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:55:28,176 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:29,553 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:29,554 INFO  mapreduce.Job - Running job: job_local901930964_0001
2021-12-20 05:55:30,106 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:30,575 INFO  mapreduce.Job - Job job_local901930964_0001 running in uber mode : false
2021-12-20 05:55:30,577 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:55:30,879 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:55:30,880 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:55:30,880 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:55:31,579 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:31,581 INFO  mapreduce.Job - Job job_local901930964_0001 completed successfully
2021-12-20 05:55:31,598 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3106342
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=460324864
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:55:31,629 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:55:31, elapsed: 00:00:03
2021-12-20 05:56:10,568 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:11,196 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:56:11
2021-12-20 05:56:11,196 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:56:11,197 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:56:11,198 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:56:11,201 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:56:11,227 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:56:11,373 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:12,676 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:12,677 INFO  mapreduce.Job - Running job: job_local1396614071_0001
2021-12-20 05:56:13,608 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:56:13,610 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:56:13,610 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:56:13,695 INFO  mapreduce.Job - Job job_local1396614071_0001 running in uber mode : false
2021-12-20 05:56:13,697 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:56:13,783 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:13,990 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:56:14,700 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:14,703 INFO  mapreduce.Job - Job job_local1396614071_0001 completed successfully
2021-12-20 05:56:14,730 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3123292
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:56:14,731 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:56:14,745 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:56:14,748 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:56:15,749 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055615
2021-12-20 05:56:15,765 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:16,179 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:16,179 INFO  mapreduce.Job - Running job: job_local1997488184_0002
2021-12-20 05:56:16,361 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:17,180 INFO  mapreduce.Job - Job job_local1997488184_0002 running in uber mode : false
2021-12-20 05:56:17,180 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:17,181 INFO  mapreduce.Job - Job job_local1997488184_0002 completed successfully
2021-12-20 05:56:17,194 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6249866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:56:17,216 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:56:17, elapsed: 00:00:06
2021-12-20 05:56:19,164 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:19,670 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:56:19
2021-12-20 05:56:19,671 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055615
2021-12-20 05:56:19,832 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:20,357 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:255)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:303)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:274)

2021-12-20 05:56:22,385 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:23,100 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:56:23
2021-12-20 05:56:23,101 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:56:23,101 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055615]
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:56:23,104 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055615
2021-12-20 05:56:23,105 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:56:23,245 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:24,637 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:24,639 INFO  mapreduce.Job - Running job: job_local1452689239_0001
2021-12-20 05:56:25,149 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:25,667 INFO  mapreduce.Job - Job job_local1452689239_0001 running in uber mode : false
2021-12-20 05:56:25,669 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:56:25,976 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:56:25,977 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:56:25,977 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:56:26,671 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:26,673 INFO  mapreduce.Job - Job job_local1452689239_0001 completed successfully
2021-12-20 05:56:26,702 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3112206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=408944640
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:56:26,726 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:56:26, elapsed: 00:00:03
2021-12-20 05:57:08,059 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:57:08,843 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-20 05:57:08
2021-12-20 05:57:08,843 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220054847
2021-12-20 05:57:08,847 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520
2021-12-20 05:57:08,848 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615
2021-12-20 05:57:08,996 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:57:09,707 ERROR crawl.LinkDb - LinkDb job failed: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
2021-12-20 05:57:09,710 ERROR crawl.LinkDb - LinkDb: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.crawl.LinkDb.invert(LinkDb.java:225)
	at org.apache.nutch.crawl.LinkDb.run(LinkDb.java:370)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.LinkDb.main(LinkDb.java:329)

2021-12-20 05:57:57,711 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:57:58
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:57:58,305 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:57:58,307 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:57:58,321 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:57:58,457 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:57:59,905 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:57:59,906 INFO  mapreduce.Job - Running job: job_local1481630145_0001
2021-12-20 05:58:00,937 INFO  mapreduce.Job - Job job_local1481630145_0001 running in uber mode : false
2021-12-20 05:58:00,939 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:58:00,997 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:58:00,998 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:58:00,999 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:58:01,166 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:01,349 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:58:01,943 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:58:01,944 INFO  mapreduce.Job - Job job_local1481630145_0001 completed successfully
2021-12-20 05:58:01,977 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3123292
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=509607936
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:58:01,978 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:58:01,996 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:58:02,002 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:58:03,003 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055803
2021-12-20 05:58:03,014 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:03,416 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:58:03,416 INFO  mapreduce.Job - Running job: job_local1342592206_0002
2021-12-20 05:58:03,627 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:04,417 INFO  mapreduce.Job - Job job_local1342592206_0002 running in uber mode : false
2021-12-20 05:58:04,418 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:58:04,420 INFO  mapreduce.Job - Job job_local1342592206_0002 completed successfully
2021-12-20 05:58:04,432 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6249866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:58:04,466 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:58:04, elapsed: 00:00:06
2021-12-20 05:58:45,222 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-20 05:58:45
2021-12-20 05:58:45,223 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211220055803
2021-12-20 05:58:45,618 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:58:46,061 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:58:47,640 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:58:47,641 INFO  mapreduce.Job - Running job: job_local231793127_0001
2021-12-20 05:58:48,093 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-20 05:58:48,093 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-20 05:58:48,164 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-20 05:58:48,231 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 22 records
2021-12-20 05:58:48,231 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-20 05:58:48,234 INFO  fetcher.QueueFeeder - 	22	SUCCESSFULLY_QUEUED
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-20 05:58:48,682 INFO  mapreduce.Job - Job job_local231793127_0001 running in uber mode : false
2021-12-20 05:58:48,684 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:58:48,726 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,769 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,770 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,771 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,772 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,773 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,782 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,784 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,788 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,788 INFO  fetcher.FetcherThread - FetcherThread 49 fetching https://nutch.apache.org/community/ (queue crawl delay=5000ms)
2021-12-20 05:58:48,792 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://en.wikipedia.org/wiki/Web_crawler (queue crawl delay=5000ms)
2021-12-20 05:58:48,792 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://solr.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:48,795 INFO  fetcher.FetcherThread - FetcherThread 52 fetching https://github.com/jeblister/kube (queue crawl delay=5000ms)
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.host = null
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.port = 8080
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.exception.list = false
2021-12-20 05:58:49,126 INFO  http.Http - http.timeout = 10000
2021-12-20 05:58:49,126 INFO  http.Http - http.content.limit = 1048576
2021-12-20 05:58:49,126 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-20 05:58:49,126 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-20 05:58:49,126 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-20 05:58:49,126 INFO  http.Http - http.enable.cookie.header = true
2021-12-20 05:58:49,127 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,129 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,130 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,137 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,138 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,145 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,146 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,147 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://www.elastic.co/elastic-stack/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,158 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/scoring/ScoringFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:49,164 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,165 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,175 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,176 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,180 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-20 05:58:49,180 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-20 05:58:49,185 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://hadoop.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,189 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://tika.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,192 INFO  fetcher.FetcherThread - FetcherThread 57 fetching https://cwiki.apache.org/confluence/display/NUTCH/NutchTutorial (queue crawl delay=5000ms)
2021-12-20 05:58:50,185 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=1, fetchQueues.totalSize=13, fetchQueues.getQueueCount=9
2021-12-20 05:58:50,584 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/scoring/ScoringFilter.html
2021-12-20 05:58:50,625 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/HtmlParseFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,625 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/HtmlParseFilter.html
2021-12-20 05:58:50,699 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/indexer/IndexingFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,699 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/indexer/IndexingFilter.html
2021-12-20 05:58:50,975 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/Parser.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,975 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/Parser.html
2021-12-20 05:58:51,187 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=8, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:52,188 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:53,190 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:54,191 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=2
2021-12-20 05:58:55,192 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=2
2021-12-20 05:58:55,980 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/download/ (queue crawl delay=5000ms)
2021-12-20 05:58:56,194 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=9, fetchQueues.getQueueCount=2
2021-12-20 05:58:56,496 INFO  fetcher.FetcherThread - FetcherThread 52 fetching https://github.com/apache/nutch (queue crawl delay=5000ms)
2021-12-20 05:58:57,195 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=8, fetchQueues.getQueueCount=2
2021-12-20 05:58:58,196 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:58:59,197 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:00,198 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:00,702 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-20 05:59:01,200 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:01,450 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/download (queue crawl delay=5000ms)
2021-12-20 05:59:01,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2021-12-20 05:59:02,201 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:03,203 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:04,204 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:05,205 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:06,207 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:06,649 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://nutch.apache.org/documentation/ (queue crawl delay=5000ms)
2021-12-20 05:59:07,208 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:08,209 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:09,210 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:10,211 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:11,212 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:11,833 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://nutch.apache.org/news/ (queue crawl delay=5000ms)
2021-12-20 05:59:12,213 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:13,214 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:14,216 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:15,217 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:16,218 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:17,006 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/index.xml (queue crawl delay=5000ms)
2021-12-20 05:59:17,219 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960157003
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   now           = 1639960157220
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:18,221 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   now           = 1639960158222
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:19,223 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   now           = 1639960159224
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:19,225 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:19,225 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:20,226 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   now           = 1639960160227
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:21,228 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   now           = 1639960161229
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:22,230 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   now           = 1639960162231
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:22,598 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/apache/ (queue crawl delay=5000ms)
2021-12-20 05:59:23,232 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   now           = 1639960163233
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:24,234 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   now           = 1639960164235
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:25,236 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   now           = 1639960165237
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:26,238 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:26,238 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:26,238 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   now           = 1639960166239
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:27,240 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   now           = 1639960167240
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:27,754 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/img/kube/plus-square.svg (queue crawl delay=5000ms)
2021-12-20 05:59:28,241 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:28,241 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   now           = 1639960168242
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:29,243 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   now           = 1639960169243
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:29,244 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:30,244 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   now           = 1639960170245
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:31,246 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:31,246 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:31,246 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   now           = 1639960171247
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:32,248 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   now           = 1639960172249
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:33,245 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/img/kube/plug.svg (queue crawl delay=5000ms)
2021-12-20 05:59:33,250 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   now           = 1639960173251
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:34,252 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:34,253 INFO  fetcher.FetchItemQueue -   now           = 1639960174253
2021-12-20 05:59:34,253 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:35,253 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   now           = 1639960175254
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:36,255 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   now           = 1639960176256
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:37,257 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   now           = 1639960177258
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:38,259 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   now           = 1639960178259
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:38,769 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/development/ (queue crawl delay=5000ms)
2021-12-20 05:59:38,794 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-20 05:59:38,794 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=9
2021-12-20 05:59:38,911 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-20 05:59:38,912 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=8
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=7
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=6
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=5
2021-12-20 05:59:39,005 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-20 05:59:39,006 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=4
2021-12-20 05:59:39,017 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-20 05:59:39,018 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=3
2021-12-20 05:59:39,184 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-20 05:59:39,184 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:59:39,212 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-20 05:59:39,212 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:59:39,227 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-20 05:59:39,227 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=0
2021-12-20 05:59:39,260 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-20 05:59:39,260 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-20 05:59:39,339 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:59:39,743 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:59:39,744 INFO  mapreduce.Job - Job job_local231793127_0001 completed successfully
2021-12-20 05:59:39,775 INFO  mapreduce.Job - Counters: 34
	File System Counters
		FILE: Number of bytes read=4147300
		FILE: Number of bytes written=6738068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=41
		Map output bytes=1125226
		Map output materialized bytes=1125375
		Input split bytes=168
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=1125375
		Reduce input records=41
		Reduce output records=41
		Spilled Records=82
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=66
		Total committed heap usage (bytes)=321912832
	FetcherStatus
		bytes_downloaded=1100785
		moved=1
		robots_denied=4
		success=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2472
	File Output Format Counters 
		Bytes Written=264937
2021-12-20 05:59:39,775 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-20 05:59:39, elapsed: 00:00:54
2021-12-20 06:00:02,850 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:00:03,386 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 06:00:03
2021-12-20 06:00:03,386 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055803
2021-12-20 06:00:03,531 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:00:04,991 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:00:04,992 INFO  mapreduce.Job - Running job: job_local1892353904_0001
2021-12-20 06:00:06,008 INFO  mapreduce.Job - Job job_local1892353904_0001 running in uber mode : false
2021-12-20 06:00:06,010 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 06:00:06,391 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-20 06:00:06,419 INFO  parse.ParseSegment - Parsed (537ms): https://cwiki.apache.org/confluence/display/NUTCH/NutchTutorial
2021-12-20 06:00:06,641 INFO  parse.ParseSegment - Parsed (207ms): https://en.wikipedia.org/wiki/Web_crawler
2021-12-20 06:00:06,787 INFO  parse.ParseSegment - Parsed (126ms): https://github.com/apache/nutch
2021-12-20 06:00:06,880 INFO  parse.ParseSegment - Parsed (88ms): https://github.com/jeblister/kube
2021-12-20 06:00:06,902 INFO  parse.ParseSegment - Parsed (19ms): https://hadoop.apache.org/
2021-12-20 06:00:06,916 INFO  parse.ParseSegment - Parsed (11ms): https://nutch.apache.org/apache/
2021-12-20 06:00:06,927 INFO  parse.ParseSegment - Parsed (10ms): https://nutch.apache.org/community/
2021-12-20 06:00:06,936 INFO  parse.ParseSegment - Parsed (8ms): https://nutch.apache.org/development/
2021-12-20 06:00:06,946 INFO  parse.ParseSegment - Parsed (9ms): https://nutch.apache.org/documentation/
2021-12-20 06:00:06,958 INFO  parse.ParseSegment - Parsed (10ms): https://nutch.apache.org/download/
2021-12-20 06:00:06,959 INFO  parse.ParserFactory - The parsing plugins: [org.apache.nutch.parse.tika.TikaParser] are enabled via the plugin.includes system property, and all claim to support the content type image/svg+xml, but they are not mapped to it  in the parse-plugins.xml file
2021-12-20 06:00:07,961 ERROR tika.TikaParser - Problem loading custom Tika configuration from tika-config.xml
java.lang.NumberFormatException: For input string: ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:68)
	at java.base/java.lang.Integer.parseInt(Integer.java:668)
	at java.base/java.lang.Integer.parseInt(Integer.java:776)
	at org.apache.tika.config.TikaConfig.updateXMLReaderUtils(TikaConfig.java:303)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:192)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:182)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:157)
	at org.apache.nutch.parse.tika.TikaParser.setConf(TikaParser.java:274)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:122)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-20 06:00:14,394 INFO  parse.ParseSegment - Parsed (7435ms): https://nutch.apache.org/img/kube/plug.svg
2021-12-20 06:00:14,402 INFO  parse.ParseSegment - Parsed (7ms): https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 06:00:14,403 WARN  parse.ParserFactory - ParserFactory: Plugin: org.apache.nutch.parse.feed.FeedParser mapped to contentType application/rss+xml via parse-plugins.xml, but not enabled via plugin.includes in nutch-default.xml
2021-12-20 06:00:14,779 INFO  parse.ParseSegment - Parsed (376ms): https://nutch.apache.org/index.xml
2021-12-20 06:00:14,808 INFO  parse.ParseSegment - Parsed (28ms): https://nutch.apache.org/news/
2021-12-20 06:00:14,849 INFO  parse.ParseSegment - Parsed (40ms): https://solr.apache.org/
2021-12-20 06:00:14,878 INFO  parse.ParseSegment - Parsed (28ms): https://tika.apache.org/
2021-12-20 06:00:14,936 INFO  parse.ParseSegment - Parsed (55ms): https://www.elastic.co/elastic-stack/
2021-12-20 06:00:15,029 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:00:15,123 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:00:15,275 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 06:00:15,488 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-20 06:00:16,031 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:00:16,032 INFO  mapreduce.Job - Job job_local1892353904_0001 completed successfully
2021-12-20 06:00:16,054 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3037060
		FILE: Number of bytes written=4203903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=17
		Map output bytes=313087
		Map output materialized bytes=313162
		Input split bytes=166
		Combine input records=0
		Combine output records=0
		Reduce input groups=17
		Reduce shuffle bytes=313162
		Reduce input records=17
		Reduce output records=17
		Spilled Records=34
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=362807296
	ParserStatus
		success=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=259556
	File Output Format Counters 
		Bytes Written=0
2021-12-20 06:00:16,066 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-20 06:00:16, elapsed: 00:00:12
2021-12-20 06:01:14,395 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:01:14,987 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 06:01:14
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055520]
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 06:01:14,990 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055520
2021-12-20 06:01:14,990 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 06:01:15,108 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:01:16,428 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:01:16,429 INFO  mapreduce.Job - Running job: job_local203010184_0001
2021-12-20 06:01:16,939 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:01:17,455 INFO  mapreduce.Job - Job job_local203010184_0001 running in uber mode : false
2021-12-20 06:01:17,457 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:01:17,693 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 06:01:17,693 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 06:01:17,694 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 06:01:18,459 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:01:18,461 INFO  mapreduce.Job - Job job_local203010184_0001 completed successfully
2021-12-20 06:01:18,485 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3106342
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=408944640
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 06:01:18,515 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 06:01:18, elapsed: 00:00:03
2021-12-20 06:01:25,036 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:01:25,711 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 06:01:25
2021-12-20 06:01:25,712 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 06:01:25,712 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055803]
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 06:01:25,720 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 06:01:25,838 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:01:27,264 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:01:27,265 INFO  mapreduce.Job - Running job: job_local1863148604_0001
2021-12-20 06:01:28,212 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:01:28,275 INFO  mapreduce.Job - Job job_local1863148604_0001 running in uber mode : false
2021-12-20 06:01:28,281 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:01:28,997 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 06:01:28,999 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 06:01:28,999 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 06:01:29,286 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:01:29,288 INFO  mapreduce.Job - Job job_local1863148604_0001 completed successfully
2021-12-20 06:01:29,316 INFO  mapreduce.Job - Counters: 34
	File System Counters
		FILE: Number of bytes read=4231468
		FILE: Number of bytes written=6607229
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=866
		Map output records=866
		Map output bytes=69719
		Map output materialized bytes=71512
		Input split bytes=485
		Combine input records=0
		Combine output records=0
		Reduce input groups=499
		Reduce shuffle bytes=71512
		Reduce input records=866
		Reduce output records=499
		Spilled Records=1732
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=970981376
	CrawlDB status
		db_fetched=18
		db_gone=4
		db_redir_perm=1
		db_unfetched=476
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=77629
	File Output Format Counters 
		Bytes Written=48187
2021-12-20 06:01:29,352 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 06:01:29, elapsed: 00:00:03
2021-12-20 06:03:07,895 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-20 06:03:08
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220054847
2021-12-20 06:03:08,605 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520
2021-12-20 06:03:08,606 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615
2021-12-20 06:03:08,608 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055803
2021-12-20 06:03:08,734 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:03:09,333 ERROR crawl.LinkDb - LinkDb job failed: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
2021-12-20 06:03:09,337 ERROR crawl.LinkDb - LinkDb: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.crawl.LinkDb.invert(LinkDb.java:225)
	at org.apache.nutch.crawl.LinkDb.run(LinkDb.java:370)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.LinkDb.main(LinkDb.java:329)

2021-12-20 06:03:58,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:03:58,565 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20211220055803.
2021-12-20 06:03:58,570 INFO  indexer.IndexingJob - Indexer: starting at 2021-12-20 06:03:58
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2021-12-20 06:03:58,585 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2021-12-20 06:03:58,590 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20211220055803
2021-12-20 06:03:58,596 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2021-12-20 06:03:58,597 WARN  indexer.IndexerMapReduce - Ignoring linkDb for indexing, no linkDb found in path: crawl/linkdb
2021-12-20 06:03:58,742 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:04:00,210 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:04:00,211 INFO  mapreduce.Job - Running job: job_local1480483803_0001
2021-12-20 06:04:01,220 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:01,240 INFO  mapreduce.Job - Job job_local1480483803_0001 running in uber mode : false
2021-12-20 06:04:01,242 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 06:04:01,844 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,001 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,205 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,247 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:04:02,353 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,437 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:04:02,603 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2021-12-20 06:04:02,914 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2021-12-20 06:04:03,672 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a  string  value  of│http                            │
│            │one of the following "cloud" or "http". The values represent CloudSolrServer│                                │
│            │or HttpSolrServer respectively.                                             │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should  be  indexed.│http://localhost:8983/solr/nutch│
│            │Multiple URL can be provided using comma as a delimiter. When the  value  of│                                │
│            │type property is cloud, the URL should not include any collections or cores;│                                │
│            │just the root Solr path.                                                    │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of  type  property│                                │
│            │is cloud.                                                                   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a  single  update  batch.│1000                            │
│            │Decrease when handling very large documents to prevent  Nutch  from  running│                                │
│            │out of memory. Note: It does not explicitly trigger a server side commit.   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be  written.  If  it  is│                                │
│            │empty no field will be used.                                                │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use│false                           │
│            │the username and password properties to configure your credentials.         │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                │username                        │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                │password                        │
└────────────┴────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2021-12-20 06:04:03,716 INFO  anchor.AnchorIndexingFilter - Anchor deduplication is: off
2021-12-20 06:04:04,402 INFO  solr.SolrIndexWriter - Indexing 17/17 documents
2021-12-20 06:04:04,403 INFO  solr.SolrIndexWriter - Deleting 0 documents
2021-12-20 06:04:06,251 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:04:06,252 INFO  mapreduce.Job - Job job_local1480483803_0001 completed successfully
2021-12-20 06:04:06,309 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=7390159
		FILE: Number of bytes written=11250468
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1376
		Map output records=1376
		Map output bytes=349714
		Map output materialized bytes=352634
		Input split bytes=823
		Combine input records=0
		Combine output records=0
		Reduce input groups=499
		Reduce shuffle bytes=352634
		Reduce input records=1376
		Reduce output records=17
		Spilled Records=2752
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=1259339776
	IndexerStatus
		indexed (add/update)=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=211771
	File Output Format Counters 
		Bytes Written=0
2021-12-20 06:04:06,310 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2021-12-20 06:04:06,336 INFO  indexer.IndexingJob - Indexer:     17  indexed (add/update)
2021-12-20 06:04:06,344 INFO  indexer.IndexingJob - Indexer: finished at 2021-12-20 06:04:06, elapsed: 00:00:07
