2021-12-20 03:59:17,176 INFO  crawl.Injector - Injector: starting at 2021-12-20 03:59:17
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 03:59:17,177 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 03:59:17,689 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 03:59:18,628 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 03:59:18,803 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 03:59:20,315 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 03:59:20,316 INFO  mapreduce.Job - Running job: job_local2080166325_0001
2021-12-20 03:59:21,336 INFO  mapreduce.Job - Job job_local2080166325_0001 running in uber mode : false
2021-12-20 03:59:21,338 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 03:59:21,667 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:21,894 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 03:59:21,895 INFO  crawl.Injector - Injector: update: false
2021-12-20 03:59:21,930 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:22,017 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 03:59:22,017 INFO  crawl.Injector - Injector: update: false
2021-12-20 03:59:22,341 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 03:59:22,343 INFO  mapreduce.Job - Job job_local2080166325_0001 completed successfully
2021-12-20 03:59:22,382 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=2838013
		FILE: Number of bytes written=4660134
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=28
		Input split bytes=286
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=28
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=8
		Total committed heap usage (bytes)=619708416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 03:59:22,450 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 03:59:22,467 INFO  crawl.Injector - Injector: finished at 2021-12-20 03:59:22, elapsed: 00:00:05
2021-12-20 03:59:24,402 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: starting at 2021-12-20 03:59:25
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 03:59:25,031 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 03:59:25,032 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 03:59:25,035 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 03:59:25,186 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 03:59:26,864 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 03:59:26,865 INFO  mapreduce.Job - Running job: job_local1635138310_0001
2021-12-20 03:59:27,723 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 03:59:27,726 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 03:59:27,726 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 03:59:27,874 INFO  mapreduce.Job - Job job_local1635138310_0001 running in uber mode : false
2021-12-20 03:59:27,878 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 03:59:27,953 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 03:59:27,954 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 03:59:27,954 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 03:59:28,033 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:28,243 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 03:59:28,922 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 03:59:28,923 INFO  mapreduce.Job - Job job_local1635138310_0001 completed successfully
2021-12-20 03:59:28,954 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 03:59:28,955 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 03:59:28,983 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:13:27,208 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:13:27
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:13:27,209 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:13:27,496 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:13:28,030 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:13:28,156 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:13:29,530 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:13:29,531 INFO  mapreduce.Job - Running job: job_local362465298_0001
2021-12-20 04:13:30,543 INFO  mapreduce.Job - Job job_local362465298_0001 running in uber mode : false
2021-12-20 04:13:30,548 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:13:30,743 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:30,934 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:13:30,935 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:13:30,962 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:31,057 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:13:31,058 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:13:31,551 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:13:31,553 INFO  mapreduce.Job - Job job_local362465298_0001 completed successfully
2021-12-20 04:13:31,595 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=1030750208
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:13:31,660 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:13:31,661 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:13:31,680 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:13:31, elapsed: 00:00:04
2021-12-20 04:13:33,479 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:13:34,052 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:13:34
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:13:34,053 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:13:34,055 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:13:34,211 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:13:35,494 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:13:35,495 INFO  mapreduce.Job - Running job: job_local860905576_0001
2021-12-20 04:13:36,387 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:13:36,390 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:13:36,390 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:13:36,526 INFO  mapreduce.Job - Job job_local860905576_0001 running in uber mode : false
2021-12-20 04:13:36,563 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:13:36,593 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:13:36,594 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:13:36,594 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:13:36,680 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:36,882 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:13:37,570 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:13:37,571 INFO  mapreduce.Job - Job job_local860905576_0001 completed successfully
2021-12-20 04:13:37,595 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6217506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=835715072
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:13:37,595 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:13:37,625 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:19:30,810 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:19:30
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:19:30,811 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:19:31,080 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:19:31,772 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:19:31,899 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:19:33,193 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:19:33,194 INFO  mapreduce.Job - Running job: job_local1172278039_0001
2021-12-20 04:19:34,202 INFO  mapreduce.Job - Job job_local1172278039_0001 running in uber mode : false
2021-12-20 04:19:34,204 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:19:34,566 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:34,769 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:19:34,770 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:19:34,793 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:34,881 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:19:34,881 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:19:35,207 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:19:35,209 INFO  mapreduce.Job - Job job_local1172278039_0001 completed successfully
2021-12-20 04:19:35,242 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=1038090240
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:19:35,305 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:19:35,306 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:19:35,324 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:19:35, elapsed: 00:00:04
2021-12-20 04:19:37,089 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:19:37
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:19:37,616 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:19:37,618 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:19:37,773 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:19:39,037 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:19:39,038 INFO  mapreduce.Job - Running job: job_local1924126038_0001
2021-12-20 04:19:39,970 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:19:39,973 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:19:39,973 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:19:40,047 INFO  mapreduce.Job - Job job_local1924126038_0001 running in uber mode : false
2021-12-20 04:19:40,049 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:19:40,159 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:19:40,159 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:19:40,160 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:19:40,243 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:40,442 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:19:41,052 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:19:41,054 INFO  mapreduce.Job - Job job_local1924126038_0001 completed successfully
2021-12-20 04:19:41,079 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=830472192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:19:41,080 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:19:41,102 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:20:26,825 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:20:26
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:20:26,826 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:20:27,132 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:27,756 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:20:27,886 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:29,260 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:29,261 INFO  mapreduce.Job - Running job: job_local856695529_0001
2021-12-20 04:20:30,282 INFO  mapreduce.Job - Job job_local856695529_0001 running in uber mode : false
2021-12-20 04:20:30,286 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:30,616 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:30,858 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:20:30,860 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:20:30,886 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:30,988 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:20:30,988 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:20:31,291 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:20:31,292 INFO  mapreduce.Job - Job job_local856695529_0001 completed successfully
2021-12-20 04:20:31,317 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755486
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=34
		Total committed heap usage (bytes)=1043333120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:20:31,384 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:20:31,385 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:20:31,405 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:20:31, elapsed: 00:00:04
2021-12-20 04:20:33,254 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:33,751 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:20:33
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:20:33,754 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:20:33,756 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:20:33,904 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:35,282 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:35,283 INFO  mapreduce.Job - Running job: job_local2063707495_0001
2021-12-20 04:20:36,135 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:20:36,137 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:20:36,137 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:20:36,295 INFO  mapreduce.Job - Job job_local2063707495_0001 running in uber mode : false
2021-12-20 04:20:36,300 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:36,337 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:20:36,337 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:20:36,337 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:20:36,417 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:36,578 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:20:37,317 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:20:37,317 INFO  mapreduce.Job - Job job_local2063707495_0001 completed successfully
2021-12-20 04:20:37,352 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=25
		Total committed heap usage (bytes)=833617920
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:20:37,353 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:20:37,372 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:20:56,102 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:20:56
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:20:56,103 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:20:56,385 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:20:56,952 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:20:57,070 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:20:58,478 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:20:58,479 INFO  mapreduce.Job - Running job: job_local1482060468_0001
2021-12-20 04:20:59,508 INFO  mapreduce.Job - Job job_local1482060468_0001 running in uber mode : false
2021-12-20 04:20:59,555 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 04:20:59,768 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:00,005 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:00,006 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:00,078 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:00,181 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:00,181 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:00,558 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:00,560 INFO  mapreduce.Job - Job job_local1482060468_0001 completed successfully
2021-12-20 04:21:00,585 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=1043333120
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:21:00,637 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:21:00,638 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:21:00,656 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:21:00, elapsed: 00:00:04
2021-12-20 04:21:02,502 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:03,090 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:21:03
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:21:03,091 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:21:03,094 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:21:03,240 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:04,587 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:04,588 INFO  mapreduce.Job - Running job: job_local199458287_0001
2021-12-20 04:21:05,572 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:05,574 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:05,574 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:05,608 INFO  mapreduce.Job - Job job_local199458287_0001 running in uber mode : false
2021-12-20 04:21:05,609 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:05,753 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:05,753 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:05,753 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:05,845 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:06,095 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:06,615 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:06,616 INFO  mapreduce.Job - Job job_local199458287_0001 completed successfully
2021-12-20 04:21:06,639 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6217506
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=829423616
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:21:06,639 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:21:06,662 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:21:33,989 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:21:33
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:21:33,990 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:21:34,253 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:34,906 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:21:35,054 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:36,880 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:36,881 INFO  mapreduce.Job - Running job: job_local199372878_0001
2021-12-20 04:21:37,913 INFO  mapreduce.Job - Job job_local199372878_0001 running in uber mode : false
2021-12-20 04:21:37,915 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:38,571 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:38,801 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:38,802 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:38,837 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:38,918 INFO  mapreduce.Job -  map 100% reduce 50%
2021-12-20 04:21:38,933 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:21:38,934 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:21:39,920 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:39,920 INFO  mapreduce.Job - Job job_local199372878_0001 completed successfully
2021-12-20 04:21:39,948 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7755466
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=1039138816
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:21:40,018 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:21:40,036 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:21:40, elapsed: 00:00:06
2021-12-20 04:21:42,025 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:21:42
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:21:42,643 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:21:42,646 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:21:42,813 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:21:44,263 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:21:44,264 INFO  mapreduce.Job - Running job: job_local50371423_0001
2021-12-20 04:21:45,273 INFO  mapreduce.Job - Job job_local50371423_0001 running in uber mode : false
2021-12-20 04:21:45,275 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:21:45,307 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:45,311 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:45,311 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:45,506 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:21:45,507 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:21:45,507 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:21:45,567 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:45,786 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:21:46,280 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:21:46,282 INFO  mapreduce.Job - Job job_local50371423_0001 completed successfully
2021-12-20 04:21:46,324 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6205682
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=832569344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:21:46,324 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:21:46,344 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 04:22:56,534 INFO  crawl.Injector - Injector: starting at 2021-12-20 04:22:56
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: crawlDb: Crawl/crawldb
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: urlDir: nutch/urls
2021-12-20 04:22:56,535 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 04:22:56,808 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:22:57,385 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 04:22:57,520 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:22:58,902 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:22:58,903 INFO  mapreduce.Job - Running job: job_local1368641918_0001
2021-12-20 04:22:59,912 INFO  mapreduce.Job - Job job_local1368641918_0001 running in uber mode : false
2021-12-20 04:22:59,914 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:23:00,238 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:00,420 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:23:00,422 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:23:00,446 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:00,563 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 04:23:00,563 INFO  crawl.Injector - Injector: update: false
2021-12-20 04:23:00,918 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:23:00,919 INFO  mapreduce.Job - Job job_local1368641918_0001 completed successfully
2021-12-20 04:23:00,958 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=4739318
		FILE: Number of bytes written=7770186
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=84
		Input split bytes=898
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=84
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=28
		Total committed heap usage (bytes)=1274019840
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=478
2021-12-20 04:23:01,064 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 04:23:01,065 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-20 04:23:01,092 INFO  crawl.Injector - Injector: finished at 2021-12-20 04:23:01, elapsed: 00:00:04
2021-12-20 04:23:02,978 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 04:23:03,527 INFO  crawl.Generator - Generator: starting at 2021-12-20 04:23:03
2021-12-20 04:23:03,528 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 04:23:03,529 INFO  crawl.Generator - Generator: filtering: false
2021-12-20 04:23:03,529 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 04:23:03,531 INFO  crawl.Generator - Generator: topN: 50000
2021-12-20 04:23:03,688 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 04:23:05,077 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 04:23:05,078 INFO  mapreduce.Job - Running job: job_local1193165626_0001
2021-12-20 04:23:06,053 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:23:06,055 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:23:06,055 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:23:06,088 INFO  mapreduce.Job - Job job_local1193165626_0001 running in uber mode : false
2021-12-20 04:23:06,090 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 04:23:06,203 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 04:23:06,203 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 04:23:06,203 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 04:23:06,293 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:06,466 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 04:23:07,093 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 04:23:07,094 INFO  mapreduce.Job - Job job_local1193165626_0001 completed successfully
2021-12-20 04:23:07,139 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3785865
		FILE: Number of bytes written=6229346
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=56
		Input split bytes=288
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=56
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =4
		Failed Shuffles=0
		Merged Map outputs=4
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=832569344
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=196
	File Output Format Counters 
		Bytes Written=16
2021-12-20 04:23:07,140 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 04:23:07,158 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-20 05:47:55,210 INFO  crawl.Injector - Injector: starting at 2021-12-20 05:47:55
2021-12-20 05:47:55,215 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-20 05:47:55,215 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-20 05:47:55,216 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-20 05:47:55,586 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:47:56,454 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/search/nutch/urls/seed.txt
2021-12-20 05:47:56,644 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:47:58,208 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:47:58,209 INFO  mapreduce.Job - Running job: job_local1714956858_0001
2021-12-20 05:47:59,242 INFO  mapreduce.Job - Job job_local1714956858_0001 running in uber mode : false
2021-12-20 05:47:59,252 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:47:59,540 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-20 05:47:59,681 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:47:59,950 INFO  crawl.Injector - Injector: overwrite: false
2021-12-20 05:47:59,951 INFO  crawl.Injector - Injector: update: false
2021-12-20 05:48:00,256 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:00,257 INFO  mapreduce.Job - Job job_local1714956858_0001 completed successfully
2021-12-20 05:48:00,298 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1892034
		FILE: Number of bytes written=3105958
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=55
		Map output materialized bytes=63
		Input split bytes=286
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=63
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=391
2021-12-20 05:48:00,332 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-20 05:48:00,333 INFO  crawl.Injector - Injector: Total new urls injected: 1
2021-12-20 05:48:00,361 INFO  crawl.Injector - Injector: finished at 2021-12-20 05:48:00, elapsed: 00:00:05
2021-12-20 05:48:42,039 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:48:42,722 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:48:42
2021-12-20 05:48:42,722 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:48:42,723 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:48:42,723 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:48:42,737 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:48:42,933 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:48:44,396 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:48:44,397 INFO  mapreduce.Job - Running job: job_local947595629_0001
2021-12-20 05:48:45,287 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:48:45,289 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:48:45,289 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:48:45,417 INFO  mapreduce.Job - Job job_local947595629_0001 running in uber mode : false
2021-12-20 05:48:45,421 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:48:45,432 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:45,642 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:48:46,425 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:46,426 INFO  mapreduce.Job - Job job_local947595629_0001 completed successfully
2021-12-20 05:48:46,446 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1892094
		FILE: Number of bytes written=3108012
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=84
		Map output materialized bytes=92
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=92
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=161
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:48:46,447 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:48:46,467 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:48:47,468 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220054847
2021-12-20 05:48:47,484 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:47,900 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:48:47,900 INFO  mapreduce.Job - Running job: job_local1183284572_0002
2021-12-20 05:48:48,096 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:48:48,901 INFO  mapreduce.Job - Job job_local1183284572_0002 running in uber mode : false
2021-12-20 05:48:48,902 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:48:48,902 INFO  mapreduce.Job - Job job_local1183284572_0002 completed successfully
2021-12-20 05:48:48,910 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3784622
		FILE: Number of bytes written=6217628
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=106
		Map output materialized bytes=114
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=114
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=212
	File Output Format Counters 
		Bytes Written=182
2021-12-20 05:48:48,929 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:48:48, elapsed: 00:00:06
2021-12-20 05:52:31,866 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-20 05:52:31
2021-12-20 05:52:31,867 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211220054847
2021-12-20 05:52:32,287 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:52:32,836 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:52:34,276 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:52:34,277 INFO  mapreduce.Job - Running job: job_local237842719_0001
2021-12-20 05:52:34,689 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-20 05:52:34,690 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-20 05:52:34,789 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-20 05:52:34,835 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - 	1	SUCCESSFULLY_QUEUED
2021-12-20 05:52:34,836 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-20 05:52:34,837 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-20 05:52:34,837 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-20 05:52:35,296 INFO  mapreduce.Job - Job job_local237842719_0001 running in uber mode : false
2021-12-20 05:52:35,298 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:52:35,366 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,505 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,507 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,508 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,511 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,518 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,519 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:52:35,519 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,520 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-20 05:52:35,522 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,521 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-20 05:52:35,522 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.host = null
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.port = 8080
2021-12-20 05:52:35,881 INFO  http.Http - http.proxy.exception.list = false
2021-12-20 05:52:35,881 INFO  http.Http - http.timeout = 10000
2021-12-20 05:52:35,881 INFO  http.Http - http.content.limit = 1048576
2021-12-20 05:52:35,881 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-20 05:52:35,881 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-20 05:52:35,881 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-20 05:52:35,881 INFO  http.Http - http.enable.cookie.header = true
2021-12-20 05:52:35,882 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,888 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,889 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,898 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,898 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-20 05:52:35,898 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,899 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,904 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,905 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,912 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,913 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,917 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,924 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,925 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,927 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:52:35,928 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:52:35,929 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-20 05:52:35,930 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:52:35,930 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-20 05:52:35,931 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,932 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-20 05:52:35,932 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-20 05:52:35,933 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-20 05:52:35,936 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:35,936 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-20 05:52:35,937 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:52:36,947 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2021-12-20 05:52:37,963 INFO  fetcher.Fetcher - -activeThreads=1, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=1
2021-12-20 05:52:38,137 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-20 05:52:38,137 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=0
2021-12-20 05:52:38,964 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-20 05:52:38,964 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-20 05:52:39,115 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:52:39,306 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:52:40,307 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:52:40,309 INFO  mapreduce.Job - Job job_local237842719_0001 completed successfully
2021-12-20 05:52:40,327 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1928338
		FILE: Number of bytes written=3160153
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=18172
		Map output materialized bytes=18185
		Input split bytes=168
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=18185
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=32
		Total committed heap usage (bytes)=429916160
	FetcherStatus
		bytes_downloaded=17249
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=182
	File Output Format Counters 
		Bytes Written=8594
2021-12-20 05:52:40,334 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-20 05:52:40, elapsed: 00:00:08
2021-12-20 05:53:13,215 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:53:13,748 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:53:13
2021-12-20 05:53:13,749 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220054847
2021-12-20 05:53:13,918 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:53:15,388 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:53:15,389 INFO  mapreduce.Job - Running job: job_local878885184_0001
2021-12-20 05:53:16,413 INFO  mapreduce.Job - Job job_local878885184_0001 running in uber mode : false
2021-12-20 05:53:16,416 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:53:16,789 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-20 05:53:16,798 INFO  parse.ParseSegment - Parsed (489ms): https://nutch.apache.org/
2021-12-20 05:53:16,934 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:53:17,088 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:53:17,234 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-20 05:53:17,420 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:53:17,422 INFO  mapreduce.Job - Job job_local878885184_0001 completed successfully
2021-12-20 05:53:17,452 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1915726
		FILE: Number of bytes written=3116444
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=4232
		Map output materialized bytes=4242
		Input split bytes=166
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=4242
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=406847488
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7810
	File Output Format Counters 
		Bytes Written=0
2021-12-20 05:53:17,477 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-20 05:53:17, elapsed: 00:00:03
2021-12-20 05:53:38,470 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:53:39,108 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:53:39
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220054847]
2021-12-20 05:53:39,109 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:53:39,110 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:53:39,113 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:53:39,242 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:53:40,873 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:53:40,874 INFO  mapreduce.Job - Running job: job_local1221950224_0001
2021-12-20 05:53:41,688 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:53:41,891 INFO  mapreduce.Job - Job job_local1221950224_0001 running in uber mode : false
2021-12-20 05:53:41,892 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:53:42,369 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:53:42,370 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:53:42,370 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:53:42,894 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:53:42,895 INFO  mapreduce.Job - Job job_local1221950224_0001 completed successfully
2021-12-20 05:53:42,924 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3801588
		FILE: Number of bytes written=6223633
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=26
		Map output records=26
		Map output bytes=2104
		Map output materialized bytes=2175
		Input split bytes=485
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=2175
		Reduce input records=26
		Reduce output records=23
		Spilled Records=52
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=823132160
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:53:42,941 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:53:42, elapsed: 00:00:03
2021-12-20 05:55:15,322 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:55:15
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:55:15,943 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:55:15,944 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:55:15,946 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:55:15,961 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:55:16,111 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:17,595 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:17,596 INFO  mapreduce.Job - Running job: job_local160341921_0001
2021-12-20 05:55:18,589 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:55:18,591 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:55:18,591 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:55:18,623 INFO  mapreduce.Job - Job job_local160341921_0001 running in uber mode : false
2021-12-20 05:55:18,625 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:55:18,780 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:18,960 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:55:19,627 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:19,629 INFO  mapreduce.Job - Job job_local160341921_0001 completed successfully
2021-12-20 05:55:19,655 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3117376
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:55:19,656 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:55:19,664 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:55:19,674 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:55:20,675 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055520
2021-12-20 05:55:20,691 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:21,089 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:21,089 INFO  mapreduce.Job - Running job: job_local1722723080_0002
2021-12-20 05:55:21,280 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:22,090 INFO  mapreduce.Job - Job job_local1722723080_0002 running in uber mode : false
2021-12-20 05:55:22,091 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:22,092 INFO  mapreduce.Job - Job job_local1722723080_0002 completed successfully
2021-12-20 05:55:22,114 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6243942
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:55:22,139 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:55:22, elapsed: 00:00:06
2021-12-20 05:55:24,185 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:24,743 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:55:24
2021-12-20 05:55:24,743 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055520
2021-12-20 05:55:24,907 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:25,459 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:255)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:303)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:274)

2021-12-20 05:55:27,458 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:55:28,033 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:55:28
2021-12-20 05:55:28,033 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055520]
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:55:28,035 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:55:28,036 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:55:28,036 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:55:28,037 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055520
2021-12-20 05:55:28,037 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:55:28,176 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:55:29,553 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:55:29,554 INFO  mapreduce.Job - Running job: job_local901930964_0001
2021-12-20 05:55:30,106 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:55:30,575 INFO  mapreduce.Job - Job job_local901930964_0001 running in uber mode : false
2021-12-20 05:55:30,577 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:55:30,879 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:55:30,880 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:55:30,880 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:55:31,579 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:55:31,581 INFO  mapreduce.Job - Job job_local901930964_0001 completed successfully
2021-12-20 05:55:31,598 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3106342
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=460324864
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:55:31,629 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:55:31, elapsed: 00:00:03
2021-12-20 05:56:10,568 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:11,196 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:56:11
2021-12-20 05:56:11,196 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:56:11,197 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:56:11,198 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:56:11,201 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:56:11,227 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:56:11,373 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:12,676 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:12,677 INFO  mapreduce.Job - Running job: job_local1396614071_0001
2021-12-20 05:56:13,608 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:56:13,610 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:56:13,610 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:56:13,695 INFO  mapreduce.Job - Job job_local1396614071_0001 running in uber mode : false
2021-12-20 05:56:13,697 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:56:13,783 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:13,990 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:56:14,700 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:14,703 INFO  mapreduce.Job - Job job_local1396614071_0001 completed successfully
2021-12-20 05:56:14,730 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3123292
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:56:14,731 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:56:14,745 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:56:14,748 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:56:15,749 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055615
2021-12-20 05:56:15,765 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:16,179 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:16,179 INFO  mapreduce.Job - Running job: job_local1997488184_0002
2021-12-20 05:56:16,361 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:17,180 INFO  mapreduce.Job - Job job_local1997488184_0002 running in uber mode : false
2021-12-20 05:56:17,180 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:17,181 INFO  mapreduce.Job - Job job_local1997488184_0002 completed successfully
2021-12-20 05:56:17,194 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6249866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:56:17,216 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:56:17, elapsed: 00:00:06
2021-12-20 05:56:19,164 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:19,670 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 05:56:19
2021-12-20 05:56:19,671 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055615
2021-12-20 05:56:19,832 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:20,357 ERROR parse.ParseSegment - org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/content
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.parse.ParseSegment.parse(ParseSegment.java:255)
	at org.apache.nutch.parse.ParseSegment.run(ParseSegment.java:303)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.parse.ParseSegment.main(ParseSegment.java:274)

2021-12-20 05:56:22,385 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:56:23,100 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 05:56:23
2021-12-20 05:56:23,101 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 05:56:23,101 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055615]
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 05:56:23,102 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 05:56:23,104 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055615
2021-12-20 05:56:23,105 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 05:56:23,245 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:56:24,637 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:56:24,639 INFO  mapreduce.Job - Running job: job_local1452689239_0001
2021-12-20 05:56:25,149 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:56:25,667 INFO  mapreduce.Job - Job job_local1452689239_0001 running in uber mode : false
2021-12-20 05:56:25,669 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 05:56:25,976 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:56:25,977 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:56:25,977 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:56:26,671 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:56:26,673 INFO  mapreduce.Job - Job job_local1452689239_0001 completed successfully
2021-12-20 05:56:26,702 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3112206
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=408944640
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 05:56:26,726 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 05:56:26, elapsed: 00:00:03
2021-12-20 05:57:08,059 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:57:08,843 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-20 05:57:08
2021-12-20 05:57:08,843 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-20 05:57:08,844 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220054847
2021-12-20 05:57:08,847 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520
2021-12-20 05:57:08,848 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615
2021-12-20 05:57:08,996 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:57:09,707 ERROR crawl.LinkDb - LinkDb job failed: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
2021-12-20 05:57:09,710 ERROR crawl.LinkDb - LinkDb: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.crawl.LinkDb.invert(LinkDb.java:225)
	at org.apache.nutch.crawl.LinkDb.run(LinkDb.java:370)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.LinkDb.main(LinkDb.java:329)

2021-12-20 05:57:57,711 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: starting at 2021-12-20 05:57:58
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-20 05:57:58,304 INFO  crawl.Generator - Generator: filtering: true
2021-12-20 05:57:58,305 INFO  crawl.Generator - Generator: normalizing: true
2021-12-20 05:57:58,307 INFO  crawl.Generator - Generator: topN: 1000
2021-12-20 05:57:58,321 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-20 05:57:58,457 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:57:59,905 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:57:59,906 INFO  mapreduce.Job - Running job: job_local1481630145_0001
2021-12-20 05:58:00,937 INFO  mapreduce.Job - Job job_local1481630145_0001 running in uber mode : false
2021-12-20 05:58:00,939 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:58:00,997 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 05:58:00,998 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 05:58:00,999 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 05:58:01,166 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:01,349 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-20 05:58:01,943 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:58:01,944 INFO  mapreduce.Job - Job job_local1481630145_0001 completed successfully
2021-12-20 05:58:01,977 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1900856
		FILE: Number of bytes written=3123292
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=22
		Map output bytes=2358
		Map output materialized bytes=2412
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2412
		Reduce input records=22
		Reduce output records=0
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=509607936
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=8
2021-12-20 05:58:01,978 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-20 05:58:01,996 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-20 05:58:02,002 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-20 05:58:03,003 INFO  crawl.Generator - Generator: segment: crawl/segments/20211220055803
2021-12-20 05:58:03,014 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:03,416 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:58:03,416 INFO  mapreduce.Job - Running job: job_local1342592206_0002
2021-12-20 05:58:03,627 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:58:04,417 INFO  mapreduce.Job - Job job_local1342592206_0002 running in uber mode : false
2021-12-20 05:58:04,418 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:58:04,420 INFO  mapreduce.Job - Job job_local1342592206_0002 completed successfully
2021-12-20 05:58:04,432 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3809534
		FILE: Number of bytes written=6249866
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=3352
		Map output materialized bytes=3406
		Input split bytes=186
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=3406
		Reduce input records=22
		Reduce output records=22
		Spilled Records=44
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=4
		Total committed heap usage (bytes)=417333248
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2674
	File Output Format Counters 
		Bytes Written=2472
2021-12-20 05:58:04,466 INFO  crawl.Generator - Generator: finished at 2021-12-20 05:58:04, elapsed: 00:00:06
2021-12-20 05:58:45,222 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-20 05:58:45
2021-12-20 05:58:45,223 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211220055803
2021-12-20 05:58:45,618 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 05:58:46,061 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 05:58:47,640 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 05:58:47,641 INFO  mapreduce.Job - Running job: job_local231793127_0001
2021-12-20 05:58:48,093 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-20 05:58:48,093 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-20 05:58:48,164 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-20 05:58:48,231 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 22 records
2021-12-20 05:58:48,231 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-20 05:58:48,234 INFO  fetcher.QueueFeeder - 	22	SUCCESSFULLY_QUEUED
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-20 05:58:48,235 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-20 05:58:48,682 INFO  mapreduce.Job - Job job_local231793127_0001 running in uber mode : false
2021-12-20 05:58:48,684 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 05:58:48,726 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,769 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,770 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,771 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,772 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,773 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,782 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,784 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:48,788 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:48,788 INFO  fetcher.FetcherThread - FetcherThread 49 fetching https://nutch.apache.org/community/ (queue crawl delay=5000ms)
2021-12-20 05:58:48,792 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://en.wikipedia.org/wiki/Web_crawler (queue crawl delay=5000ms)
2021-12-20 05:58:48,792 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://solr.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:48,795 INFO  fetcher.FetcherThread - FetcherThread 52 fetching https://github.com/jeblister/kube (queue crawl delay=5000ms)
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.host = null
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.port = 8080
2021-12-20 05:58:49,126 INFO  http.Http - http.proxy.exception.list = false
2021-12-20 05:58:49,126 INFO  http.Http - http.timeout = 10000
2021-12-20 05:58:49,126 INFO  http.Http - http.content.limit = 1048576
2021-12-20 05:58:49,126 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-20 05:58:49,126 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-20 05:58:49,126 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-20 05:58:49,126 INFO  http.Http - http.enable.cookie.header = true
2021-12-20 05:58:49,127 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,129 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,130 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,137 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,138 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,145 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,146 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,147 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://www.elastic.co/elastic-stack/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,158 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/scoring/ScoringFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:49,164 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,165 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,175 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 05:58:49,176 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-20 05:58:49,180 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-20 05:58:49,180 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-20 05:58:49,185 INFO  fetcher.FetcherThread - FetcherThread 55 fetching https://hadoop.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,189 INFO  fetcher.FetcherThread - FetcherThread 56 fetching https://tika.apache.org/ (queue crawl delay=5000ms)
2021-12-20 05:58:49,192 INFO  fetcher.FetcherThread - FetcherThread 57 fetching https://cwiki.apache.org/confluence/display/NUTCH/NutchTutorial (queue crawl delay=5000ms)
2021-12-20 05:58:50,185 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=1, fetchQueues.totalSize=13, fetchQueues.getQueueCount=9
2021-12-20 05:58:50,584 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/scoring/ScoringFilter.html
2021-12-20 05:58:50,625 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/HtmlParseFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,625 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/HtmlParseFilter.html
2021-12-20 05:58:50,699 INFO  fetcher.FetcherThread - FetcherThread 58 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/indexer/IndexingFilter.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,699 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/indexer/IndexingFilter.html
2021-12-20 05:58:50,975 INFO  fetcher.FetcherThread - FetcherThread 51 fetching https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/Parser.html (queue crawl delay=5000ms)
2021-12-20 05:58:50,975 INFO  fetcher.FetcherThread - Denied by robots.txt: https://ci-builds.apache.org/job/Nutch/job/Nutch-trunk/javadoc/org/apache/nutch/parse/Parser.html
2021-12-20 05:58:51,187 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=8, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:52,188 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:53,190 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=10, fetchQueues.getQueueCount=3
2021-12-20 05:58:54,191 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=2
2021-12-20 05:58:55,192 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=2
2021-12-20 05:58:55,980 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/download/ (queue crawl delay=5000ms)
2021-12-20 05:58:56,194 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=9, fetchQueues.getQueueCount=2
2021-12-20 05:58:56,496 INFO  fetcher.FetcherThread - FetcherThread 52 fetching https://github.com/apache/nutch (queue crawl delay=5000ms)
2021-12-20 05:58:57,195 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=8, fetchQueues.getQueueCount=2
2021-12-20 05:58:58,196 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:58:59,197 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:00,198 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:00,702 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-20 05:59:01,200 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-20 05:59:01,450 INFO  fetcher.FetcherThread - FetcherThread 50 fetching https://nutch.apache.org/download (queue crawl delay=5000ms)
2021-12-20 05:59:01,597 INFO  regex.RegexURLNormalizer - can't find rules for scope 'fetcher', using default
2021-12-20 05:59:02,201 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:03,203 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:04,204 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:05,205 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:06,207 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-20 05:59:06,649 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://nutch.apache.org/documentation/ (queue crawl delay=5000ms)
2021-12-20 05:59:07,208 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:08,209 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:09,210 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:10,211 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:11,212 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-20 05:59:11,833 INFO  fetcher.FetcherThread - FetcherThread 54 fetching https://nutch.apache.org/news/ (queue crawl delay=5000ms)
2021-12-20 05:59:12,213 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:13,214 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:14,216 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:15,217 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:16,218 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-20 05:59:17,006 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/index.xml (queue crawl delay=5000ms)
2021-12-20 05:59:17,219 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960157003
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   now           = 1639960157220
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:17,220 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:18,221 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   now           = 1639960158222
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:18,222 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:19,223 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   now           = 1639960159224
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:19,224 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:19,225 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:19,225 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:20,226 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:20,226 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   now           = 1639960160227
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:20,227 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:21,228 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:21,228 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   now           = 1639960161229
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:21,229 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:22,230 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:22,230 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960162594
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   now           = 1639960162231
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/apache/
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:22,231 INFO  fetcher.FetchItemQueue -   3. https://nutch.apache.org/development/
2021-12-20 05:59:22,598 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/apache/ (queue crawl delay=5000ms)
2021-12-20 05:59:23,232 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:23,232 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   now           = 1639960163233
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:23,233 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:24,234 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   now           = 1639960164235
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:24,235 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:25,236 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   now           = 1639960165237
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:25,237 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:26,238 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:26,238 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:26,238 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   now           = 1639960166239
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:26,239 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:27,240 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960167751
2021-12-20 05:59:27,240 INFO  fetcher.FetchItemQueue -   now           = 1639960167240
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:27,241 INFO  fetcher.FetchItemQueue -   2. https://nutch.apache.org/development/
2021-12-20 05:59:27,754 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/img/kube/plus-square.svg (queue crawl delay=5000ms)
2021-12-20 05:59:28,241 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:28,241 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   now           = 1639960168242
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:28,242 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:29,243 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   now           = 1639960169243
2021-12-20 05:59:29,243 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:29,244 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:30,244 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   now           = 1639960170245
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:30,245 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:31,246 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:31,246 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:31,246 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   now           = 1639960171247
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:31,247 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:32,248 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:32,248 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   now           = 1639960172249
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/img/kube/plug.svg
2021-12-20 05:59:32,249 INFO  fetcher.FetchItemQueue -   1. https://nutch.apache.org/development/
2021-12-20 05:59:33,245 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/img/kube/plug.svg (queue crawl delay=5000ms)
2021-12-20 05:59:33,250 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=9, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   inProgress    = 1
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:33,250 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960173240
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   now           = 1639960173251
2021-12-20 05:59:33,251 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:34,252 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:34,252 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:34,253 INFO  fetcher.FetchItemQueue -   now           = 1639960174253
2021-12-20 05:59:34,253 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:35,253 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   now           = 1639960175254
2021-12-20 05:59:35,254 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:36,255 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   now           = 1639960176256
2021-12-20 05:59:36,256 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:37,257 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   now           = 1639960177258
2021-12-20 05:59:37,258 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:38,259 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueues - * queue: nutch.apache.org
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1639960178766
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   now           = 1639960178259
2021-12-20 05:59:38,259 INFO  fetcher.FetchItemQueue -   0. https://nutch.apache.org/development/
2021-12-20 05:59:38,769 INFO  fetcher.FetcherThread - FetcherThread 53 fetching https://nutch.apache.org/development/ (queue crawl delay=5000ms)
2021-12-20 05:59:38,794 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-20 05:59:38,794 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=9
2021-12-20 05:59:38,911 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-20 05:59:38,912 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=8
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=7
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-20 05:59:39,001 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=6
2021-12-20 05:59:39,002 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=5
2021-12-20 05:59:39,005 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-20 05:59:39,006 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=4
2021-12-20 05:59:39,017 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-20 05:59:39,018 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=3
2021-12-20 05:59:39,184 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-20 05:59:39,184 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=2
2021-12-20 05:59:39,212 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-20 05:59:39,212 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=1
2021-12-20 05:59:39,227 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-20 05:59:39,227 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=0
2021-12-20 05:59:39,260 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-20 05:59:39,260 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-20 05:59:39,339 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 05:59:39,743 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 05:59:39,744 INFO  mapreduce.Job - Job job_local231793127_0001 completed successfully
2021-12-20 05:59:39,775 INFO  mapreduce.Job - Counters: 34
	File System Counters
		FILE: Number of bytes read=4147300
		FILE: Number of bytes written=6738068
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=41
		Map output bytes=1125226
		Map output materialized bytes=1125375
		Input split bytes=168
		Combine input records=0
		Combine output records=0
		Reduce input groups=22
		Reduce shuffle bytes=1125375
		Reduce input records=41
		Reduce output records=41
		Spilled Records=82
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=66
		Total committed heap usage (bytes)=321912832
	FetcherStatus
		bytes_downloaded=1100785
		moved=1
		robots_denied=4
		success=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2472
	File Output Format Counters 
		Bytes Written=264937
2021-12-20 05:59:39,775 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-20 05:59:39, elapsed: 00:00:54
2021-12-20 06:00:02,850 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:00:03,386 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-20 06:00:03
2021-12-20 06:00:03,386 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211220055803
2021-12-20 06:00:03,531 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:00:04,991 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:00:04,992 INFO  mapreduce.Job - Running job: job_local1892353904_0001
2021-12-20 06:00:06,008 INFO  mapreduce.Job - Job job_local1892353904_0001 running in uber mode : false
2021-12-20 06:00:06,010 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 06:00:06,391 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-20 06:00:06,419 INFO  parse.ParseSegment - Parsed (537ms): https://cwiki.apache.org/confluence/display/NUTCH/NutchTutorial
2021-12-20 06:00:06,641 INFO  parse.ParseSegment - Parsed (207ms): https://en.wikipedia.org/wiki/Web_crawler
2021-12-20 06:00:06,787 INFO  parse.ParseSegment - Parsed (126ms): https://github.com/apache/nutch
2021-12-20 06:00:06,880 INFO  parse.ParseSegment - Parsed (88ms): https://github.com/jeblister/kube
2021-12-20 06:00:06,902 INFO  parse.ParseSegment - Parsed (19ms): https://hadoop.apache.org/
2021-12-20 06:00:06,916 INFO  parse.ParseSegment - Parsed (11ms): https://nutch.apache.org/apache/
2021-12-20 06:00:06,927 INFO  parse.ParseSegment - Parsed (10ms): https://nutch.apache.org/community/
2021-12-20 06:00:06,936 INFO  parse.ParseSegment - Parsed (8ms): https://nutch.apache.org/development/
2021-12-20 06:00:06,946 INFO  parse.ParseSegment - Parsed (9ms): https://nutch.apache.org/documentation/
2021-12-20 06:00:06,958 INFO  parse.ParseSegment - Parsed (10ms): https://nutch.apache.org/download/
2021-12-20 06:00:06,959 INFO  parse.ParserFactory - The parsing plugins: [org.apache.nutch.parse.tika.TikaParser] are enabled via the plugin.includes system property, and all claim to support the content type image/svg+xml, but they are not mapped to it  in the parse-plugins.xml file
2021-12-20 06:00:07,961 ERROR tika.TikaParser - Problem loading custom Tika configuration from tika-config.xml
java.lang.NumberFormatException: For input string: ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:68)
	at java.base/java.lang.Integer.parseInt(Integer.java:668)
	at java.base/java.lang.Integer.parseInt(Integer.java:776)
	at org.apache.tika.config.TikaConfig.updateXMLReaderUtils(TikaConfig.java:303)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:192)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:182)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:157)
	at org.apache.nutch.parse.tika.TikaParser.setConf(TikaParser.java:274)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:122)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-20 06:00:14,394 INFO  parse.ParseSegment - Parsed (7435ms): https://nutch.apache.org/img/kube/plug.svg
2021-12-20 06:00:14,402 INFO  parse.ParseSegment - Parsed (7ms): https://nutch.apache.org/img/kube/plus-square.svg
2021-12-20 06:00:14,403 WARN  parse.ParserFactory - ParserFactory: Plugin: org.apache.nutch.parse.feed.FeedParser mapped to contentType application/rss+xml via parse-plugins.xml, but not enabled via plugin.includes in nutch-default.xml
2021-12-20 06:00:14,779 INFO  parse.ParseSegment - Parsed (376ms): https://nutch.apache.org/index.xml
2021-12-20 06:00:14,808 INFO  parse.ParseSegment - Parsed (28ms): https://nutch.apache.org/news/
2021-12-20 06:00:14,849 INFO  parse.ParseSegment - Parsed (40ms): https://solr.apache.org/
2021-12-20 06:00:14,878 INFO  parse.ParseSegment - Parsed (28ms): https://tika.apache.org/
2021-12-20 06:00:14,936 INFO  parse.ParseSegment - Parsed (55ms): https://www.elastic.co/elastic-stack/
2021-12-20 06:00:15,029 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:00:15,123 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:00:15,275 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-20 06:00:15,488 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-20 06:00:16,031 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:00:16,032 INFO  mapreduce.Job - Job job_local1892353904_0001 completed successfully
2021-12-20 06:00:16,054 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=3037060
		FILE: Number of bytes written=4203903
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=18
		Map output records=17
		Map output bytes=313087
		Map output materialized bytes=313162
		Input split bytes=166
		Combine input records=0
		Combine output records=0
		Reduce input groups=17
		Reduce shuffle bytes=313162
		Reduce input records=17
		Reduce output records=17
		Spilled Records=34
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=362807296
	ParserStatus
		success=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=259556
	File Output Format Counters 
		Bytes Written=0
2021-12-20 06:00:16,066 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-20 06:00:16, elapsed: 00:00:12
2021-12-20 06:01:14,395 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:01:14,987 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 06:01:14
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055520]
2021-12-20 06:01:14,988 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 06:01:14,989 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 06:01:14,990 INFO  crawl.CrawlDb -  - skipping invalid segment crawl/segments/20211220055520
2021-12-20 06:01:14,990 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 06:01:15,108 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:01:16,428 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:01:16,429 INFO  mapreduce.Job - Running job: job_local203010184_0001
2021-12-20 06:01:16,939 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:01:17,455 INFO  mapreduce.Job - Job job_local203010184_0001 running in uber mode : false
2021-12-20 06:01:17,457 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:01:17,693 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 06:01:17,693 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 06:01:17,694 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 06:01:18,459 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:01:18,461 INFO  mapreduce.Job - Job job_local203010184_0001 completed successfully
2021-12-20 06:01:18,485 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1899984
		FILE: Number of bytes written=3106342
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=23
		Map output bytes=1923
		Map output materialized bytes=1976
		Input split bytes=150
		Combine input records=0
		Combine output records=0
		Reduce input groups=23
		Reduce shuffle bytes=1976
		Reduce input records=23
		Reduce output records=23
		Spilled Records=46
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=408944640
	CrawlDB status
		db_fetched=1
		db_unfetched=22
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2221
	File Output Format Counters 
		Bytes Written=2508
2021-12-20 06:01:18,515 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 06:01:18, elapsed: 00:00:03
2021-12-20 06:01:25,036 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:01:25,711 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-20 06:01:25
2021-12-20 06:01:25,712 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-20 06:01:25,712 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211220055803]
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-20 06:01:25,713 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-20 06:01:25,720 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-20 06:01:25,838 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:01:27,264 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:01:27,265 INFO  mapreduce.Job - Running job: job_local1863148604_0001
2021-12-20 06:01:28,212 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:01:28,275 INFO  mapreduce.Job - Job job_local1863148604_0001 running in uber mode : false
2021-12-20 06:01:28,281 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:01:28,997 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-20 06:01:28,999 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-20 06:01:28,999 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-20 06:01:29,286 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:01:29,288 INFO  mapreduce.Job - Job job_local1863148604_0001 completed successfully
2021-12-20 06:01:29,316 INFO  mapreduce.Job - Counters: 34
	File System Counters
		FILE: Number of bytes read=4231468
		FILE: Number of bytes written=6607229
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=866
		Map output records=866
		Map output bytes=69719
		Map output materialized bytes=71512
		Input split bytes=485
		Combine input records=0
		Combine output records=0
		Reduce input groups=499
		Reduce shuffle bytes=71512
		Reduce input records=866
		Reduce output records=499
		Spilled Records=1732
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=970981376
	CrawlDB status
		db_fetched=18
		db_gone=4
		db_redir_perm=1
		db_unfetched=476
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=77629
	File Output Format Counters 
		Bytes Written=48187
2021-12-20 06:01:29,352 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-20 06:01:29, elapsed: 00:00:03
2021-12-20 06:03:07,895 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-20 06:03:08
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-20 06:03:08,602 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220054847
2021-12-20 06:03:08,605 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520
2021-12-20 06:03:08,606 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615
2021-12-20 06:03:08,608 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055803
2021-12-20 06:03:08,734 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:03:09,333 ERROR crawl.LinkDb - LinkDb job failed: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
2021-12-20 06:03:09,337 ERROR crawl.LinkDb - LinkDb: org.apache.hadoop.mapreduce.lib.input.InvalidInputException: Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055520/parse_data
Input path does not exist: file:/home/dhinesh/Desktop/barat/search/nutch/crawl/segments/20211220055615/parse_data
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.singleThreadedListStatus(FileInputFormat.java:332)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.listStatus(FileInputFormat.java:274)
	at org.apache.hadoop.mapreduce.lib.input.SequenceFileInputFormat.listStatus(SequenceFileInputFormat.java:59)
	at org.apache.hadoop.mapreduce.lib.input.FileInputFormat.getSplits(FileInputFormat.java:396)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeNewSplits(JobSubmitter.java:310)
	at org.apache.hadoop.mapreduce.JobSubmitter.writeSplits(JobSubmitter.java:327)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:200)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.crawl.LinkDb.invert(LinkDb.java:225)
	at org.apache.nutch.crawl.LinkDb.run(LinkDb.java:370)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.LinkDb.main(LinkDb.java:329)

2021-12-20 06:03:58,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-20 06:03:58,565 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20211220055803.
2021-12-20 06:03:58,570 INFO  indexer.IndexingJob - Indexer: starting at 2021-12-20 06:03:58
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2021-12-20 06:03:58,582 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2021-12-20 06:03:58,585 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2021-12-20 06:03:58,590 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20211220055803
2021-12-20 06:03:58,596 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2021-12-20 06:03:58,597 WARN  indexer.IndexerMapReduce - Ignoring linkDb for indexing, no linkDb found in path: crawl/linkdb
2021-12-20 06:03:58,742 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-20 06:04:00,210 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-20 06:04:00,211 INFO  mapreduce.Job - Running job: job_local1480483803_0001
2021-12-20 06:04:01,220 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:01,240 INFO  mapreduce.Job - Job job_local1480483803_0001 running in uber mode : false
2021-12-20 06:04:01,242 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-20 06:04:01,844 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,001 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,205 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,247 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-20 06:04:02,353 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-20 06:04:02,437 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-20 06:04:02,603 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2021-12-20 06:04:02,914 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2021-12-20 06:04:03,672 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a  string  value  ofhttp                            
            one of the following "cloud" or "http". The values represent CloudSolrServer                                
            or HttpSolrServer respectively.                                                                             

url         Defines the fully qualified URL of Solr into which data should  be  indexed.http://localhost:8983/solr/nutch
            Multiple URL can be provided using comma as a delimiter. When the  value  of                                
            type property is cloud, the URL should not include any collections or cores;                                
            just the root Solr path.                                                                                    

collection  The collection used in requests. Only used when the value of  type  property                                
            is cloud.                                                                                                   

commitSize  Defines the number of documents to send to Solr in a  single  update  batch.1000                            
            Decrease when handling very large documents to prevent  Nutch  from  running                                
            out of memory. Note: It does not explicitly trigger a server side commit.                                   

weight.fieldField's name where the weight of the documents will be  written.  If  it  is                                
            empty no field will be used.                                                                                

auth        Whether to enable HTTP basic authentication for communicating with Solr. Usefalse                           
            the username and password properties to configure your credentials.                                         

username    The username of Solr server.                                                username                        

password    The password of Solr server.                                                password                        



2021-12-20 06:04:03,716 INFO  anchor.AnchorIndexingFilter - Anchor deduplication is: off
2021-12-20 06:04:04,402 INFO  solr.SolrIndexWriter - Indexing 17/17 documents
2021-12-20 06:04:04,403 INFO  solr.SolrIndexWriter - Deleting 0 documents
2021-12-20 06:04:06,251 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-20 06:04:06,252 INFO  mapreduce.Job - Job job_local1480483803_0001 completed successfully
2021-12-20 06:04:06,309 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=7390159
		FILE: Number of bytes written=11250468
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1376
		Map output records=1376
		Map output bytes=349714
		Map output materialized bytes=352634
		Input split bytes=823
		Combine input records=0
		Combine output records=0
		Reduce input groups=499
		Reduce shuffle bytes=352634
		Reduce input records=1376
		Reduce output records=17
		Spilled Records=2752
		Shuffled Maps =5
		Failed Shuffles=0
		Merged Map outputs=5
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=1259339776
	IndexerStatus
		indexed (add/update)=17
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=211771
	File Output Format Counters 
		Bytes Written=0
2021-12-20 06:04:06,310 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2021-12-20 06:04:06,336 INFO  indexer.IndexingJob - Indexer:     17  indexed (add/update)
2021-12-20 06:04:06,344 INFO  indexer.IndexingJob - Indexer: finished at 2021-12-20 06:04:06, elapsed: 00:00:07
