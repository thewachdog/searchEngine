2021-12-30 00:04:10,888 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:04:10
2021-12-30 00:04:10,891 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:04:10,892 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:04:10,893 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:04:11,182 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:11,822 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:04:11,952 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:13,387 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:13,388 INFO  mapreduce.Job - Running job: job_local484666709_0001
2021-12-30 00:04:14,409 INFO  mapreduce.Job - Job job_local484666709_0001 running in uber mode : false
2021-12-30 00:04:14,411 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:14,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:04:14,884 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:15,260 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:04:15,263 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:04:15,417 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:15,419 INFO  mapreduce.Job - Job job_local484666709_0001 completed successfully
2021-12-30 00:04:15,488 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2848879
		FILE: Number of bytes written=4659483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=1634
		Map output materialized bytes=1669
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=1669
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=619708416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=2040
2021-12-30 00:04:15,631 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:04:15,635 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:04:15,635 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-30 00:04:15,637 INFO  crawl.Injector - Injector: Total new urls injected: 1
2021-12-30 00:04:15,683 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:04:15, elapsed: 00:00:04
2021-12-30 00:04:17,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:18,371 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:04:18
2021-12-30 00:04:18,374 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:04:18,375 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:04:18,376 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:04:18,397 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:04:18,568 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:20,050 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:20,051 INFO  mapreduce.Job - Running job: job_local928364296_0001
2021-12-30 00:04:21,072 INFO  mapreduce.Job - Job job_local928364296_0001 running in uber mode : false
2021-12-30 00:04:21,074 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:21,324 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:21,327 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:21,337 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:21,512 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:21,782 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:04:22,078 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:22,080 INFO  mapreduce.Job - Job job_local928364296_0001 completed successfully
2021-12-30 00:04:22,112 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1895438
		FILE: Number of bytes written=3108322
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=94
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=94
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=7
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1808
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:04:22,113 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:04:22,137 INFO  crawl.Generator - Generator:      7  SCHEDULE_REJECTED
2021-12-30 00:04:22,140 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:04:23,141 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000423
2021-12-30 00:04:23,162 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:23,655 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:23,655 INFO  mapreduce.Job - Running job: job_local1955071772_0002
2021-12-30 00:04:23,871 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:24,656 INFO  mapreduce.Job - Job job_local1955071772_0002 running in uber mode : false
2021-12-30 00:04:24,656 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:24,657 INFO  mapreduce.Job - Job job_local1955071772_0002 completed successfully
2021-12-30 00:04:24,673 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3788028
		FILE: Number of bytes written=6218266
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=110
		Map output materialized bytes=118
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=118
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=432013312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=214
	File Output Format Counters 
		Bytes Written=184
2021-12-30 00:04:24,692 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:04:24, elapsed: 00:00:06
2021-12-30 00:04:26,585 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:04:26
2021-12-30 00:04:26,588 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000423
2021-12-30 00:04:27,031 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:27,578 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:29,392 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:29,393 INFO  mapreduce.Job - Running job: job_local237098788_0001
2021-12-30 00:04:29,949 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:04:29,950 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:04:30,063 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:04:30,085 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	1	SUCCESSFULLY_QUEUED
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:04:30,426 INFO  mapreduce.Job - Job job_local237098788_0001 running in uber mode : false
2021-12-30 00:04:30,428 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:30,613 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,694 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:30,697 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,698 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:30,705 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,709 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/ (queue crawl delay=5000ms)
2021-12-30 00:04:30,713 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:04:30,714 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,144 INFO  http.Http - http.proxy.host = null
2021-12-30 00:04:31,145 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:04:31,147 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:04:31,148 INFO  http.Http - http.timeout = 10000
2021-12-30 00:04:31,149 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:04:31,150 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:04:31,151 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:04:31,151 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:04:31,151 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:04:31,152 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,161 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,162 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,166 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,173 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:04:31,173 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,188 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,189 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:04:31,189 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,199 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:04:31,199 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,201 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,216 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:04:31,217 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-30 00:04:31,219 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,220 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:04:31,221 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,232 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,233 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:04:31,239 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,252 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:04:31,253 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,253 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,262 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:04:31,262 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:04:31,264 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:04:31,265 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,718 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:04:31,719 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:04:32,265 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:04:32,266 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:04:32,402 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:32,434 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:33,435 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:33,437 INFO  mapreduce.Job - Job job_local237098788_0001 completed successfully
2021-12-30 00:04:33,487 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1916112
		FILE: Number of bytes written=3138405
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=12035
		Map output materialized bytes=12048
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=12048
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=408944640
	FetcherStatus
		bytes_downloaded=11287
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=184
	File Output Format Counters 
		Bytes Written=4957
2021-12-30 00:04:33,493 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:04:33, elapsed: 00:00:06
2021-12-30 00:04:36,255 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:36,804 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:04:36
2021-12-30 00:04:36,806 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000423
2021-12-30 00:04:36,968 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:38,764 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:38,765 INFO  mapreduce.Job - Running job: job_local759744685_0001
2021-12-30 00:04:39,774 INFO  mapreduce.Job - Job job_local759744685_0001 running in uber mode : false
2021-12-30 00:04:39,776 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:40,186 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:04:40,197 INFO  parse.ParseSegment - Parsed (392ms): http://192.168.240.25:5500/
2021-12-30 00:04:40,394 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:40,697 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:40,780 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:40,987 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:04:41,781 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:41,783 INFO  mapreduce.Job - Job job_local759744685_0001 completed successfully
2021-12-30 00:04:41,833 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1907514
		FILE: Number of bytes written=3113209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=3746
		Map output materialized bytes=3756
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=3756
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=490733568
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4168
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:04:41,850 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:04:41, elapsed: 00:00:05
2021-12-30 00:04:44,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:44,648 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:04:44
2021-12-30 00:04:44,650 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:04:44,651 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000423]
2021-12-30 00:04:44,653 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:04:44,655 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:04:44,656 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:04:44,658 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:04:44,665 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:04:44,788 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:46,633 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:46,636 INFO  mapreduce.Job - Running job: job_local937219088_0001
2021-12-30 00:04:47,437 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:47,656 INFO  mapreduce.Job - Job job_local937219088_0001 running in uber mode : false
2021-12-30 00:04:47,658 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:48,280 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:48,287 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:48,287 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:48,660 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:48,661 INFO  mapreduce.Job - Job job_local937219088_0001 completed successfully
2021-12-30 00:04:48,695 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=3802711
		FILE: Number of bytes written=6213487
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=17
		Map output records=17
		Map output bytes=2359
		Map output materialized bytes=2419
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2419
		Reduce input records=17
		Reduce output records=10
		Spilled Records=34
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=823132160
	CrawlDB status
		db_fetched=7
		db_gone=1
		db_unfetched=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2856
	File Output Format Counters 
		Bytes Written=2346
2021-12-30 00:04:48,753 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:04:48, elapsed: 00:00:04
2021-12-30 00:04:51,090 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:51,801 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:04:51
2021-12-30 00:04:51,802 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:04:51,804 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:04:51,805 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:04:51,808 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:04:51,826 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:04:52,001 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:53,718 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:53,720 INFO  mapreduce.Job - Running job: job_local425305859_0001
2021-12-30 00:04:54,744 INFO  mapreduce.Job - Job job_local425305859_0001 running in uber mode : false
2021-12-30 00:04:54,747 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:54,788 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:54,789 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:54,789 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:54,952 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:55,142 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:04:55,751 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:55,752 INFO  mapreduce.Job - Job job_local425305859_0001 completed successfully
2021-12-30 00:04:55,802 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1896274
		FILE: Number of bytes written=3108716
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=2
		Map output bytes=196
		Map output materialized bytes=206
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=206
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=8
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2114
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:04:55,805 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:04:55,836 INFO  crawl.Generator - Generator:      8  SCHEDULE_REJECTED
2021-12-30 00:04:55,842 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:04:56,843 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000456
2021-12-30 00:04:56,869 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:57,344 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:57,345 INFO  mapreduce.Job - Running job: job_local809370763_0002
2021-12-30 00:04:57,702 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:58,347 INFO  mapreduce.Job - Job job_local809370763_0002 running in uber mode : false
2021-12-30 00:04:58,348 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:58,349 INFO  mapreduce.Job - Job job_local809370763_0002 completed successfully
2021-12-30 00:04:58,371 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3789646
		FILE: Number of bytes written=6213590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=268
		Map output materialized bytes=278
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=278
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=332
	File Output Format Counters 
		Bytes Written=294
2021-12-30 00:04:58,406 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:04:58, elapsed: 00:00:06
2021-12-30 00:05:00,660 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:05:00
2021-12-30 00:05:00,662 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000456
2021-12-30 00:05:01,085 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:01,601 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:03,026 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:03,027 INFO  mapreduce.Job - Running job: job_local27251455_0001
2021-12-30 00:05:03,449 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:05:03,450 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:05:03,529 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:05:03,578 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records
2021-12-30 00:05:03,585 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	2	SUCCESSFULLY_QUEUED
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:05:04,052 INFO  mapreduce.Job - Job job_local27251455_0001 running in uber mode : false
2021-12-30 00:05:04,055 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:04,121 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,161 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,164 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,165 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,180 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,184 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,184 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/python.html (queue crawl delay=5000ms)
2021-12-30 00:05:04,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.host = null
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:05:04,494 INFO  http.Http - http.timeout = 10000
2021-12-30 00:05:04,494 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:05:04,494 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:05:04,494 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:05:04,494 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:05:04,494 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:05:04,496 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,498 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,500 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,506 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,521 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,532 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,533 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,539 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,542 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,549 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,553 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:05:04,554 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:05:05,557 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   now           = 1640802905560
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:06,561 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   now           = 1640802906562
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:07,563 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   now           = 1640802907564
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:08,565 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   now           = 1640802908567
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:09,568 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   now           = 1640802909568
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:09,907 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/projects.html (queue crawl delay=5000ms)
2021-12-30 00:05:09,956 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:05:09,957 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=9
2021-12-30 00:05:10,011 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:05:10,011 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=8
2021-12-30 00:05:10,023 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:05:10,023 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:05:10,025 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:05:10,026 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=6
2021-12-30 00:05:10,048 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:05:10,048 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=5
2021-12-30 00:05:10,051 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:05:10,052 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=4
2021-12-30 00:05:10,054 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:05:10,054 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=3
2021-12-30 00:05:10,069 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:05:10,069 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=2
2021-12-30 00:05:10,200 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:05:10,200 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:05:10,202 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:05:10,202 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:05:10,569 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:05:10,570 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:05:10,711 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:11,067 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:11,068 INFO  mapreduce.Job - Job job_local27251455_0001 completed successfully
2021-12-30 00:05:11,101 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1938142
		FILE: Number of bytes written=3169103
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=22932
		Map output materialized bytes=22952
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=22952
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=423624704
	FetcherStatus
		bytes_downloaded=21328
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=294
	File Output Format Counters 
		Bytes Written=8809
2021-12-30 00:05:11,105 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:05:11, elapsed: 00:00:10
2021-12-30 00:05:13,206 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:13,745 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:05:13
2021-12-30 00:05:13,747 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000456
2021-12-30 00:05:13,895 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:15,358 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:15,359 INFO  mapreduce.Job - Running job: job_local1789137285_0001
2021-12-30 00:05:16,383 INFO  mapreduce.Job - Job job_local1789137285_0001 running in uber mode : false
2021-12-30 00:05:16,385 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:16,926 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:05:16,940 INFO  parse.ParseSegment - Parsed (311ms): http://192.168.240.25:5500/projects.html
2021-12-30 00:05:17,002 INFO  parse.ParseSegment - Parsed (56ms): http://192.168.240.25:5500/python.html
2021-12-30 00:05:17,113 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:17,332 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:17,390 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:05:17,708 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:05:18,391 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:18,392 INFO  mapreduce.Job - Job job_local1789137285_0001 completed successfully
2021-12-30 00:05:18,433 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1922226
		FILE: Number of bytes written=3133309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=7488
		Map output materialized bytes=7502
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=7502
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=269484032
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7778
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:05:18,453 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:05:18, elapsed: 00:00:04
2021-12-30 00:05:20,760 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:21,505 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:05:21
2021-12-30 00:05:21,507 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000456]
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:05:21,510 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:05:21,511 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:05:21,515 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:05:21,660 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:23,321 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:23,322 INFO  mapreduce.Job - Running job: job_local183016213_0001
2021-12-30 00:05:24,237 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:24,332 INFO  mapreduce.Job - Job job_local183016213_0001 running in uber mode : false
2021-12-30 00:05:24,337 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:05:25,094 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:05:25,095 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:05:25,095 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:05:25,341 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:25,343 INFO  mapreduce.Job - Job job_local183016213_0001 completed successfully
2021-12-30 00:05:25,379 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=3813538
		FILE: Number of bytes written=6223337
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=38
		Map output records=38
		Map output bytes=4348
		Map output materialized bytes=4452
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4452
		Reduce input records=38
		Reduce output records=24
		Spilled Records=76
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=817889280
	CrawlDB status
		db_fetched=9
		db_gone=1
		db_unfetched=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5002
	File Output Format Counters 
		Bytes Written=3907
2021-12-30 00:05:25,418 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:05:25, elapsed: 00:00:03
2021-12-30 00:05:27,663 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:28,321 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:05:28
2021-12-30 00:05:28,322 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:05:28,322 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:05:28,328 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:05:28,332 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:05:28,347 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:05:28,550 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:30,053 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:30,056 INFO  mapreduce.Job - Running job: job_local636735057_0001
2021-12-30 00:05:31,085 INFO  mapreduce.Job - Job job_local636735057_0001 running in uber mode : false
2021-12-30 00:05:31,087 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:31,276 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:05:31,282 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:05:31,282 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:05:31,486 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:31,769 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:05:32,096 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:32,098 INFO  mapreduce.Job - Job job_local636735057_0001 completed successfully
2021-12-30 00:05:32,142 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1902146
		FILE: Number of bytes written=3114300
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=14
		Map output bytes=1547
		Map output materialized bytes=1581
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1581
		Reduce input records=14
		Reduce output records=0
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3675
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:05:32,142 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:05:32,160 INFO  crawl.Generator - Generator:     10  SCHEDULE_REJECTED
2021-12-30 00:05:32,170 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:05:33,171 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000533
2021-12-30 00:05:33,185 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:33,637 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:33,638 INFO  mapreduce.Job - Running job: job_local1516696440_0002
2021-12-30 00:05:33,869 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:34,638 INFO  mapreduce.Job - Job job_local1516696440_0002 running in uber mode : false
2021-12-30 00:05:34,639 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:34,640 INFO  mapreduce.Job - Job job_local1516696440_0002 completed successfully
2021-12-30 00:05:34,651 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3805150
		FILE: Number of bytes written=6235205
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=2226
		Map output materialized bytes=2260
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=2260
		Reduce input records=14
		Reduce output records=14
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1791
	File Output Format Counters 
		Bytes Written=1657
2021-12-30 00:05:34,679 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:05:34, elapsed: 00:00:06
2021-12-30 00:05:36,851 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:05:36
2021-12-30 00:05:36,855 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:05:37,315 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:37,829 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:39,493 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:39,494 INFO  mapreduce.Job - Running job: job_local1025464847_0001
2021-12-30 00:05:39,980 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:05:39,981 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:05:40,070 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:05:40,143 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 14 records
2021-12-30 00:05:40,147 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:05:40,148 INFO  fetcher.QueueFeeder - 	14	SUCCESSFULLY_QUEUED
2021-12-30 00:05:40,150 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:05:40,154 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:05:40,164 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:05:40,521 INFO  mapreduce.Job - Job job_local1025464847_0001 running in uber mode : false
2021-12-30 00:05:40,523 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:40,768 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,809 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,813 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,818 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,830 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,831 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,836 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,838 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,840 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,843 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,844 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/index.html (queue crawl delay=5000ms)
2021-12-30 00:05:40,846 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,184 INFO  http.Http - http.proxy.host = null
2021-12-30 00:05:41,185 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:05:41,186 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:05:41,187 INFO  http.Http - http.timeout = 10000
2021-12-30 00:05:41,189 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:05:41,190 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:05:41,191 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:05:41,192 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:05:41,192 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:05:41,193 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,202 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,210 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,214 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,215 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,244 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,258 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:05:41,259 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:05:42,261 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:43,262 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:44,263 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:45,264 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:46,266 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:46,607 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/4inputoutput.html (queue crawl delay=5000ms)
2021-12-30 00:05:47,267 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:48,269 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:49,270 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:50,271 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:51,272 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:51,656 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/1datatype.html (queue crawl delay=5000ms)
2021-12-30 00:05:52,273 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:52,540 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-30 00:05:53,275 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:54,276 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:55,277 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:56,281 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:56,696 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/5operators.html (queue crawl delay=5000ms)
2021-12-30 00:05:57,282 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:05:58,284 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:05:59,286 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:00,287 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:01,288 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:01,755 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/3arithmetic.html (queue crawl delay=5000ms)
2021-12-30 00:06:02,289 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:03,290 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:04,292 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:05,292 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:06,294 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:06,796 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/10forloop.html (queue crawl delay=5000ms)
2021-12-30 00:06:07,296 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:08,297 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:09,298 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:10,299 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:11,300 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:11,826 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/8nested.html (queue crawl delay=5000ms)
2021-12-30 00:06:12,302 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:13,303 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:14,304 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:15,305 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:16,306 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:16,861 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/12listtupleoperations.html (queue crawl delay=5000ms)
2021-12-30 00:06:17,308 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:18,309 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:19,310 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:20,312 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:21,313 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:21,895 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/6conditional.html (queue crawl delay=5000ms)
2021-12-30 00:06:22,314 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:23,315 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:24,315 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:25,316 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:26,317 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:26,931 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/media/webscraping.webp (queue crawl delay=5000ms)
2021-12-30 00:06:27,319 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   now           = 1640802987319
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:28,320 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:28,320 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   now           = 1640802988321
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:29,322 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   now           = 1640802989323
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:30,324 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:30,324 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:30,324 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   now           = 1640802990325
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:31,326 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   now           = 1640802991327
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:31,980 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/9whileloop.html (queue crawl delay=5000ms)
2021-12-30 00:06:32,328 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   now           = 1640802992329
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:33,330 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   now           = 1640802993330
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:34,331 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   now           = 1640802994332
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:34,333 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:35,333 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   now           = 1640802995334
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:36,335 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   now           = 1640802996336
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:37,017 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/2variable.html (queue crawl delay=5000ms)
2021-12-30 00:06:37,337 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   now           = 1640802997337
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:37,338 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:38,338 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:38,338 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:38,338 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   now           = 1640802998339
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:39,340 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   now           = 1640802999341
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:40,342 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   now           = 1640803000342
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:40,343 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:41,343 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   now           = 1640803001344
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:42,040 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/11listtuples.html (queue crawl delay=5000ms)
2021-12-30 00:06:42,345 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   now           = 1640803002346
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:43,346 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   now           = 1640803003347
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:44,348 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:44,348 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:44,348 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   now           = 1640803004349
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:45,350 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   now           = 1640803005350
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:46,351 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   now           = 1640803006352
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:47,082 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/7comments.html (queue crawl delay=5000ms)
2021-12-30 00:06:47,109 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:06:47,109 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=9
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:06:47,278 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:06:47,278 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=6
2021-12-30 00:06:47,282 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:06:47,282 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=5
2021-12-30 00:06:47,300 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:06:47,300 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=4
2021-12-30 00:06:47,353 INFO  fetcher.Fetcher - -activeThreads=4, spinWaiting=4, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:06:47,368 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:06:47,368 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=3
2021-12-30 00:06:47,385 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:06:47,385 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:06:47,386 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:06:47,387 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:47,388 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:47,388 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:48,354 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:06:48,354 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:06:48,452 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:06:48,600 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:06:49,601 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:06:49,603 INFO  mapreduce.Job - Job job_local1025464847_0001 completed successfully
2021-12-30 00:06:49,633 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2393672
		FILE: Number of bytes written=4001547
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=28
		Map output bytes=249249
		Map output materialized bytes=249354
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=249354
		Reduce input records=28
		Reduce output records=28
		Spilled Records=56
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=423624704
	FetcherStatus
		bytes_downloaded=237313
		success=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1657
	File Output Format Counters 
		Bytes Written=150319
2021-12-30 00:06:49,635 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:06:49, elapsed: 00:01:12
2021-12-30 00:06:52,212 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:06:52,742 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:06:52
2021-12-30 00:06:52,743 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000533
2021-12-30 00:06:52,904 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:06:55,285 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:06:55,286 INFO  mapreduce.Job - Running job: job_local36374451_0001
2021-12-30 00:06:56,317 INFO  mapreduce.Job - Job job_local36374451_0001 running in uber mode : false
2021-12-30 00:06:56,319 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:06:56,695 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:06:56,709 INFO  parse.ParseSegment - Parsed (301ms): http://192.168.240.25:5500/index.html
2021-12-30 00:06:56,722 INFO  parse.ParserFactory - The parsing plugins: [org.apache.nutch.parse.tika.TikaParser] are enabled via the plugin.includes system property, and all claim to support the content type image/webp, but they are not mapped to it  in the parse-plugins.xml file
2021-12-30 00:06:58,467 ERROR tika.TikaParser - Problem loading custom Tika configuration from tika-config.xml
java.lang.NumberFormatException: For input string: ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:68)
	at java.base/java.lang.Integer.parseInt(Integer.java:668)
	at java.base/java.lang.Integer.parseInt(Integer.java:776)
	at org.apache.tika.config.TikaConfig.updateXMLReaderUtils(TikaConfig.java:303)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:192)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:182)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:157)
	at org.apache.nutch.parse.tika.TikaParser.setConf(TikaParser.java:274)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:122)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-30 00:07:05,441 INFO  parse.ParseSegment - Parsed (8719ms): http://192.168.240.25:5500/media/webscraping.webp
2021-12-30 00:07:05,491 INFO  parse.ParseSegment - Parsed (46ms): http://192.168.240.25:5500/pythontut/10forloop.html
2021-12-30 00:07:05,519 INFO  parse.ParseSegment - Parsed (26ms): http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:07:05,578 INFO  parse.ParseSegment - Parsed (58ms): http://192.168.240.25:5500/pythontut/12listtupleoperations.html
2021-12-30 00:07:05,600 INFO  parse.ParseSegment - Parsed (20ms): http://192.168.240.25:5500/pythontut/1datatype.html
2021-12-30 00:07:05,633 INFO  parse.ParseSegment - Parsed (32ms): http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:07:05,652 INFO  parse.ParseSegment - Parsed (17ms): http://192.168.240.25:5500/pythontut/3arithmetic.html
2021-12-30 00:07:05,675 INFO  parse.ParseSegment - Parsed (22ms): http://192.168.240.25:5500/pythontut/4inputoutput.html
2021-12-30 00:07:05,690 INFO  parse.ParseSegment - Parsed (13ms): http://192.168.240.25:5500/pythontut/5operators.html
2021-12-30 00:07:05,709 INFO  parse.ParseSegment - Parsed (18ms): http://192.168.240.25:5500/pythontut/6conditional.html
2021-12-30 00:07:05,724 INFO  parse.ParseSegment - Parsed (13ms): http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:07:05,746 INFO  parse.ParseSegment - Parsed (21ms): http://192.168.240.25:5500/pythontut/8nested.html
2021-12-30 00:07:05,783 INFO  parse.ParseSegment - Parsed (36ms): http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:07:05,919 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:06,112 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:07:06,297 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:07:06,332 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:07,333 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:07,335 INFO  mapreduce.Job - Job job_local36374451_0001 completed successfully
2021-12-30 00:07:07,352 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2289122
		FILE: Number of bytes written=3277651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=51956
		Map output materialized bytes=52018
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=52018
		Reduce input records=14
		Reduce output records=14
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		Total committed heap usage (bytes)=318767104
	ParserStatus
		success=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146709
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:07:07,367 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:07:07, elapsed: 00:00:14
2021-12-30 00:07:09,305 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:09,919 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:07:09
2021-12-30 00:07:09,920 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:07:09,920 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000533]
2021-12-30 00:07:09,921 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:07:09,928 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:07:10,050 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:11,469 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:11,470 INFO  mapreduce.Job - Running job: job_local1137037029_0001
2021-12-30 00:07:12,274 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:12,495 INFO  mapreduce.Job - Job job_local1137037029_0001 running in uber mode : false
2021-12-30 00:07:12,497 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:13,001 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:07:13,002 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:07:13,002 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:07:13,499 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:13,500 INFO  mapreduce.Job - Job job_local1137037029_0001 completed successfully
2021-12-30 00:07:13,545 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3858479
		FILE: Number of bytes written=6272555
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=119
		Map output records=119
		Map output bytes=12672
		Map output materialized bytes=12952
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=12952
		Reduce input records=119
		Reduce output records=24
		Spilled Records=238
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=960495616
	CrawlDB status
		db_fetched=23
		db_gone=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=13670
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:07:13,574 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:07:13, elapsed: 00:00:03
2021-12-30 00:07:16,507 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:07:17
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:07:17,550 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:07:17,551 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:07:17,551 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:07:17,552 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:07:17,553 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:07:17,706 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:20,126 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:20,130 INFO  mapreduce.Job - Running job: job_local377853345_0001
2021-12-30 00:07:21,184 INFO  mapreduce.Job - Job job_local377853345_0001 running in uber mode : false
2021-12-30 00:07:21,188 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:21,928 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:23,193 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:23,194 INFO  mapreduce.Job - Job job_local377853345_0001 completed successfully
2021-12-30 00:07:23,313 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10863834
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=41
		Total committed heap usage (bytes)=1460666368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:07:23,314 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:07:23,371 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:24,756 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:24,757 INFO  mapreduce.Job - Running job: job_local468564376_0002
2021-12-30 00:07:25,761 INFO  mapreduce.Job - Job job_local468564376_0002 running in uber mode : false
2021-12-30 00:07:25,761 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:07:27,046 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:27,764 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:27,766 INFO  mapreduce.Job - Job job_local468564376_0002 completed successfully
2021-12-30 00:07:27,803 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5742064
		FILE: Number of bytes written=9307972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=344
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=751828992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:07:27,887 INFO  crawl.LinkDb - LinkDb: finished at 2021-12-30 00:07:27, elapsed: 00:00:10
2021-12-30 00:07:33,067 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:33,812 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20211230000533.
2021-12-30 00:07:33,819 INFO  indexer.IndexingJob - Indexer: starting at 2021-12-30 00:07:33
2021-12-30 00:07:33,835 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2021-12-30 00:07:33,837 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2021-12-30 00:07:33,838 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2021-12-30 00:07:33,846 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2021-12-30 00:07:33,852 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20211230000533
2021-12-30 00:07:33,857 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2021-12-30 00:07:34,052 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:36,270 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:36,272 INFO  mapreduce.Job - Running job: job_local390450797_0001
2021-12-30 00:07:37,295 INFO  mapreduce.Job - Job job_local390450797_0001 running in uber mode : false
2021-12-30 00:07:37,297 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:07:37,511 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:37,756 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:37,948 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,136 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,276 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,303 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-30 00:07:38,460 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:38,620 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2021-12-30 00:07:39,106 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2021-12-30 00:07:39,305 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:40,142 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:

type        Specifies the SolrClient implementation to use. This is a  string  value  ofhttp                            
            one of the following "cloud" or "http". The values represent CloudSolrServer                                
            or HttpSolrServer respectively.                                                                             

url         Defines the fully qualified URL of Solr into which data should  be  indexed.http://localhost:8983/solr/nutch
            Multiple URL can be provided using comma as a delimiter. When the  value  of                                
            type property is cloud, the URL should not include any collections or cores;                                
            just the root Solr path.                                                                                    

collection  The collection used in requests. Only used when the value of  type  property                                
            is cloud.                                                                                                   

commitSize  Defines the number of documents to send to Solr in a  single  update  batch.1000                            
            Decrease when handling very large documents to prevent  Nutch  from  running                                
            out of memory. Note: It does not explicitly trigger a server side commit.                                   

weight.fieldField's name where the weight of the documents will be  written.  If  it  is                                
            empty no field will be used.                                                                                

auth        Whether to enable HTTP basic authentication for communicating with Solr. Usefalse                           
            the username and password properties to configure your credentials.                                         

username    The username of Solr server.                                                username                        

password    The password of Solr server.                                                password                        



2021-12-30 00:07:40,209 INFO  anchor.AnchorIndexingFilter - Anchor deduplication is: off
2021-12-30 00:07:40,391 INFO  solr.SolrIndexWriter - Indexing 14/14 documents
2021-12-30 00:07:40,397 INFO  solr.SolrIndexWriter - Deleting 0 documents
2021-12-30 00:07:41,328 WARN  mapred.LocalJobRunner - job_local390450797_0001
java.lang.Exception: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/nutch: Expected mime type application/octet-stream but got text/html. <html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<title>Error 404 Not Found</title>
</head>
<body><h2>HTTP ERROR 404 Not Found</h2>
<table>
<tr><th>URI:</th><td>/solr/nutch/update</td></tr>
<tr><th>STATUS:</th><td>404</td></tr>
<tr><th>MESSAGE:</th><td>Not Found</td></tr>
<tr><th>SERVLET:</th><td>default</td></tr>
</table>

</body>
</html>

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/nutch: Expected mime type application/octet-stream but got text/html. <html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<title>Error 404 Not Found</title>
</head>
<body><h2>HTTP ERROR 404 Not Found</h2>
<table>
<tr><th>URI:</th><td>/solr/nutch/update</td></tr>
<tr><th>STATUS:</th><td>404</td></tr>
<tr><th>MESSAGE:</th><td>Not Found</td></tr>
<tr><th>SERVLET:</th><td>default</td></tr>
</table>

</body>
</html>

	at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:629)
	at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:265)
	at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248)
	at org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1290)
	at org.apache.nutch.indexwriter.solr.SolrIndexWriter.push(SolrIndexWriter.java:249)
	at org.apache.nutch.indexwriter.solr.SolrIndexWriter.commit(SolrIndexWriter.java:218)
	at org.apache.nutch.indexer.IndexWriters.commit(IndexWriters.java:264)
	at org.apache.nutch.indexer.IndexerOutputFormat$1.close(IndexerOutputFormat.java:54)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:551)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:630)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-30 00:07:42,308 INFO  mapreduce.Job - Job job_local390450797_0001 failed with state FAILED due to: NA
2021-12-30 00:07:42,381 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5862301
		FILE: Number of bytes written=9591996
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=147
		Map output records=147
		Map output bytes=54073
		Map output materialized bytes=54495
		Input split bytes=1104
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=54495
		Reduce input records=0
		Reduce output records=0
		Spilled Records=147
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=53
		Total committed heap usage (bytes)=1298137088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=36801
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:07:42,385 ERROR indexer.IndexingJob - Indexing job did not succeed, job status:FAILED, reason: NA
2021-12-30 00:07:42,389 ERROR indexer.IndexingJob - Indexer: java.lang.RuntimeException: Indexing job did not succeed, job status:FAILED, reason: NA
	at org.apache.nutch.indexer.IndexingJob.index(IndexingJob.java:150)
	at org.apache.nutch.indexer.IndexingJob.run(IndexingJob.java:291)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.indexer.IndexingJob.main(IndexingJob.java:300)

2021-12-30 00:20:40,503 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:20:40
2021-12-30 00:20:40,506 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:20:40,507 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:20:40,509 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:20:40,804 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:41,433 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:20:41,566 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:42,944 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:42,947 INFO  mapreduce.Job - Running job: job_local1953095821_0001
2021-12-30 00:20:43,973 INFO  mapreduce.Job - Job job_local1953095821_0001 running in uber mode : false
2021-12-30 00:20:43,976 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:44,135 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:20:44,234 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:20:44,516 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:20:44,518 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:20:44,993 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:20:44,995 INFO  mapreduce.Job - Job job_local1953095821_0001 completed successfully
2021-12-30 00:20:45,015 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2868750
		FILE: Number of bytes written=4687881
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=5487
		Map output materialized bytes=5573
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5573
		Reduce input records=25
		Reduce output records=24
		Spilled Records=50
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=623902720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
		urls_merged=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:20:45,095 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:20:45,096 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:20:45,098 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 1
2021-12-30 00:20:45,099 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-30 00:20:45,116 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:20:45, elapsed: 00:00:04
2021-12-30 00:20:47,092 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:47,660 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:20:47
2021-12-30 00:20:47,662 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:20:47,663 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:20:47,664 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:20:47,682 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:20:47,824 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:49,233 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:49,235 INFO  mapreduce.Job - Running job: job_local906574406_0001
2021-12-30 00:20:50,163 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:20:50,167 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:20:50,168 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:20:50,244 INFO  mapreduce.Job - Job job_local906574406_0001 running in uber mode : false
2021-12-30 00:20:50,246 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:50,323 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:20:51,251 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:20:51,254 INFO  mapreduce.Job - Job job_local906574406_0001 completed successfully
2021-12-30 00:20:51,284 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:20:51,284 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:20:51,300 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:20:51,309 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:20:53,070 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:20:53
2021-12-30 00:20:53,072 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:20:53,434 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:53,972 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:54,295 ERROR fetcher.Fetcher - Fetcher: java.io.IOException: Segment already fetched!
	at org.apache.nutch.fetcher.FetcherOutputFormat.checkOutputSpecs(FetcherOutputFormat.java:55)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.fetcher.Fetcher.fetch(Fetcher.java:498)
	at org.apache.nutch.fetcher.Fetcher.run(Fetcher.java:545)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.fetcher.Fetcher.main(Fetcher.java:518)

2021-12-30 00:20:56,253 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:56,877 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:20:56
2021-12-30 00:20:56,879 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:20:56,880 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:20:56,881 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:20:56,885 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:20:56,905 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:20:57,072 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:58,427 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:58,428 INFO  mapreduce.Job - Running job: job_local801910902_0001
2021-12-30 00:20:59,432 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:20:59,433 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:20:59,434 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:20:59,441 INFO  mapreduce.Job - Job job_local801910902_0001 running in uber mode : false
2021-12-30 00:20:59,443 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:59,610 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:00,445 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:00,447 INFO  mapreduce.Job - Job job_local801910902_0001 completed successfully
2021-12-30 00:21:00,470 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:21:00,472 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:21:00,479 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:21:00,498 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:21:02,381 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:21:02,951 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:21:02
2021-12-30 00:21:02,953 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:21:02,955 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:21:02,957 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:21:02,967 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:21:02,990 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:21:03,157 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:21:04,557 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:04,558 INFO  mapreduce.Job - Running job: job_local253976520_0001
2021-12-30 00:21:05,530 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:21:05,531 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:21:05,531 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:21:05,585 INFO  mapreduce.Job - Job job_local253976520_0001 running in uber mode : false
2021-12-30 00:21:05,586 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:21:05,722 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:06,591 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:06,592 INFO  mapreduce.Job - Job job_local253976520_0001 completed successfully
2021-12-30 00:21:06,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:21:06,624 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:21:06,646 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:21:06,663 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:21:08,600 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:21:09,231 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:21:09
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:21:09,240 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:21:09,241 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:21:09,242 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:21:09,245 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:21:09,246 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:21:09,378 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:21:10,896 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:10,897 INFO  mapreduce.Job - Running job: job_local8254689_0001
2021-12-30 00:21:11,906 INFO  mapreduce.Job - Job job_local8254689_0001 running in uber mode : false
2021-12-30 00:21:11,912 INFO  mapreduce.Job -  map 83% reduce 0%
2021-12-30 00:21:11,947 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:12,922 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:12,923 INFO  mapreduce.Job - Job job_local8254689_0001 completed successfully
2021-12-30 00:21:12,949 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10822730
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=1549795328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:21:12,951 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:21:12,961 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:13,347 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:13,347 INFO  mapreduce.Job - Running job: job_local330131418_0002
2021-12-30 00:21:14,111 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:14,348 INFO  mapreduce.Job - Job job_local330131418_0002 running in uber mode : false
2021-12-30 00:21:14,348 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:14,349 INFO  mapreduce.Job - Job job_local330131418_0002 completed successfully
2021-12-30 00:21:14,357 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5742064
		FILE: Number of bytes written=9290356
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=344
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=754974720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:21:14,407 INFO  crawl.LinkDb - LinkDb: finished at 2021-12-30 00:21:14, elapsed: 00:00:05
2021-12-30 00:31:32,108 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:31:32
2021-12-30 00:31:32,121 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:31:32,123 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:31:32,124 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:31:32,522 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:33,423 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:31:33,573 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:35,134 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:35,135 INFO  mapreduce.Job - Running job: job_local253266142_0001
2021-12-30 00:31:36,161 INFO  mapreduce.Job - Job job_local253266142_0001 running in uber mode : false
2021-12-30 00:31:36,178 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:31:36,764 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:31:36,839 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:31:37,101 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:31:37,101 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:31:37,188 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:31:37,189 INFO  mapreduce.Job - Job job_local253266142_0001 completed successfully
2021-12-30 00:31:37,227 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2868750
		FILE: Number of bytes written=4679061
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=5487
		Map output materialized bytes=5573
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5573
		Reduce input records=25
		Reduce output records=24
		Spilled Records=50
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=745537536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
		urls_merged=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:31:37,298 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:31:37,299 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:31:37,300 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 1
2021-12-30 00:31:37,301 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-30 00:31:37,321 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:31:37, elapsed: 00:00:05
2021-12-30 00:31:39,344 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:31:39
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:31:39,894 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:31:40,057 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:41,375 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:41,376 INFO  mapreduce.Job - Running job: job_local279330765_0001
2021-12-30 00:31:42,387 INFO  mapreduce.Job - Job job_local279330765_0001 running in uber mode : false
2021-12-30 00:31:42,389 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:31:42,468 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:31:42,470 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:31:42,470 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:31:42,692 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:31:43,395 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:31:43,396 INFO  mapreduce.Job - Job job_local279330765_0001 completed successfully
2021-12-30 00:31:43,429 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:31:43,431 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:31:43,439 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:31:43,459 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:31:45,857 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:31:45
2021-12-30 00:31:45,858 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:31:46,359 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:47,071 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:47,441 ERROR fetcher.Fetcher - Fetcher: java.io.IOException: Segment already fetched!
	at org.apache.nutch.fetcher.FetcherOutputFormat.checkOutputSpecs(FetcherOutputFormat.java:55)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.fetcher.Fetcher.fetch(Fetcher.java:498)
	at org.apache.nutch.fetcher.Fetcher.run(Fetcher.java:545)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.fetcher.Fetcher.main(Fetcher.java:518)

2021-12-30 00:31:49,698 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:50,258 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:31:50
2021-12-30 00:31:50,260 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:31:50,261 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:31:50,262 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:31:50,265 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:31:50,287 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:31:50,443 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:52,065 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:52,067 INFO  mapreduce.Job - Running job: job_local1147790014_0001
2021-12-30 00:31:55,033 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:55,650 ERROR crawl.Generator - Generator: java.io.IOException: lock file crawl/crawldb/.locked already exists.
	at org.apache.nutch.util.LockUtil.createLockFile(LockUtil.java:50)
	at org.apache.nutch.util.LockUtil.createLockFile(LockUtil.java:80)
	at org.apache.nutch.crawl.CrawlDb.lock(CrawlDb.java:194)
	at org.apache.nutch.crawl.Generator.generate(Generator.java:760)
	at org.apache.nutch.crawl.Generator.run(Generator.java:1051)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.Generator.main(Generator.java:998)

2021-12-30 00:31:57,660 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:58,305 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:31:58
2021-12-30 00:31:58,307 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:31:58,308 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:31:58,310 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:31:58,311 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:31:58,313 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:31:58,317 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:31:58,319 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:31:58,324 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:31:58,324 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:31:58,327 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:31:58,451 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:59,921 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:59,922 INFO  mapreduce.Job - Running job: job_local1292122582_0001
2021-12-30 00:32:00,949 INFO  mapreduce.Job - Job job_local1292122582_0001 running in uber mode : false
2021-12-30 00:32:00,957 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:32:01,048 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:32:01,963 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:32:01,965 INFO  mapreduce.Job - Job job_local1292122582_0001 completed successfully
2021-12-30 00:32:01,998 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10884414
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=1586495488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:32:02,000 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:32:02,010 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:32:02,423 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:32:02,423 INFO  mapreduce.Job - Running job: job_local1535484144_0002
