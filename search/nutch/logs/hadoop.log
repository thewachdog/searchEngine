2021-12-30 00:04:10,888 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:04:10
2021-12-30 00:04:10,891 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:04:10,892 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:04:10,893 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:04:11,182 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:11,822 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:04:11,952 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:13,387 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:13,388 INFO  mapreduce.Job - Running job: job_local484666709_0001
2021-12-30 00:04:14,409 INFO  mapreduce.Job - Job job_local484666709_0001 running in uber mode : false
2021-12-30 00:04:14,411 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:14,775 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:04:14,884 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:15,260 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:04:15,263 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:04:15,417 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:15,419 INFO  mapreduce.Job - Job job_local484666709_0001 completed successfully
2021-12-30 00:04:15,488 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2848879
		FILE: Number of bytes written=4659483
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=8
		Map output bytes=1634
		Map output materialized bytes=1669
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=8
		Reduce shuffle bytes=1669
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=619708416
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=2040
2021-12-30 00:04:15,631 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:04:15,635 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:04:15,635 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-30 00:04:15,637 INFO  crawl.Injector - Injector: Total new urls injected: 1
2021-12-30 00:04:15,683 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:04:15, elapsed: 00:00:04
2021-12-30 00:04:17,810 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:18,371 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:04:18
2021-12-30 00:04:18,374 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:04:18,375 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:04:18,376 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:04:18,397 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:04:18,568 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:20,050 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:20,051 INFO  mapreduce.Job - Running job: job_local928364296_0001
2021-12-30 00:04:21,072 INFO  mapreduce.Job - Job job_local928364296_0001 running in uber mode : false
2021-12-30 00:04:21,074 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:21,324 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:21,327 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:21,337 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:21,512 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:21,782 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:04:22,078 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:22,080 INFO  mapreduce.Job - Job job_local928364296_0001 completed successfully
2021-12-30 00:04:22,112 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1895438
		FILE: Number of bytes written=3108322
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=8
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=94
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=94
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=7
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1808
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:04:22,113 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:04:22,137 INFO  crawl.Generator - Generator:      7  SCHEDULE_REJECTED
2021-12-30 00:04:22,140 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:04:23,141 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000423
2021-12-30 00:04:23,162 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:23,655 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:23,655 INFO  mapreduce.Job - Running job: job_local1955071772_0002
2021-12-30 00:04:23,871 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:24,656 INFO  mapreduce.Job - Job job_local1955071772_0002 running in uber mode : false
2021-12-30 00:04:24,656 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:24,657 INFO  mapreduce.Job - Job job_local1955071772_0002 completed successfully
2021-12-30 00:04:24,673 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3788028
		FILE: Number of bytes written=6218266
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=110
		Map output materialized bytes=118
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=118
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=432013312
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=214
	File Output Format Counters 
		Bytes Written=184
2021-12-30 00:04:24,692 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:04:24, elapsed: 00:00:06
2021-12-30 00:04:26,585 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:04:26
2021-12-30 00:04:26,588 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000423
2021-12-30 00:04:27,031 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:27,578 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:29,392 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:29,393 INFO  mapreduce.Job - Running job: job_local237098788_0001
2021-12-30 00:04:29,949 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:04:29,950 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:04:30,063 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:04:30,085 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	1	SUCCESSFULLY_QUEUED
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:04:30,091 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:04:30,426 INFO  mapreduce.Job - Job job_local237098788_0001 running in uber mode : false
2021-12-30 00:04:30,428 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:30,613 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,694 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:30,697 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,698 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:30,705 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:30,709 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/ (queue crawl delay=5000ms)
2021-12-30 00:04:30,713 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:04:30,714 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,144 INFO  http.Http - http.proxy.host = null
2021-12-30 00:04:31,145 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:04:31,147 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:04:31,148 INFO  http.Http - http.timeout = 10000
2021-12-30 00:04:31,149 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:04:31,150 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:04:31,151 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:04:31,151 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:04:31,151 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:04:31,152 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,161 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,162 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,165 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,166 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,173 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:04:31,173 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,188 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,189 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:04:31,189 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,194 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,199 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:04:31,199 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,201 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,216 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:04:31,217 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-30 00:04:31,219 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,220 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:04:31,221 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,227 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,232 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,233 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:04:31,239 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,246 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:31,252 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:04:31,253 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,253 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:04:31,262 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:04:31,262 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:04:31,264 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:04:31,265 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:04:31,718 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:04:31,719 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:04:32,265 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:04:32,266 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:04:32,402 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:32,434 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:33,435 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:33,437 INFO  mapreduce.Job - Job job_local237098788_0001 completed successfully
2021-12-30 00:04:33,487 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1916112
		FILE: Number of bytes written=3138405
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=12035
		Map output materialized bytes=12048
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=12048
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=13
		Total committed heap usage (bytes)=408944640
	FetcherStatus
		bytes_downloaded=11287
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=184
	File Output Format Counters 
		Bytes Written=4957
2021-12-30 00:04:33,493 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:04:33, elapsed: 00:00:06
2021-12-30 00:04:36,255 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:36,804 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:04:36
2021-12-30 00:04:36,806 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000423
2021-12-30 00:04:36,968 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:38,764 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:38,765 INFO  mapreduce.Job - Running job: job_local759744685_0001
2021-12-30 00:04:39,774 INFO  mapreduce.Job - Job job_local759744685_0001 running in uber mode : false
2021-12-30 00:04:39,776 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:40,186 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:04:40,197 INFO  parse.ParseSegment - Parsed (392ms): http://192.168.240.25:5500/
2021-12-30 00:04:40,394 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:40,697 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:04:40,780 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:40,987 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:04:41,781 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:41,783 INFO  mapreduce.Job - Job job_local759744685_0001 completed successfully
2021-12-30 00:04:41,833 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1907514
		FILE: Number of bytes written=3113209
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=3746
		Map output materialized bytes=3756
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=3756
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=490733568
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4168
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:04:41,850 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:04:41, elapsed: 00:00:05
2021-12-30 00:04:44,001 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:44,648 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:04:44
2021-12-30 00:04:44,650 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:04:44,651 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000423]
2021-12-30 00:04:44,653 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:04:44,655 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:04:44,656 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:04:44,658 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:04:44,665 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:04:44,788 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:46,633 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:46,636 INFO  mapreduce.Job - Running job: job_local937219088_0001
2021-12-30 00:04:47,437 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:47,656 INFO  mapreduce.Job - Job job_local937219088_0001 running in uber mode : false
2021-12-30 00:04:47,658 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:04:48,280 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:48,287 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:48,287 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:48,660 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:48,661 INFO  mapreduce.Job - Job job_local937219088_0001 completed successfully
2021-12-30 00:04:48,695 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=3802711
		FILE: Number of bytes written=6213487
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=17
		Map output records=17
		Map output bytes=2359
		Map output materialized bytes=2419
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=10
		Reduce shuffle bytes=2419
		Reduce input records=17
		Reduce output records=10
		Spilled Records=34
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=33
		Total committed heap usage (bytes)=823132160
	CrawlDB status
		db_fetched=7
		db_gone=1
		db_unfetched=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2856
	File Output Format Counters 
		Bytes Written=2346
2021-12-30 00:04:48,753 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:04:48, elapsed: 00:00:04
2021-12-30 00:04:51,090 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:04:51,801 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:04:51
2021-12-30 00:04:51,802 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:04:51,804 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:04:51,805 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:04:51,808 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:04:51,826 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:04:52,001 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:04:53,718 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:53,720 INFO  mapreduce.Job - Running job: job_local425305859_0001
2021-12-30 00:04:54,744 INFO  mapreduce.Job - Job job_local425305859_0001 running in uber mode : false
2021-12-30 00:04:54,747 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:04:54,788 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:04:54,789 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:04:54,789 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:04:54,952 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:55,142 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:04:55,751 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:55,752 INFO  mapreduce.Job - Job job_local425305859_0001 completed successfully
2021-12-30 00:04:55,802 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1896274
		FILE: Number of bytes written=3108716
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=10
		Map output records=2
		Map output bytes=196
		Map output materialized bytes=206
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=206
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=8
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2114
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:04:55,805 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:04:55,836 INFO  crawl.Generator - Generator:      8  SCHEDULE_REJECTED
2021-12-30 00:04:55,842 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:04:56,843 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000456
2021-12-30 00:04:56,869 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:57,344 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:04:57,345 INFO  mapreduce.Job - Running job: job_local809370763_0002
2021-12-30 00:04:57,702 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:04:58,347 INFO  mapreduce.Job - Job job_local809370763_0002 running in uber mode : false
2021-12-30 00:04:58,348 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:04:58,349 INFO  mapreduce.Job - Job job_local809370763_0002 completed successfully
2021-12-30 00:04:58,371 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3789646
		FILE: Number of bytes written=6213590
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=268
		Map output materialized bytes=278
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=278
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=332
	File Output Format Counters 
		Bytes Written=294
2021-12-30 00:04:58,406 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:04:58, elapsed: 00:00:06
2021-12-30 00:05:00,660 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:05:00
2021-12-30 00:05:00,662 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000456
2021-12-30 00:05:01,085 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:01,601 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:03,026 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:03,027 INFO  mapreduce.Job - Running job: job_local27251455_0001
2021-12-30 00:05:03,449 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:05:03,450 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:05:03,529 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:05:03,578 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records
2021-12-30 00:05:03,585 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	2	SUCCESSFULLY_QUEUED
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:05:03,587 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:05:04,052 INFO  mapreduce.Job - Job job_local27251455_0001 running in uber mode : false
2021-12-30 00:05:04,055 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:04,121 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,161 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,164 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,165 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,180 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,184 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,184 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/python.html (queue crawl delay=5000ms)
2021-12-30 00:05:04,187 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.host = null
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:05:04,494 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:05:04,494 INFO  http.Http - http.timeout = 10000
2021-12-30 00:05:04,494 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:05:04,494 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:05:04,494 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:05:04,494 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:05:04,494 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:05:04,496 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,498 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,500 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,505 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,506 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,520 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,521 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,532 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,533 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,539 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,542 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:04,549 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:04,553 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:05:04,554 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:05:05,557 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:05,559 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   now           = 1640802905560
2021-12-30 00:05:05,560 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:06,561 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   now           = 1640802906562
2021-12-30 00:05:06,562 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:07,563 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   now           = 1640802907564
2021-12-30 00:05:07,564 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:08,565 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:08,566 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   now           = 1640802908567
2021-12-30 00:05:08,567 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:09,568 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802909889
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   now           = 1640802909568
2021-12-30 00:05:09,568 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/projects.html
2021-12-30 00:05:09,907 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/projects.html (queue crawl delay=5000ms)
2021-12-30 00:05:09,956 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:05:09,957 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=9
2021-12-30 00:05:10,011 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:05:10,011 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=8
2021-12-30 00:05:10,023 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:05:10,023 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:05:10,025 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:05:10,026 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=6
2021-12-30 00:05:10,048 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:05:10,048 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=5
2021-12-30 00:05:10,051 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:05:10,052 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=4
2021-12-30 00:05:10,054 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:05:10,054 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=3
2021-12-30 00:05:10,069 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:05:10,069 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=2
2021-12-30 00:05:10,200 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:05:10,200 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=1
2021-12-30 00:05:10,202 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:05:10,202 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:05:10,569 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:05:10,570 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:05:10,711 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:11,067 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:11,068 INFO  mapreduce.Job - Job job_local27251455_0001 completed successfully
2021-12-30 00:05:11,101 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1938142
		FILE: Number of bytes written=3169103
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=4
		Map output bytes=22932
		Map output materialized bytes=22952
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=22952
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=29
		Total committed heap usage (bytes)=423624704
	FetcherStatus
		bytes_downloaded=21328
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=294
	File Output Format Counters 
		Bytes Written=8809
2021-12-30 00:05:11,105 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:05:11, elapsed: 00:00:10
2021-12-30 00:05:13,206 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:13,745 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:05:13
2021-12-30 00:05:13,747 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000456
2021-12-30 00:05:13,895 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:15,358 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:15,359 INFO  mapreduce.Job - Running job: job_local1789137285_0001
2021-12-30 00:05:16,383 INFO  mapreduce.Job - Job job_local1789137285_0001 running in uber mode : false
2021-12-30 00:05:16,385 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:16,926 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:05:16,940 INFO  parse.ParseSegment - Parsed (311ms): http://192.168.240.25:5500/projects.html
2021-12-30 00:05:17,002 INFO  parse.ParseSegment - Parsed (56ms): http://192.168.240.25:5500/python.html
2021-12-30 00:05:17,113 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:17,332 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:17,390 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:05:17,708 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:05:18,391 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:18,392 INFO  mapreduce.Job - Job job_local1789137285_0001 completed successfully
2021-12-30 00:05:18,433 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1922226
		FILE: Number of bytes written=3133309
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=7488
		Map output materialized bytes=7502
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=7502
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=269484032
	ParserStatus
		success=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=7778
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:05:18,453 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:05:18, elapsed: 00:00:04
2021-12-30 00:05:20,760 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:21,505 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:05:21
2021-12-30 00:05:21,507 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000456]
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:05:21,509 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:05:21,510 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:05:21,511 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:05:21,515 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:05:21,660 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:23,321 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:23,322 INFO  mapreduce.Job - Running job: job_local183016213_0001
2021-12-30 00:05:24,237 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:24,332 INFO  mapreduce.Job - Job job_local183016213_0001 running in uber mode : false
2021-12-30 00:05:24,337 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:05:25,094 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:05:25,095 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:05:25,095 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:05:25,341 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:25,343 INFO  mapreduce.Job - Job job_local183016213_0001 completed successfully
2021-12-30 00:05:25,379 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=3813538
		FILE: Number of bytes written=6223337
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=38
		Map output records=38
		Map output bytes=4348
		Map output materialized bytes=4452
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=4452
		Reduce input records=38
		Reduce output records=24
		Spilled Records=76
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=817889280
	CrawlDB status
		db_fetched=9
		db_gone=1
		db_unfetched=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5002
	File Output Format Counters 
		Bytes Written=3907
2021-12-30 00:05:25,418 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:05:25, elapsed: 00:00:03
2021-12-30 00:05:27,663 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:28,321 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:05:28
2021-12-30 00:05:28,322 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:05:28,322 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:05:28,328 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:05:28,332 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:05:28,347 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:05:28,550 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:30,053 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:30,056 INFO  mapreduce.Job - Running job: job_local636735057_0001
2021-12-30 00:05:31,085 INFO  mapreduce.Job - Job job_local636735057_0001 running in uber mode : false
2021-12-30 00:05:31,087 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:31,276 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:05:31,282 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:05:31,282 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:05:31,486 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:31,769 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-30 00:05:32,096 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:32,098 INFO  mapreduce.Job - Job job_local636735057_0001 completed successfully
2021-12-30 00:05:32,142 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1902146
		FILE: Number of bytes written=3114300
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=14
		Map output bytes=1547
		Map output materialized bytes=1581
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=3
		Reduce shuffle bytes=1581
		Reduce input records=14
		Reduce output records=0
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=10
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3675
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:05:32,142 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:05:32,160 INFO  crawl.Generator - Generator:     10  SCHEDULE_REJECTED
2021-12-30 00:05:32,170 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-30 00:05:33,171 INFO  crawl.Generator - Generator: segment: crawl/segments/20211230000533
2021-12-30 00:05:33,185 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:33,637 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:33,638 INFO  mapreduce.Job - Running job: job_local1516696440_0002
2021-12-30 00:05:33,869 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:05:34,638 INFO  mapreduce.Job - Job job_local1516696440_0002 running in uber mode : false
2021-12-30 00:05:34,639 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:05:34,640 INFO  mapreduce.Job - Job job_local1516696440_0002 completed successfully
2021-12-30 00:05:34,651 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3805150
		FILE: Number of bytes written=6235205
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=2226
		Map output materialized bytes=2260
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=2260
		Reduce input records=14
		Reduce output records=14
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1791
	File Output Format Counters 
		Bytes Written=1657
2021-12-30 00:05:34,679 INFO  crawl.Generator - Generator: finished at 2021-12-30 00:05:34, elapsed: 00:00:06
2021-12-30 00:05:36,851 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:05:36
2021-12-30 00:05:36,855 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:05:37,315 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:05:37,829 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:05:39,493 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:05:39,494 INFO  mapreduce.Job - Running job: job_local1025464847_0001
2021-12-30 00:05:39,980 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-30 00:05:39,981 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-30 00:05:40,070 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-30 00:05:40,143 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 14 records
2021-12-30 00:05:40,147 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-30 00:05:40,148 INFO  fetcher.QueueFeeder - 	14	SUCCESSFULLY_QUEUED
2021-12-30 00:05:40,150 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-30 00:05:40,154 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-30 00:05:40,164 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-30 00:05:40,521 INFO  mapreduce.Job - Job job_local1025464847_0001 running in uber mode : false
2021-12-30 00:05:40,523 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:05:40,768 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,809 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,813 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,818 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,830 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,831 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,836 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,838 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,840 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:40,843 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:40,844 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/index.html (queue crawl delay=5000ms)
2021-12-30 00:05:40,846 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,184 INFO  http.Http - http.proxy.host = null
2021-12-30 00:05:41,185 INFO  http.Http - http.proxy.port = 8080
2021-12-30 00:05:41,186 INFO  http.Http - http.proxy.exception.list = false
2021-12-30 00:05:41,187 INFO  http.Http - http.timeout = 10000
2021-12-30 00:05:41,189 INFO  http.Http - http.content.limit = 1048576
2021-12-30 00:05:41,190 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-30 00:05:41,191 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-30 00:05:41,192 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-30 00:05:41,192 INFO  http.Http - http.enable.cookie.header = true
2021-12-30 00:05:41,193 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,200 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,202 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,209 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,210 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,214 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,215 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,240 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:05:41,244 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-30 00:05:41,258 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-30 00:05:41,259 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-30 00:05:42,261 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:43,262 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:44,263 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:45,264 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:46,266 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=13, fetchQueues.getQueueCount=1
2021-12-30 00:05:46,607 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/4inputoutput.html (queue crawl delay=5000ms)
2021-12-30 00:05:47,267 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:48,269 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:49,270 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:50,271 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:51,272 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=12, fetchQueues.getQueueCount=1
2021-12-30 00:05:51,656 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/1datatype.html (queue crawl delay=5000ms)
2021-12-30 00:05:52,273 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:52,540 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-30 00:05:53,275 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:54,276 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:55,277 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:56,281 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=11, fetchQueues.getQueueCount=1
2021-12-30 00:05:56,696 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5500/pythontut/5operators.html (queue crawl delay=5000ms)
2021-12-30 00:05:57,282 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:05:58,284 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:05:59,286 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:00,287 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:01,288 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=10, fetchQueues.getQueueCount=1
2021-12-30 00:06:01,755 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/3arithmetic.html (queue crawl delay=5000ms)
2021-12-30 00:06:02,289 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:03,290 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:04,292 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:05,292 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:06,294 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=9, fetchQueues.getQueueCount=1
2021-12-30 00:06:06,796 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/10forloop.html (queue crawl delay=5000ms)
2021-12-30 00:06:07,296 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:08,297 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:09,298 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:10,299 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:11,300 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=8, fetchQueues.getQueueCount=1
2021-12-30 00:06:11,826 INFO  fetcher.FetcherThread - FetcherThread 57 fetching http://192.168.240.25:5500/pythontut/8nested.html (queue crawl delay=5000ms)
2021-12-30 00:06:12,302 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:13,303 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:14,304 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:15,305 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:16,306 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=7, fetchQueues.getQueueCount=1
2021-12-30 00:06:16,861 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/12listtupleoperations.html (queue crawl delay=5000ms)
2021-12-30 00:06:17,308 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:18,309 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:19,310 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:20,312 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:21,313 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=6, fetchQueues.getQueueCount=1
2021-12-30 00:06:21,895 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/6conditional.html (queue crawl delay=5000ms)
2021-12-30 00:06:22,314 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:23,315 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:24,315 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:25,316 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:26,317 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=5, fetchQueues.getQueueCount=1
2021-12-30 00:06:26,931 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/media/webscraping.webp (queue crawl delay=5000ms)
2021-12-30 00:06:27,319 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   now           = 1640802987319
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:27,319 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:28,320 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:28,320 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   now           = 1640802988321
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:28,321 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:29,322 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   now           = 1640802989323
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:29,323 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:30,324 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:30,324 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:30,324 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   now           = 1640802990325
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:30,325 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:31,326 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=4, fetchQueues.getQueueCount=1
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:31,326 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802991977
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   now           = 1640802991327
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:31,327 INFO  fetcher.FetchItemQueue -   3. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:31,980 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/9whileloop.html (queue crawl delay=5000ms)
2021-12-30 00:06:32,328 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:32,328 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   now           = 1640802992329
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:32,329 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:33,330 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:33,330 INFO  fetcher.FetchItemQueue -   now           = 1640802993330
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:33,331 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:34,331 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   now           = 1640802994332
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:34,332 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:34,333 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:35,333 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   now           = 1640802995334
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:35,334 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:36,335 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640802997014
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   now           = 1640802996336
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:36,336 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:37,017 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/2variable.html (queue crawl delay=5000ms)
2021-12-30 00:06:37,337 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   now           = 1640802997337
2021-12-30 00:06:37,337 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:37,338 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:38,338 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:38,338 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:38,338 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   now           = 1640802998339
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:38,339 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:39,340 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:39,340 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   now           = 1640802999341
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:39,341 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:40,342 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   now           = 1640803000342
2021-12-30 00:06:40,342 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:40,343 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:41,343 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803002037
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   now           = 1640803001344
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:06:41,344 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:42,040 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/11listtuples.html (queue crawl delay=5000ms)
2021-12-30 00:06:42,345 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:42,345 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   now           = 1640803002346
2021-12-30 00:06:42,346 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:43,346 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   now           = 1640803003347
2021-12-30 00:06:43,347 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:44,348 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:44,348 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:44,348 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   now           = 1640803004349
2021-12-30 00:06:44,349 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:45,350 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   now           = 1640803005350
2021-12-30 00:06:45,350 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:46,351 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640803007079
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   now           = 1640803006352
2021-12-30 00:06:46,352 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:06:47,082 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5500/pythontut/7comments.html (queue crawl delay=5000ms)
2021-12-30 00:06:47,109 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-30 00:06:47,109 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=9
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:06:47,258 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=7
2021-12-30 00:06:47,278 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-30 00:06:47,278 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=6
2021-12-30 00:06:47,282 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-30 00:06:47,282 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=5
2021-12-30 00:06:47,300 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-30 00:06:47,300 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=4
2021-12-30 00:06:47,353 INFO  fetcher.Fetcher - -activeThreads=4, spinWaiting=4, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:06:47,368 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-30 00:06:47,368 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=3
2021-12-30 00:06:47,385 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-30 00:06:47,385 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-30 00:06:47,386 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-30 00:06:47,387 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:47,388 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:47,388 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=0
2021-12-30 00:06:48,354 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-30 00:06:48,354 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-30 00:06:48,452 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:06:48,600 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:06:49,601 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:06:49,603 INFO  mapreduce.Job - Job job_local1025464847_0001 completed successfully
2021-12-30 00:06:49,633 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2393672
		FILE: Number of bytes written=4001547
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=28
		Map output bytes=249249
		Map output materialized bytes=249354
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=249354
		Reduce input records=28
		Reduce output records=28
		Spilled Records=56
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=38
		Total committed heap usage (bytes)=423624704
	FetcherStatus
		bytes_downloaded=237313
		success=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1657
	File Output Format Counters 
		Bytes Written=150319
2021-12-30 00:06:49,635 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-30 00:06:49, elapsed: 00:01:12
2021-12-30 00:06:52,212 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:06:52,742 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-30 00:06:52
2021-12-30 00:06:52,743 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211230000533
2021-12-30 00:06:52,904 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:06:55,285 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:06:55,286 INFO  mapreduce.Job - Running job: job_local36374451_0001
2021-12-30 00:06:56,317 INFO  mapreduce.Job - Job job_local36374451_0001 running in uber mode : false
2021-12-30 00:06:56,319 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:06:56,695 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-30 00:06:56,709 INFO  parse.ParseSegment - Parsed (301ms): http://192.168.240.25:5500/index.html
2021-12-30 00:06:56,722 INFO  parse.ParserFactory - The parsing plugins: [org.apache.nutch.parse.tika.TikaParser] are enabled via the plugin.includes system property, and all claim to support the content type image/webp, but they are not mapped to it  in the parse-plugins.xml file
2021-12-30 00:06:58,467 ERROR tika.TikaParser - Problem loading custom Tika configuration from tika-config.xml
java.lang.NumberFormatException: For input string: ""
	at java.base/java.lang.NumberFormatException.forInputString(NumberFormatException.java:68)
	at java.base/java.lang.Integer.parseInt(Integer.java:668)
	at java.base/java.lang.Integer.parseInt(Integer.java:776)
	at org.apache.tika.config.TikaConfig.updateXMLReaderUtils(TikaConfig.java:303)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:192)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:182)
	at org.apache.tika.config.TikaConfig.<init>(TikaConfig.java:157)
	at org.apache.nutch.parse.tika.TikaParser.setConf(TikaParser.java:274)
	at org.apache.nutch.plugin.Extension.getExtensionInstance(Extension.java:169)
	at org.apache.nutch.parse.ParserFactory.getParsers(ParserFactory.java:134)
	at org.apache.nutch.parse.ParseUtil.parse(ParseUtil.java:75)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:122)
	at org.apache.nutch.parse.ParseSegment$ParseSegmentMapper.map(ParseSegment.java:77)
	at org.apache.hadoop.mapreduce.Mapper.run(Mapper.java:146)
	at org.apache.hadoop.mapred.MapTask.runNewMapper(MapTask.java:799)
	at org.apache.hadoop.mapred.MapTask.run(MapTask.java:347)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$MapTaskRunnable.run(LocalJobRunner.java:271)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-30 00:07:05,441 INFO  parse.ParseSegment - Parsed (8719ms): http://192.168.240.25:5500/media/webscraping.webp
2021-12-30 00:07:05,491 INFO  parse.ParseSegment - Parsed (46ms): http://192.168.240.25:5500/pythontut/10forloop.html
2021-12-30 00:07:05,519 INFO  parse.ParseSegment - Parsed (26ms): http://192.168.240.25:5500/pythontut/11listtuples.html
2021-12-30 00:07:05,578 INFO  parse.ParseSegment - Parsed (58ms): http://192.168.240.25:5500/pythontut/12listtupleoperations.html
2021-12-30 00:07:05,600 INFO  parse.ParseSegment - Parsed (20ms): http://192.168.240.25:5500/pythontut/1datatype.html
2021-12-30 00:07:05,633 INFO  parse.ParseSegment - Parsed (32ms): http://192.168.240.25:5500/pythontut/2variable.html
2021-12-30 00:07:05,652 INFO  parse.ParseSegment - Parsed (17ms): http://192.168.240.25:5500/pythontut/3arithmetic.html
2021-12-30 00:07:05,675 INFO  parse.ParseSegment - Parsed (22ms): http://192.168.240.25:5500/pythontut/4inputoutput.html
2021-12-30 00:07:05,690 INFO  parse.ParseSegment - Parsed (13ms): http://192.168.240.25:5500/pythontut/5operators.html
2021-12-30 00:07:05,709 INFO  parse.ParseSegment - Parsed (18ms): http://192.168.240.25:5500/pythontut/6conditional.html
2021-12-30 00:07:05,724 INFO  parse.ParseSegment - Parsed (13ms): http://192.168.240.25:5500/pythontut/7comments.html
2021-12-30 00:07:05,746 INFO  parse.ParseSegment - Parsed (21ms): http://192.168.240.25:5500/pythontut/8nested.html
2021-12-30 00:07:05,783 INFO  parse.ParseSegment - Parsed (36ms): http://192.168.240.25:5500/pythontut/9whileloop.html
2021-12-30 00:07:05,919 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:06,112 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-30 00:07:06,297 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-30 00:07:06,332 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:07,333 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:07,335 INFO  mapreduce.Job - Job job_local36374451_0001 completed successfully
2021-12-30 00:07:07,352 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2289122
		FILE: Number of bytes written=3277651
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=14
		Map output records=14
		Map output bytes=51956
		Map output materialized bytes=52018
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=14
		Reduce shuffle bytes=52018
		Reduce input records=14
		Reduce output records=14
		Spilled Records=28
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=59
		Total committed heap usage (bytes)=318767104
	ParserStatus
		success=14
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=146709
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:07:07,367 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-30 00:07:07, elapsed: 00:00:14
2021-12-30 00:07:09,305 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:09,919 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-30 00:07:09
2021-12-30 00:07:09,920 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-30 00:07:09,920 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211230000533]
2021-12-30 00:07:09,921 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-30 00:07:09,922 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-30 00:07:09,928 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-30 00:07:10,050 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:11,469 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:11,470 INFO  mapreduce.Job - Running job: job_local1137037029_0001
2021-12-30 00:07:12,274 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:12,495 INFO  mapreduce.Job - Job job_local1137037029_0001 running in uber mode : false
2021-12-30 00:07:12,497 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:13,001 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:07:13,002 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:07:13,002 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:07:13,499 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:13,500 INFO  mapreduce.Job - Job job_local1137037029_0001 completed successfully
2021-12-30 00:07:13,545 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3858479
		FILE: Number of bytes written=6272555
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=119
		Map output records=119
		Map output bytes=12672
		Map output materialized bytes=12952
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=12952
		Reduce input records=119
		Reduce output records=24
		Spilled Records=238
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=960495616
	CrawlDB status
		db_fetched=23
		db_gone=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=13670
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:07:13,574 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-30 00:07:13, elapsed: 00:00:03
2021-12-30 00:07:16,507 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:07:17
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:07:17,539 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:07:17,550 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:07:17,551 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:07:17,551 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:07:17,552 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:07:17,553 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:07:17,706 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:20,126 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:20,130 INFO  mapreduce.Job - Running job: job_local377853345_0001
2021-12-30 00:07:21,184 INFO  mapreduce.Job - Job job_local377853345_0001 running in uber mode : false
2021-12-30 00:07:21,188 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:21,928 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:23,193 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:23,194 INFO  mapreduce.Job - Job job_local377853345_0001 completed successfully
2021-12-30 00:07:23,313 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10863834
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=41
		Total committed heap usage (bytes)=1460666368
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:07:23,314 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:07:23,371 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:24,756 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:24,757 INFO  mapreduce.Job - Running job: job_local468564376_0002
2021-12-30 00:07:25,761 INFO  mapreduce.Job - Job job_local468564376_0002 running in uber mode : false
2021-12-30 00:07:25,761 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:07:27,046 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:27,764 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:07:27,766 INFO  mapreduce.Job - Job job_local468564376_0002 completed successfully
2021-12-30 00:07:27,803 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5742064
		FILE: Number of bytes written=9307972
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=344
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=751828992
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:07:27,887 INFO  crawl.LinkDb - LinkDb: finished at 2021-12-30 00:07:27, elapsed: 00:00:10
2021-12-30 00:07:33,067 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:07:33,812 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20211230000533.
2021-12-30 00:07:33,819 INFO  indexer.IndexingJob - Indexer: starting at 2021-12-30 00:07:33
2021-12-30 00:07:33,835 INFO  indexer.IndexingJob - Indexer: deleting gone documents: false
2021-12-30 00:07:33,837 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2021-12-30 00:07:33,838 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2021-12-30 00:07:33,846 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2021-12-30 00:07:33,852 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20211230000533
2021-12-30 00:07:33,857 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2021-12-30 00:07:34,052 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:07:36,270 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:07:36,272 INFO  mapreduce.Job - Running job: job_local390450797_0001
2021-12-30 00:07:37,295 INFO  mapreduce.Job - Job job_local390450797_0001 running in uber mode : false
2021-12-30 00:07:37,297 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:07:37,511 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:37,756 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:37,948 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,136 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,276 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-30 00:07:38,303 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-30 00:07:38,460 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:07:38,620 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2021-12-30 00:07:39,106 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2021-12-30 00:07:39,305 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:07:40,142 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a  string  value  of│http                            │
│            │one of the following "cloud" or "http". The values represent CloudSolrServer│                                │
│            │or HttpSolrServer respectively.                                             │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should  be  indexed.│http://localhost:8983/solr/nutch│
│            │Multiple URL can be provided using comma as a delimiter. When the  value  of│                                │
│            │type property is cloud, the URL should not include any collections or cores;│                                │
│            │just the root Solr path.                                                    │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of  type  property│                                │
│            │is cloud.                                                                   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a  single  update  batch.│1000                            │
│            │Decrease when handling very large documents to prevent  Nutch  from  running│                                │
│            │out of memory. Note: It does not explicitly trigger a server side commit.   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be  written.  If  it  is│                                │
│            │empty no field will be used.                                                │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use│false                           │
│            │the username and password properties to configure your credentials.         │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                │username                        │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                │password                        │
└────────────┴────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2021-12-30 00:07:40,209 INFO  anchor.AnchorIndexingFilter - Anchor deduplication is: off
2021-12-30 00:07:40,391 INFO  solr.SolrIndexWriter - Indexing 14/14 documents
2021-12-30 00:07:40,397 INFO  solr.SolrIndexWriter - Deleting 0 documents
2021-12-30 00:07:41,328 WARN  mapred.LocalJobRunner - job_local390450797_0001
java.lang.Exception: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/nutch: Expected mime type application/octet-stream but got text/html. <html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<title>Error 404 Not Found</title>
</head>
<body><h2>HTTP ERROR 404 Not Found</h2>
<table>
<tr><th>URI:</th><td>/solr/nutch/update</td></tr>
<tr><th>STATUS:</th><td>404</td></tr>
<tr><th>MESSAGE:</th><td>Not Found</td></tr>
<tr><th>SERVLET:</th><td>default</td></tr>
</table>

</body>
</html>

	at org.apache.hadoop.mapred.LocalJobRunner$Job.runTasks(LocalJobRunner.java:492)
	at org.apache.hadoop.mapred.LocalJobRunner$Job.run(LocalJobRunner.java:559)
Caused by: org.apache.solr.client.solrj.impl.HttpSolrClient$RemoteSolrException: Error from server at http://localhost:8983/solr/nutch: Expected mime type application/octet-stream but got text/html. <html>
<head>
<meta http-equiv="Content-Type" content="text/html;charset=utf-8"/>
<title>Error 404 Not Found</title>
</head>
<body><h2>HTTP ERROR 404 Not Found</h2>
<table>
<tr><th>URI:</th><td>/solr/nutch/update</td></tr>
<tr><th>STATUS:</th><td>404</td></tr>
<tr><th>MESSAGE:</th><td>Not Found</td></tr>
<tr><th>SERVLET:</th><td>default</td></tr>
</table>

</body>
</html>

	at org.apache.solr.client.solrj.impl.HttpSolrClient.executeMethod(HttpSolrClient.java:629)
	at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:265)
	at org.apache.solr.client.solrj.impl.HttpSolrClient.request(HttpSolrClient.java:248)
	at org.apache.solr.client.solrj.SolrClient.request(SolrClient.java:1290)
	at org.apache.nutch.indexwriter.solr.SolrIndexWriter.push(SolrIndexWriter.java:249)
	at org.apache.nutch.indexwriter.solr.SolrIndexWriter.commit(SolrIndexWriter.java:218)
	at org.apache.nutch.indexer.IndexWriters.commit(IndexWriters.java:264)
	at org.apache.nutch.indexer.IndexerOutputFormat$1.close(IndexerOutputFormat.java:54)
	at org.apache.hadoop.mapred.ReduceTask$NewTrackingRecordWriter.close(ReduceTask.java:551)
	at org.apache.hadoop.mapred.ReduceTask.runNewReducer(ReduceTask.java:630)
	at org.apache.hadoop.mapred.ReduceTask.run(ReduceTask.java:390)
	at org.apache.hadoop.mapred.LocalJobRunner$Job$ReduceTaskRunnable.run(LocalJobRunner.java:347)
	at java.base/java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:515)
	at java.base/java.util.concurrent.FutureTask.run(FutureTask.java:264)
	at java.base/java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1128)
	at java.base/java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:628)
	at java.base/java.lang.Thread.run(Thread.java:830)
2021-12-30 00:07:42,308 INFO  mapreduce.Job - Job job_local390450797_0001 failed with state FAILED due to: NA
2021-12-30 00:07:42,381 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5862301
		FILE: Number of bytes written=9591996
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=147
		Map output records=147
		Map output bytes=54073
		Map output materialized bytes=54495
		Input split bytes=1104
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=54495
		Reduce input records=0
		Reduce output records=0
		Spilled Records=147
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=53
		Total committed heap usage (bytes)=1298137088
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=36801
	File Output Format Counters 
		Bytes Written=0
2021-12-30 00:07:42,385 ERROR indexer.IndexingJob - Indexing job did not succeed, job status:FAILED, reason: NA
2021-12-30 00:07:42,389 ERROR indexer.IndexingJob - Indexer: java.lang.RuntimeException: Indexing job did not succeed, job status:FAILED, reason: NA
	at org.apache.nutch.indexer.IndexingJob.index(IndexingJob.java:150)
	at org.apache.nutch.indexer.IndexingJob.run(IndexingJob.java:291)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.indexer.IndexingJob.main(IndexingJob.java:300)

2021-12-30 00:20:40,503 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:20:40
2021-12-30 00:20:40,506 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:20:40,507 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:20:40,509 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:20:40,804 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:41,433 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:20:41,566 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:42,944 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:42,947 INFO  mapreduce.Job - Running job: job_local1953095821_0001
2021-12-30 00:20:43,973 INFO  mapreduce.Job - Job job_local1953095821_0001 running in uber mode : false
2021-12-30 00:20:43,976 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:44,135 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:20:44,234 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:20:44,516 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:20:44,518 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:20:44,993 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:20:44,995 INFO  mapreduce.Job - Job job_local1953095821_0001 completed successfully
2021-12-30 00:20:45,015 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2868750
		FILE: Number of bytes written=4687881
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=5487
		Map output materialized bytes=5573
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5573
		Reduce input records=25
		Reduce output records=24
		Spilled Records=50
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=623902720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
		urls_merged=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:20:45,095 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:20:45,096 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:20:45,098 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 1
2021-12-30 00:20:45,099 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-30 00:20:45,116 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:20:45, elapsed: 00:00:04
2021-12-30 00:20:47,092 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:47,660 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:20:47
2021-12-30 00:20:47,662 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:20:47,663 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:20:47,664 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:20:47,682 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:20:47,824 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:49,233 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:49,235 INFO  mapreduce.Job - Running job: job_local906574406_0001
2021-12-30 00:20:50,163 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:20:50,167 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:20:50,168 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:20:50,244 INFO  mapreduce.Job - Job job_local906574406_0001 running in uber mode : false
2021-12-30 00:20:50,246 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:50,323 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:20:51,251 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:20:51,254 INFO  mapreduce.Job - Job job_local906574406_0001 completed successfully
2021-12-30 00:20:51,284 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=14
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:20:51,284 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:20:51,300 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:20:51,309 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:20:53,070 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:20:53
2021-12-30 00:20:53,072 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:20:53,434 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:53,972 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:54,295 ERROR fetcher.Fetcher - Fetcher: java.io.IOException: Segment already fetched!
	at org.apache.nutch.fetcher.FetcherOutputFormat.checkOutputSpecs(FetcherOutputFormat.java:55)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.fetcher.Fetcher.fetch(Fetcher.java:498)
	at org.apache.nutch.fetcher.Fetcher.run(Fetcher.java:545)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.fetcher.Fetcher.main(Fetcher.java:518)

2021-12-30 00:20:56,253 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:20:56,877 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:20:56
2021-12-30 00:20:56,879 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:20:56,880 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:20:56,881 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:20:56,885 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:20:56,905 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:20:57,072 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:20:58,427 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:20:58,428 INFO  mapreduce.Job - Running job: job_local801910902_0001
2021-12-30 00:20:59,432 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:20:59,433 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:20:59,434 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:20:59,441 INFO  mapreduce.Job - Job job_local801910902_0001 running in uber mode : false
2021-12-30 00:20:59,443 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:20:59,610 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:00,445 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:00,447 INFO  mapreduce.Job - Job job_local801910902_0001 completed successfully
2021-12-30 00:21:00,470 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=22
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:21:00,472 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:21:00,479 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:21:00,498 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:21:02,381 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:21:02,951 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:21:02
2021-12-30 00:21:02,953 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:21:02,955 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:21:02,957 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:21:02,967 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:21:02,990 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:21:03,157 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:21:04,557 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:04,558 INFO  mapreduce.Job - Running job: job_local253976520_0001
2021-12-30 00:21:05,530 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:21:05,531 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:21:05,531 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:21:05,585 INFO  mapreduce.Job - Job job_local253976520_0001 running in uber mode : false
2021-12-30 00:21:05,586 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:21:05,722 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:06,591 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:06,592 INFO  mapreduce.Job - Job job_local253976520_0001 completed successfully
2021-12-30 00:21:06,623 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107784
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=17
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:21:06,624 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:21:06,646 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:21:06,663 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:21:08,600 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:21:09,231 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:21:09
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:21:09,232 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:21:09,240 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:21:09,241 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:21:09,242 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:21:09,245 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:21:09,246 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:21:09,378 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:21:10,896 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:10,897 INFO  mapreduce.Job - Running job: job_local8254689_0001
2021-12-30 00:21:11,906 INFO  mapreduce.Job - Job job_local8254689_0001 running in uber mode : false
2021-12-30 00:21:11,912 INFO  mapreduce.Job -  map 83% reduce 0%
2021-12-30 00:21:11,947 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:12,922 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:12,923 INFO  mapreduce.Job - Job job_local8254689_0001 completed successfully
2021-12-30 00:21:12,949 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10822730
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=31
		Total committed heap usage (bytes)=1549795328
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:21:12,951 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:21:12,961 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:13,347 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:21:13,347 INFO  mapreduce.Job - Running job: job_local330131418_0002
2021-12-30 00:21:14,111 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:21:14,348 INFO  mapreduce.Job - Job job_local330131418_0002 running in uber mode : false
2021-12-30 00:21:14,348 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:21:14,349 INFO  mapreduce.Job - Job job_local330131418_0002 completed successfully
2021-12-30 00:21:14,357 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=5742064
		FILE: Number of bytes written=9290356
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=12
		Input split bytes=344
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=12
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=21
		Total committed heap usage (bytes)=754974720
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=276
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:21:14,407 INFO  crawl.LinkDb - LinkDb: finished at 2021-12-30 00:21:14, elapsed: 00:00:05
2021-12-30 00:31:32,108 INFO  crawl.Injector - Injector: starting at 2021-12-30 00:31:32
2021-12-30 00:31:32,121 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-30 00:31:32,123 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-30 00:31:32,124 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-30 00:31:32,522 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:33,423 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-30 00:31:33,573 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:35,134 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:35,135 INFO  mapreduce.Job - Running job: job_local253266142_0001
2021-12-30 00:31:36,161 INFO  mapreduce.Job - Job job_local253266142_0001 running in uber mode : false
2021-12-30 00:31:36,178 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:31:36,764 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-30 00:31:36,839 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:31:37,101 INFO  crawl.Injector - Injector: overwrite: false
2021-12-30 00:31:37,101 INFO  crawl.Injector - Injector: update: false
2021-12-30 00:31:37,188 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:31:37,189 INFO  mapreduce.Job - Job job_local253266142_0001 completed successfully
2021-12-30 00:31:37,227 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=2868750
		FILE: Number of bytes written=4679061
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=5487
		Map output materialized bytes=5573
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=24
		Reduce shuffle bytes=5573
		Reduce input records=25
		Reduce output records=24
		Spilled Records=50
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=20
		Total committed heap usage (bytes)=745537536
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
		urls_merged=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=5996
2021-12-30 00:31:37,298 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-30 00:31:37,299 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-30 00:31:37,300 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 1
2021-12-30 00:31:37,301 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-30 00:31:37,321 INFO  crawl.Injector - Injector: finished at 2021-12-30 00:31:37, elapsed: 00:00:05
2021-12-30 00:31:39,344 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:31:39
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:31:39,877 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:31:39,894 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:31:40,057 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:41,375 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:41,376 INFO  mapreduce.Job - Running job: job_local279330765_0001
2021-12-30 00:31:42,387 INFO  mapreduce.Job - Job job_local279330765_0001 running in uber mode : false
2021-12-30 00:31:42,389 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-30 00:31:42,468 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-30 00:31:42,470 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-30 00:31:42,470 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-30 00:31:42,692 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:31:43,395 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:31:43,396 INFO  mapreduce.Job - Job job_local279330765_0001 completed successfully
2021-12-30 00:31:43,429 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1903174
		FILE: Number of bytes written=3107844
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=24
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=15
		Total committed heap usage (bytes)=413138944
	Generator
		SCHEDULE_REJECTED=24
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5764
	File Output Format Counters 
		Bytes Written=8
2021-12-30 00:31:43,431 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-30 00:31:43,439 INFO  crawl.Generator - Generator:     24  SCHEDULE_REJECTED
2021-12-30 00:31:43,459 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-30 00:31:45,857 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-30 00:31:45
2021-12-30 00:31:45,858 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211230000533
2021-12-30 00:31:46,359 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:47,071 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:47,441 ERROR fetcher.Fetcher - Fetcher: java.io.IOException: Segment already fetched!
	at org.apache.nutch.fetcher.FetcherOutputFormat.checkOutputSpecs(FetcherOutputFormat.java:55)
	at org.apache.hadoop.mapreduce.JobSubmitter.checkSpecs(JobSubmitter.java:277)
	at org.apache.hadoop.mapreduce.JobSubmitter.submitJobInternal(JobSubmitter.java:143)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1570)
	at org.apache.hadoop.mapreduce.Job$11.run(Job.java:1567)
	at java.base/java.security.AccessController.doPrivileged(AccessController.java:691)
	at java.base/javax.security.auth.Subject.doAs(Subject.java:423)
	at org.apache.hadoop.security.UserGroupInformation.doAs(UserGroupInformation.java:1729)
	at org.apache.hadoop.mapreduce.Job.submit(Job.java:1567)
	at org.apache.hadoop.mapreduce.Job.waitForCompletion(Job.java:1588)
	at org.apache.nutch.fetcher.Fetcher.fetch(Fetcher.java:498)
	at org.apache.nutch.fetcher.Fetcher.run(Fetcher.java:545)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.fetcher.Fetcher.main(Fetcher.java:518)

2021-12-30 00:31:49,698 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:50,258 INFO  crawl.Generator - Generator: starting at 2021-12-30 00:31:50
2021-12-30 00:31:50,260 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-30 00:31:50,261 INFO  crawl.Generator - Generator: filtering: true
2021-12-30 00:31:50,262 INFO  crawl.Generator - Generator: normalizing: true
2021-12-30 00:31:50,265 INFO  crawl.Generator - Generator: topN: 1000
2021-12-30 00:31:50,287 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-30 00:31:50,443 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:52,065 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:52,067 INFO  mapreduce.Job - Running job: job_local1147790014_0001
2021-12-30 00:31:55,033 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:55,650 ERROR crawl.Generator - Generator: java.io.IOException: lock file crawl/crawldb/.locked already exists.
	at org.apache.nutch.util.LockUtil.createLockFile(LockUtil.java:50)
	at org.apache.nutch.util.LockUtil.createLockFile(LockUtil.java:80)
	at org.apache.nutch.crawl.CrawlDb.lock(CrawlDb.java:194)
	at org.apache.nutch.crawl.Generator.generate(Generator.java:760)
	at org.apache.nutch.crawl.Generator.run(Generator.java:1051)
	at org.apache.hadoop.util.ToolRunner.run(ToolRunner.java:76)
	at org.apache.nutch.crawl.Generator.main(Generator.java:998)

2021-12-30 00:31:57,660 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-30 00:31:58,305 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-30 00:31:58
2021-12-30 00:31:58,307 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-30 00:31:58,308 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-30 00:31:58,310 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-30 00:31:58,311 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-30 00:31:58,313 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-30 00:31:58,317 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-30 00:31:58,319 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-30 00:31:58,324 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000423
2021-12-30 00:31:58,324 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000456
2021-12-30 00:31:58,327 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211230000533
2021-12-30 00:31:58,451 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-30 00:31:59,921 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:31:59,922 INFO  mapreduce.Job - Running job: job_local1292122582_0001
2021-12-30 00:32:00,949 INFO  mapreduce.Job - Job job_local1292122582_0001 running in uber mode : false
2021-12-30 00:32:00,957 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-30 00:32:01,048 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:32:01,963 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-30 00:32:01,965 INFO  mapreduce.Job - Job job_local1292122582_0001 completed successfully
2021-12-30 00:32:01,998 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=6743947
		FILE: Number of bytes written=10884414
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=23
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=36
		Input split bytes=1146
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=36
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=1586495488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=16107
	File Output Format Counters 
		Bytes Written=279
2021-12-30 00:32:02,000 INFO  crawl.LinkDb - LinkDb: merging with existing linkdb: crawl/linkdb
2021-12-30 00:32:02,010 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-30 00:32:02,423 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-30 00:32:02,423 INFO  mapreduce.Job - Running job: job_local1535484144_0002
