2021-12-26 17:33:53,990 INFO  crawl.Injector - Injector: starting at 2021-12-26 17:33:53
2021-12-26 17:33:53,991 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-26 17:33:53,991 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-26 17:33:53,991 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-26 17:33:54,335 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:33:55,229 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-26 17:33:55,430 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:33:57,424 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:33:57,426 INFO  mapreduce.Job - Running job: job_local561470382_0001
2021-12-26 17:33:58,465 INFO  mapreduce.Job - Job job_local561470382_0001 running in uber mode : false
2021-12-26 17:33:58,478 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:33:58,918 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:33:59,191 INFO  crawl.Injector - Injector: overwrite: false
2021-12-26 17:33:59,192 INFO  crawl.Injector - Injector: update: false
2021-12-26 17:33:59,481 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:33:59,483 INFO  mapreduce.Job - Job job_local561470382_0001 completed successfully
2021-12-26 17:33:59,506 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1891894
		FILE: Number of bytes written=3100051
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=308
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=18
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=239
2021-12-26 17:33:59,535 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-26 17:33:59,536 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 0
2021-12-26 17:33:59,536 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-26 17:33:59,536 INFO  crawl.Injector - Injector: Total new urls injected: 0
2021-12-26 17:33:59,555 INFO  crawl.Injector - Injector: finished at 2021-12-26 17:33:59, elapsed: 00:00:05
2021-12-26 17:34:01,754 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:34:02,364 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:34:02
2021-12-26 17:34:02,364 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:34:02,364 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:34:02,364 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:34:02,380 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:34:02,538 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:34:04,266 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:34:04,267 INFO  mapreduce.Job - Running job: job_local875170329_0001
2021-12-26 17:34:05,318 INFO  mapreduce.Job - Job job_local875170329_0001 running in uber mode : false
2021-12-26 17:34:05,320 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:34:05,509 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:34:05,519 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:34:05,519 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:34:05,663 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:34:06,324 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:34:06,326 INFO  mapreduce.Job - Job job_local875170329_0001 completed successfully
2021-12-26 17:34:06,355 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1891838
		FILE: Number of bytes written=3107840
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=30
		Total committed heap usage (bytes)=406847488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=98
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:34:06,355 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:34:06,381 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-26 17:34:10,442 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:34:11,071 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:34:11
2021-12-26 17:34:11,072 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:34:11,072 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:34:11,072 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:34:11,075 INFO  crawl.Generator - Generator: topN: 1000
2021-12-26 17:34:11,092 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:34:11,270 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:34:12,889 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:34:12,890 INFO  mapreduce.Job - Running job: job_local1879176782_0001
2021-12-26 17:34:13,943 INFO  mapreduce.Job - Job job_local1879176782_0001 running in uber mode : false
2021-12-26 17:34:13,946 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:34:13,958 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:34:13,959 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:34:13,959 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:34:14,060 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:34:14,949 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:34:14,951 INFO  mapreduce.Job - Job job_local1879176782_0001 completed successfully
2021-12-26 17:34:14,986 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1891838
		FILE: Number of bytes written=3113696
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=11
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=98
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:34:14,987 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:34:14,998 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-26 17:34:17,027 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:34:17,654 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:34:17
2021-12-26 17:34:17,654 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:34:17,654 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:34:17,654 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:34:17,658 INFO  crawl.Generator - Generator: topN: 1000
2021-12-26 17:34:17,673 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:34:17,821 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:34:19,508 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:34:19,509 INFO  mapreduce.Job - Running job: job_local1208043020_0001
2021-12-26 17:34:20,532 INFO  mapreduce.Job - Job job_local1208043020_0001 running in uber mode : false
2021-12-26 17:34:20,534 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:34:20,605 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:34:20,606 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:34:20,606 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:34:20,711 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:34:21,538 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:34:21,539 INFO  mapreduce.Job - Job job_local1208043020_0001 completed successfully
2021-12-26 17:34:21,570 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1891838
		FILE: Number of bytes written=3113696
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=0
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=6
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=6
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=19
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=98
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:34:21,575 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:34:21,591 WARN  crawl.Generator - Generator: 0 records selected for fetching, exiting ...
2021-12-26 17:34:23,654 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:43:20,279 INFO  crawl.Injector - Injector: starting at 2021-12-26 17:43:20
2021-12-26 17:43:20,280 INFO  crawl.Injector - Injector: crawlDb: crawl/crawldb
2021-12-26 17:43:20,280 INFO  crawl.Injector - Injector: urlDir: urls
2021-12-26 17:43:20,281 INFO  crawl.Injector - Injector: Converting injected urls to crawl db entries.
2021-12-26 17:43:20,537 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:43:21,263 INFO  crawl.Injector - Injecting seed URL file file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/urls/seed.txt
2021-12-26 17:43:21,389 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:43:22,813 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:43:22,814 INFO  mapreduce.Job - Running job: job_local663242210_0001
2021-12-26 17:43:23,864 INFO  mapreduce.Job - Job job_local663242210_0001 running in uber mode : false
2021-12-26 17:43:23,869 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:43:23,937 INFO  regex.RegexURLNormalizer - can't find rules for scope 'inject', using default
2021-12-26 17:43:24,017 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:43:24,253 INFO  crawl.Injector - Injector: overwrite: false
2021-12-26 17:43:24,254 INFO  crawl.Injector - Injector: update: false
2021-12-26 17:43:24,874 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:43:24,876 INFO  mapreduce.Job - Job job_local663242210_0001 completed successfully
2021-12-26 17:43:24,905 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=2840740
		FILE: Number of bytes written=4651446
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=57
		Map output materialized bytes=71
		Input split bytes=642
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=71
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =2
		Failed Shuffles=0
		Merged Map outputs=2
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=625999872
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	injector
		urls_injected=1
	File Input Format Counters 
		Bytes Read=0
	File Output Format Counters 
		Bytes Written=395
2021-12-26 17:43:24,978 INFO  crawl.Injector - Injector: Total urls rejected by filters: 0
2021-12-26 17:43:24,981 INFO  crawl.Injector - Injector: Total urls injected after normalization and filtering: 1
2021-12-26 17:43:24,981 INFO  crawl.Injector - Injector: Total urls injected but already in CrawlDb: 0
2021-12-26 17:43:24,981 INFO  crawl.Injector - Injector: Total new urls injected: 1
2021-12-26 17:43:24,999 INFO  crawl.Injector - Injector: finished at 2021-12-26 17:43:24, elapsed: 00:00:04
2021-12-26 17:43:46,637 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:43:47,244 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:43:47
2021-12-26 17:43:47,245 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:43:47,245 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:43:47,245 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:43:47,258 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:43:47,409 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:43:48,848 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:43:48,849 INFO  mapreduce.Job - Running job: job_local426402674_0001
2021-12-26 17:43:49,841 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:43:49,842 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:43:49,843 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:43:49,859 INFO  mapreduce.Job - Job job_local426402674_0001 running in uber mode : false
2021-12-26 17:43:49,861 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:43:50,010 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:43:50,209 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-26 17:43:50,865 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:43:50,866 INFO  mapreduce.Job - Job job_local426402674_0001 completed successfully
2021-12-26 17:43:50,894 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=1892146
		FILE: Number of bytes written=3108320
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=86
		Map output materialized bytes=94
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=94
		Reduce input records=1
		Reduce output records=0
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=27
		Total committed heap usage (bytes)=406847488
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=163
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:43:50,895 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:43:50,904 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-26 17:43:51,905 INFO  crawl.Generator - Generator: segment: crawl/segments/20211226174351
2021-12-26 17:43:51,918 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:43:52,317 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:43:52,317 INFO  mapreduce.Job - Running job: job_local1222691904_0002
2021-12-26 17:43:52,501 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:43:53,318 INFO  mapreduce.Job - Job job_local1222691904_0002 running in uber mode : false
2021-12-26 17:43:53,319 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:43:53,320 INFO  mapreduce.Job - Job job_local1222691904_0002 completed successfully
2021-12-26 17:43:53,335 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3784736
		FILE: Number of bytes written=6218260
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=110
		Map output materialized bytes=118
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=118
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=10
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=214
	File Output Format Counters 
		Bytes Written=184
2021-12-26 17:43:53,360 INFO  crawl.Generator - Generator: finished at 2021-12-26 17:43:53, elapsed: 00:00:06
2021-12-26 17:47:38,814 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-26 17:47:38
2021-12-26 17:47:38,815 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211226174351
2021-12-26 17:47:39,469 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:47:40,297 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:47:42,449 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:47:42,461 INFO  mapreduce.Job - Running job: job_local1904176093_0001
2021-12-26 17:47:43,181 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-26 17:47:43,182 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-26 17:47:43,392 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-26 17:47:43,433 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 1 records
2021-12-26 17:47:43,434 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-26 17:47:43,435 INFO  fetcher.QueueFeeder - 	1	SUCCESSFULLY_QUEUED
2021-12-26 17:47:43,435 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-26 17:47:43,435 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-26 17:47:43,436 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-26 17:47:43,492 INFO  mapreduce.Job - Job job_local1904176093_0001 running in uber mode : false
2021-12-26 17:47:43,494 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:47:44,398 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,506 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:44,512 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,513 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:44,522 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,523 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:44,530 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,531 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5501/ (queue crawl delay=5000ms)
2021-12-26 17:47:44,532 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:44,533 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-26 17:47:44,534 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:44,535 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,536 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:44,537 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-26 17:47:44,538 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:44,541 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:44,543 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-26 17:47:44,543 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=2
2021-12-26 17:47:44,545 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-26 17:47:44,545 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:44,993 INFO  http.Http - http.proxy.host = null
2021-12-26 17:47:44,994 INFO  http.Http - http.proxy.port = 8080
2021-12-26 17:47:44,994 INFO  http.Http - http.proxy.exception.list = false
2021-12-26 17:47:44,994 INFO  http.Http - http.timeout = 10000
2021-12-26 17:47:44,994 INFO  http.Http - http.content.limit = 1048576
2021-12-26 17:47:44,994 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-26 17:47:44,994 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-26 17:47:44,994 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-26 17:47:44,994 INFO  http.Http - http.enable.cookie.header = true
2021-12-26 17:47:44,995 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:45,000 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:45,002 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:45,021 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-26 17:47:45,021 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:45,023 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:45,024 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:45,033 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:45,036 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:45,037 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-26 17:47:45,037 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-26 17:47:45,044 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:47:45,045 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:47:45,045 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-26 17:47:45,046 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:45,051 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-26 17:47:45,062 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-26 17:47:45,067 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-26 17:47:45,074 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=2
2021-12-26 17:47:45,073 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-26 17:47:45,075 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:47:45,623 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-26 17:47:45,634 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=0
2021-12-26 17:47:46,071 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-26 17:47:46,072 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-26 17:47:46,312 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:47:46,500 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:47:47,501 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:47:47,502 INFO  mapreduce.Job - Job job_local1904176093_0001 completed successfully
2021-12-26 17:47:47,535 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1915082
		FILE: Number of bytes written=3142288
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=2
		Map output bytes=11520
		Map output materialized bytes=11533
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=11533
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=41
		Total committed heap usage (bytes)=419430400
	FetcherStatus
		bytes_downloaded=10772
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=184
	File Output Format Counters 
		Bytes Written=4525
2021-12-26 17:47:47,536 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-26 17:47:47, elapsed: 00:00:08
2021-12-26 17:48:00,833 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:48:01,911 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-26 17:48:01
2021-12-26 17:48:01,911 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211226174351
2021-12-26 17:48:02,230 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:48:04,567 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:48:04,568 INFO  mapreduce.Job - Running job: job_local777169636_0001
2021-12-26 17:48:05,592 INFO  mapreduce.Job - Job job_local777169636_0001 running in uber mode : false
2021-12-26 17:48:05,599 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:48:06,477 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-26 17:48:06,489 INFO  parse.ParseSegment - Parsed (489ms): http://192.168.240.25:5501/
2021-12-26 17:48:06,615 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:48:06,708 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:48:06,987 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:48:07,361 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-26 17:48:07,616 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:48:07,617 INFO  mapreduce.Job - Job job_local777169636_0001 completed successfully
2021-12-26 17:48:07,640 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1904754
		FILE: Number of bytes written=3111007
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=2799
		Map output materialized bytes=2809
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=2809
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=23
		Total committed heap usage (bytes)=549453824
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3735
	File Output Format Counters 
		Bytes Written=0
2021-12-26 17:48:07,658 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-26 17:48:07, elapsed: 00:00:05
2021-12-26 17:48:19,158 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:48:20,142 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-26 17:48:20
2021-12-26 17:48:20,146 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-26 17:48:20,149 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211226174351]
2021-12-26 17:48:20,149 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-26 17:48:20,150 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-26 17:48:20,150 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-26 17:48:20,150 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-26 17:48:20,167 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-26 17:48:20,470 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:48:22,611 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:48:22,612 INFO  mapreduce.Job - Running job: job_local1524038515_0001
2021-12-26 17:48:23,638 INFO  mapreduce.Job - Job job_local1524038515_0001 running in uber mode : false
2021-12-26 17:48:23,643 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:48:24,005 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:48:25,323 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:48:25,324 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:48:25,325 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:48:25,652 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:48:25,653 INFO  mapreduce.Job - Job job_local1524038515_0001 completed successfully
2021-12-26 17:48:25,724 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3798374
		FILE: Number of bytes written=6219968
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=22
		Map output records=22
		Map output bytes=1481
		Map output materialized bytes=1544
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=5
		Reduce shuffle bytes=1544
		Reduce input records=22
		Reduce output records=5
		Spilled Records=44
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=64
		Total committed heap usage (bytes)=829423616
	CrawlDB status
		db_fetched=1
		db_unfetched=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=2030
	File Output Format Counters 
		Bytes Written=860
2021-12-26 17:48:25,810 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-26 17:48:25, elapsed: 00:00:05
2021-12-26 17:48:35,431 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:48:36,415 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:48:36
2021-12-26 17:48:36,415 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:48:36,415 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:48:36,415 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:48:36,418 INFO  crawl.Generator - Generator: topN: 1000
2021-12-26 17:48:36,447 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:48:36,784 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:48:39,514 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:48:39,516 INFO  mapreduce.Job - Running job: job_local947934094_0001
2021-12-26 17:48:40,596 INFO  mapreduce.Job - Job job_local947934094_0001 running in uber mode : false
2021-12-26 17:48:40,598 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:48:41,261 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:48:41,263 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:48:41,263 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:48:41,571 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:48:41,604 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:48:42,036 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-26 17:48:42,605 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:48:42,607 INFO  mapreduce.Job - Job job_local947934094_0001 completed successfully
2021-12-26 17:48:42,652 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1893712
		FILE: Number of bytes written=3109552
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=5
		Map output records=4
		Map output bytes=397
		Map output materialized bytes=411
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=411
		Reduce input records=4
		Reduce output records=0
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=54
		Total committed heap usage (bytes)=406847488
	Generator
		SCHEDULE_REJECTED=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=628
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:48:42,653 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:48:42,673 INFO  crawl.Generator - Generator:      1  SCHEDULE_REJECTED
2021-12-26 17:48:42,676 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-26 17:48:43,676 INFO  crawl.Generator - Generator: segment: crawl/segments/20211226174843
2021-12-26 17:48:43,695 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:48:44,404 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:48:44,407 INFO  mapreduce.Job - Running job: job_local1233253799_0002
2021-12-26 17:48:44,866 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:48:45,407 INFO  mapreduce.Job - Job job_local1233253799_0002 running in uber mode : false
2021-12-26 17:48:45,408 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:48:45,408 INFO  mapreduce.Job - Job job_local1233253799_0002 completed successfully
2021-12-26 17:48:45,418 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3788500
		FILE: Number of bytes written=6221787
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=546
		Map output materialized bytes=560
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=560
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=6
		Total committed heap usage (bytes)=408944640
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=553
	File Output Format Counters 
		Bytes Written=495
2021-12-26 17:48:45,436 INFO  crawl.Generator - Generator: finished at 2021-12-26 17:48:45, elapsed: 00:00:09
2021-12-26 17:49:11,904 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-26 17:49:11
2021-12-26 17:49:11,908 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211226174843
2021-12-26 17:49:12,589 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:49:13,516 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:49:15,859 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:49:15,860 INFO  mapreduce.Job - Running job: job_local1808675883_0001
2021-12-26 17:49:16,517 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-26 17:49:16,520 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-26 17:49:16,718 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-26 17:49:16,765 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 4 records
2021-12-26 17:49:16,767 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-26 17:49:16,767 INFO  fetcher.QueueFeeder - 	4	SUCCESSFULLY_QUEUED
2021-12-26 17:49:16,768 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-26 17:49:16,769 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-26 17:49:16,769 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-26 17:49:16,903 INFO  mapreduce.Job - Job job_local1808675883_0001 running in uber mode : false
2021-12-26 17:49:16,905 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:49:17,586 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:17,656 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:17,658 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:17,660 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:17,666 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:17,667 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:17,669 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:17,674 INFO  fetcher.FetcherThread - FetcherThread 49 fetching http://192.168.240.25:5501/login.html (queue crawl delay=5000ms)
2021-12-26 17:49:17,674 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:17,679 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:17,687 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:17,699 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:18,177 INFO  http.Http - http.proxy.host = null
2021-12-26 17:49:18,178 INFO  http.Http - http.proxy.port = 8080
2021-12-26 17:49:18,179 INFO  http.Http - http.proxy.exception.list = false
2021-12-26 17:49:18,179 INFO  http.Http - http.timeout = 10000
2021-12-26 17:49:18,179 INFO  http.Http - http.content.limit = 1048576
2021-12-26 17:49:18,179 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-26 17:49:18,179 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-26 17:49:18,179 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-26 17:49:18,181 INFO  http.Http - http.enable.cookie.header = true
2021-12-26 17:49:18,183 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:18,189 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:18,190 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:18,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:18,194 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:18,201 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:18,202 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:18,216 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:18,217 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:49:18,223 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-26 17:49:18,224 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-26 17:49:19,225 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-26 17:49:19,226 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:19,226 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:19,226 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:19,226 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:19,227 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:19,227 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521163671
2021-12-26 17:49:19,227 INFO  fetcher.FetchItemQueue -   now           = 1640521159227
2021-12-26 17:49:19,232 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/index.html
2021-12-26 17:49:19,233 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/res.html
2021-12-26 17:49:19,233 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:20,234 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521163671
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   now           = 1640521160234
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/index.html
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/res.html
2021-12-26 17:49:20,234 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:21,236 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521163671
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   now           = 1640521161236
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/index.html
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/res.html
2021-12-26 17:49:21,236 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:22,237 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521163671
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   now           = 1640521162240
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/index.html
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/res.html
2021-12-26 17:49:22,240 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:23,241 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=3, fetchQueues.getQueueCount=1
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521163671
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   now           = 1640521163241
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/index.html
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/res.html
2021-12-26 17:49:23,241 INFO  fetcher.FetchItemQueue -   2. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:23,676 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5501/index.html (queue crawl delay=5000ms)
2021-12-26 17:49:24,242 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521168756
2021-12-26 17:49:24,242 INFO  fetcher.FetchItemQueue -   now           = 1640521164242
2021-12-26 17:49:24,243 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/res.html
2021-12-26 17:49:24,243 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:25,243 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-26 17:49:25,243 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:25,243 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:25,243 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521168756
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   now           = 1640521165244
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/res.html
2021-12-26 17:49:25,244 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:26,244 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-26 17:49:26,251 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:26,251 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:26,251 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521168756
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   now           = 1640521166252
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/res.html
2021-12-26 17:49:26,252 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:27,252 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-26 17:49:27,252 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521168756
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   now           = 1640521167253
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/res.html
2021-12-26 17:49:27,253 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:28,253 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=2, fetchQueues.getQueueCount=1
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521168756
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   now           = 1640521168254
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/res.html
2021-12-26 17:49:28,254 INFO  fetcher.FetchItemQueue -   1. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:28,762 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5501/res.html (queue crawl delay=5000ms)
2021-12-26 17:49:28,917 INFO  mapreduce.Job -  map 67% reduce 0%
2021-12-26 17:49:29,255 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521173819
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   now           = 1640521169256
2021-12-26 17:49:29,256 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:30,257 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:30,257 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521173819
2021-12-26 17:49:30,258 INFO  fetcher.FetchItemQueue -   now           = 1640521170258
2021-12-26 17:49:30,258 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:31,258 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521173819
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   now           = 1640521171259
2021-12-26 17:49:31,259 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:32,260 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521173819
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   now           = 1640521172260
2021-12-26 17:49:32,260 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:33,261 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521173819
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   now           = 1640521173261
2021-12-26 17:49:33,261 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:33,823 INFO  fetcher.FetcherThread - FetcherThread 50 fetching http://192.168.240.25:5501/reactui/public/index.html (queue crawl delay=5000ms)
2021-12-26 17:49:33,867 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-26 17:49:33,868 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=9
2021-12-26 17:49:34,190 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-26 17:49:34,190 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=8
2021-12-26 17:49:34,193 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-26 17:49:34,194 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=7
2021-12-26 17:49:34,201 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-26 17:49:34,201 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=6
2021-12-26 17:49:34,211 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-26 17:49:34,212 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=5
2021-12-26 17:49:34,219 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-26 17:49:34,219 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=4
2021-12-26 17:49:34,219 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-26 17:49:34,220 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=3
2021-12-26 17:49:34,224 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-26 17:49:34,224 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=2
2021-12-26 17:49:34,236 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-26 17:49:34,237 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:49:34,245 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-26 17:49:34,245 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=0
2021-12-26 17:49:34,262 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-26 17:49:34,262 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-26 17:49:34,495 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:49:34,925 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:49:35,926 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:49:35,927 INFO  mapreduce.Job - Job job_local1808675883_0001 completed successfully
2021-12-26 17:49:35,952 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=1993852
		FILE: Number of bytes written=3280142
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=8
		Map output bytes=50572
		Map output materialized bytes=50606
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=50606
		Reduce input records=8
		Reduce output records=8
		Spilled Records=16
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=46
		Total committed heap usage (bytes)=271581184
	FetcherStatus
		bytes_downloaded=47343
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=495
	File Output Format Counters 
		Bytes Written=25158
2021-12-26 17:49:35,953 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-26 17:49:35, elapsed: 00:00:24
2021-12-26 17:49:45,893 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:49:46,704 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-26 17:49:46
2021-12-26 17:49:46,704 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211226174843
2021-12-26 17:49:47,068 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:49:49,857 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:49:49,864 INFO  mapreduce.Job - Running job: job_local415591210_0001
2021-12-26 17:49:50,908 INFO  mapreduce.Job - Job job_local415591210_0001 running in uber mode : false
2021-12-26 17:49:50,911 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:49:51,897 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-26 17:49:51,908 INFO  parse.ParseSegment - Parsed (427ms): http://192.168.240.25:5501/index.html
2021-12-26 17:49:51,947 INFO  parse.ParseSegment - Parsed (35ms): http://192.168.240.25:5501/login.html
2021-12-26 17:49:51,967 INFO  parse.ParseSegment - Parsed (16ms): http://192.168.240.25:5501/reactui/public/index.html
2021-12-26 17:49:52,050 INFO  parse.ParseSegment - Parsed (70ms): http://192.168.240.25:5501/res.html
2021-12-26 17:49:52,353 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:49:52,572 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:49:52,919 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-26 17:49:52,931 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:49:53,932 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:49:53,933 INFO  mapreduce.Job - Job job_local415591210_0001 completed successfully
2021-12-26 17:49:53,961 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1957210
		FILE: Number of bytes written=3134560
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=4
		Map output records=4
		Map output bytes=9024
		Map output materialized bytes=9046
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=4
		Reduce shuffle bytes=9046
		Reduce input records=4
		Reduce output records=4
		Spilled Records=8
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=35
		Total committed heap usage (bytes)=534773760
	ParserStatus
		success=4
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=23726
	File Output Format Counters 
		Bytes Written=0
2021-12-26 17:49:53,976 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-26 17:49:53, elapsed: 00:00:07
2021-12-26 17:50:01,970 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:50:02,743 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-26 17:50:02
2021-12-26 17:50:02,743 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-26 17:50:02,744 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211226174843]
2021-12-26 17:50:02,744 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-26 17:50:02,744 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-26 17:50:02,745 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-26 17:50:02,745 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-26 17:50:02,750 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-26 17:50:02,926 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:50:05,387 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:50:05,392 INFO  mapreduce.Job - Running job: job_local1655712091_0001
2021-12-26 17:50:06,438 INFO  mapreduce.Job - Job job_local1655712091_0001 running in uber mode : false
2021-12-26 17:50:06,440 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:50:06,943 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:50:07,445 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:50:08,593 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:50:08,594 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:50:08,594 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:50:09,448 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:50:09,449 INFO  mapreduce.Job - Job job_local1655712091_0001 completed successfully
2021-12-26 17:50:09,491 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3816202
		FILE: Number of bytes written=6234837
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=55
		Map output records=55
		Map output bytes=4537
		Map output materialized bytes=4670
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=4670
		Reduce input records=55
		Reduce output records=7
		Spilled Records=110
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=61
		Total committed heap usage (bytes)=828375040
	CrawlDB status
		db_fetched=5
		db_unfetched=2
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5311
	File Output Format Counters 
		Bytes Written=1640
2021-12-26 17:50:09,536 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-26 17:50:09, elapsed: 00:00:06
2021-12-26 17:50:21,042 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:50:22,036 INFO  crawl.Generator - Generator: starting at 2021-12-26 17:50:22
2021-12-26 17:50:22,037 INFO  crawl.Generator - Generator: Selecting best-scoring urls due for fetch.
2021-12-26 17:50:22,037 INFO  crawl.Generator - Generator: filtering: true
2021-12-26 17:50:22,041 INFO  crawl.Generator - Generator: normalizing: true
2021-12-26 17:50:22,045 INFO  crawl.Generator - Generator: topN: 1000
2021-12-26 17:50:22,069 INFO  crawl.Generator - Generator: running in local mode, generating exactly one partition.
2021-12-26 17:50:22,321 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:50:25,055 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:50:25,057 INFO  mapreduce.Job - Running job: job_local1975208380_0001
2021-12-26 17:50:26,110 INFO  mapreduce.Job - Job job_local1975208380_0001 running in uber mode : false
2021-12-26 17:50:26,111 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:50:26,392 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:50:26,402 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:50:26,402 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:50:26,651 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:50:27,017 INFO  regex.RegexURLNormalizer - can't find rules for scope 'generate_host_count', using default
2021-12-26 17:50:27,115 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:50:28,116 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:50:28,117 INFO  mapreduce.Job - Job job_local1975208380_0001 completed successfully
2021-12-26 17:50:28,152 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1894922
		FILE: Number of bytes written=3114752
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=7
		Map output records=2
		Map output bytes=226
		Map output materialized bytes=236
		Input split bytes=172
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=236
		Reduce input records=2
		Reduce output records=0
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=43
		Total committed heap usage (bytes)=408944640
	Generator
		SCHEDULE_REJECTED=5
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=1408
	File Output Format Counters 
		Bytes Written=8
2021-12-26 17:50:28,153 INFO  crawl.Generator - Generator: number of items rejected during selection:
2021-12-26 17:50:28,161 INFO  crawl.Generator - Generator:      5  SCHEDULE_REJECTED
2021-12-26 17:50:28,174 INFO  crawl.Generator - Generator: Partitioning selected urls for politeness.
2021-12-26 17:50:29,175 INFO  crawl.Generator - Generator: segment: crawl/segments/20211226175029
2021-12-26 17:50:29,204 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:50:29,790 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:50:29,790 INFO  mapreduce.Job - Running job: job_local1142088793_0002
2021-12-26 17:50:30,140 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:50:30,791 INFO  mapreduce.Job - Job job_local1142088793_0002 running in uber mode : false
2021-12-26 17:50:30,792 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:50:30,797 INFO  mapreduce.Job - Job job_local1142088793_0002 completed successfully
2021-12-26 17:50:30,810 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3788534
		FILE: Number of bytes written=6225780
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=2
		Map output bytes=328
		Map output materialized bytes=338
		Input split bytes=209
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=338
		Reduce input records=2
		Reduce output records=2
		Spilled Records=4
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=12
		Total committed heap usage (bytes)=413138944
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=362
	File Output Format Counters 
		Bytes Written=324
2021-12-26 17:50:30,837 INFO  crawl.Generator - Generator: finished at 2021-12-26 17:50:30, elapsed: 00:00:08
2021-12-26 17:50:51,818 INFO  fetcher.Fetcher - Fetcher: starting at 2021-12-26 17:50:51
2021-12-26 17:50:51,819 INFO  fetcher.Fetcher - Fetcher: segment: crawl/segments/20211226175029
2021-12-26 17:50:52,387 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:50:53,061 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:50:55,750 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:50:55,751 INFO  mapreduce.Job - Running job: job_local98974347_0001
2021-12-26 17:50:56,436 INFO  fetcher.FetchItemQueues - Using queue mode : byHost
2021-12-26 17:50:56,438 INFO  fetcher.Fetcher - Fetcher: threads: 10
2021-12-26 17:50:56,571 INFO  fetcher.Fetcher - Fetcher: time-out divisor: 2
2021-12-26 17:50:56,623 INFO  fetcher.QueueFeeder - QueueFeeder finished: total 2 records
2021-12-26 17:50:56,624 INFO  fetcher.QueueFeeder - QueueFeeder queuing status:
2021-12-26 17:50:56,624 INFO  fetcher.QueueFeeder - 	2	SUCCESSFULLY_QUEUED
2021-12-26 17:50:56,624 INFO  fetcher.QueueFeeder - 	0	ERROR_CREATE_FETCH_ITEM
2021-12-26 17:50:56,626 INFO  fetcher.QueueFeeder - 	0	ABOVE_EXCEPTION_THRESHOLD
2021-12-26 17:50:56,628 INFO  fetcher.QueueFeeder - 	0	HIT_BY_TIMELIMIT
2021-12-26 17:50:56,768 INFO  mapreduce.Job - Job job_local98974347_0001 running in uber mode : false
2021-12-26 17:50:56,770 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:50:57,389 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,470 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,489 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,491 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,501 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,503 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,515 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,516 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,523 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,524 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,529 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:57,538 INFO  fetcher.FetcherThread - FetcherThread 52 fetching http://192.168.240.25:5501/food.html (queue crawl delay=5000ms)
2021-12-26 17:50:57,539 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:57,548 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:58,150 INFO  http.Http - http.proxy.host = null
2021-12-26 17:50:58,150 INFO  http.Http - http.proxy.port = 8080
2021-12-26 17:50:58,150 INFO  http.Http - http.proxy.exception.list = false
2021-12-26 17:50:58,150 INFO  http.Http - http.timeout = 10000
2021-12-26 17:50:58,150 INFO  http.Http - http.content.limit = 1048576
2021-12-26 17:50:58,150 INFO  http.Http - http.agent = Nutch Crawler/Nutch-1.18
2021-12-26 17:50:58,151 INFO  http.Http - http.accept.language = en-us,en-gb,en;q=0.7,*;q=0.3
2021-12-26 17:50:58,151 INFO  http.Http - http.accept = text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8
2021-12-26 17:50:58,151 INFO  http.Http - http.enable.cookie.header = true
2021-12-26 17:50:58,152 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:58,159 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:58,169 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:58,193 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:58,196 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:58,202 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:50:58,202 INFO  fetcher.FetcherThread - FetcherThread 43 Using queue mode : byHost
2021-12-26 17:50:58,215 INFO  fetcher.Fetcher - Fetcher: throughput threshold: -1
2021-12-26 17:50:58,215 INFO  fetcher.Fetcher - Fetcher: throughput threshold retries: 5
2021-12-26 17:50:59,218 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521263682
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   now           = 1640521259218
2021-12-26 17:50:59,218 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json
2021-12-26 17:51:00,219 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521263682
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   now           = 1640521260220
2021-12-26 17:51:00,220 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json
2021-12-26 17:51:01,221 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521263682
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   now           = 1640521261222
2021-12-26 17:51:01,222 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json
2021-12-26 17:51:02,223 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521263682
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   now           = 1640521262223
2021-12-26 17:51:02,223 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json
2021-12-26 17:51:03,224 INFO  fetcher.Fetcher - -activeThreads=10, spinWaiting=10, fetchQueues.totalSize=1, fetchQueues.getQueueCount=1
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueues - * queue: 192.168.240.25
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   maxThreads    = 1
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   inProgress    = 0
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   crawlDelay    = 5000
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   minCrawlDelay = 0
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   nextFetchTime = 1640521263682
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   now           = 1640521263224
2021-12-26 17:51:03,224 INFO  fetcher.FetchItemQueue -   0. http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json
2021-12-26 17:51:03,710 INFO  fetcher.FetcherThread - FetcherThread 52 fetching http://192.168.240.25:5501/reactui/public/%25PUBLIC_URL%25/manifest.json (queue crawl delay=5000ms)
2021-12-26 17:51:03,718 INFO  fetcher.FetcherThread - FetcherThread 56 has no more work available
2021-12-26 17:51:03,719 INFO  fetcher.FetcherThread - FetcherThread 56 -finishing thread FetcherThread, activeThreads=9
2021-12-26 17:51:03,719 INFO  fetcher.FetcherThread - FetcherThread 57 has no more work available
2021-12-26 17:51:03,720 INFO  fetcher.FetcherThread - FetcherThread 57 -finishing thread FetcherThread, activeThreads=8
2021-12-26 17:51:03,718 INFO  fetcher.FetcherThread - FetcherThread 58 has no more work available
2021-12-26 17:51:03,720 INFO  fetcher.FetcherThread - FetcherThread 58 -finishing thread FetcherThread, activeThreads=7
2021-12-26 17:51:03,755 INFO  fetcher.FetcherThread - FetcherThread 52 has no more work available
2021-12-26 17:51:03,755 INFO  fetcher.FetcherThread - FetcherThread 52 -finishing thread FetcherThread, activeThreads=6
2021-12-26 17:51:04,041 INFO  fetcher.FetcherThread - FetcherThread 49 has no more work available
2021-12-26 17:51:04,041 INFO  fetcher.FetcherThread - FetcherThread 49 -finishing thread FetcherThread, activeThreads=5
2021-12-26 17:51:04,041 INFO  fetcher.FetcherThread - FetcherThread 50 has no more work available
2021-12-26 17:51:04,042 INFO  fetcher.FetcherThread - FetcherThread 50 -finishing thread FetcherThread, activeThreads=4
2021-12-26 17:51:04,043 INFO  fetcher.FetcherThread - FetcherThread 51 has no more work available
2021-12-26 17:51:04,043 INFO  fetcher.FetcherThread - FetcherThread 51 -finishing thread FetcherThread, activeThreads=3
2021-12-26 17:51:04,047 INFO  fetcher.FetcherThread - FetcherThread 53 has no more work available
2021-12-26 17:51:04,047 INFO  fetcher.FetcherThread - FetcherThread 53 -finishing thread FetcherThread, activeThreads=2
2021-12-26 17:51:04,053 INFO  fetcher.FetcherThread - FetcherThread 54 has no more work available
2021-12-26 17:51:04,054 INFO  fetcher.FetcherThread - FetcherThread 54 -finishing thread FetcherThread, activeThreads=1
2021-12-26 17:51:04,176 INFO  fetcher.FetcherThread - FetcherThread 55 has no more work available
2021-12-26 17:51:04,176 INFO  fetcher.FetcherThread - FetcherThread 55 -finishing thread FetcherThread, activeThreads=0
2021-12-26 17:51:04,225 INFO  fetcher.Fetcher - -activeThreads=0, spinWaiting=0, fetchQueues.totalSize=0, fetchQueues.getQueueCount=0
2021-12-26 17:51:04,225 INFO  fetcher.Fetcher - -activeThreads=0
2021-12-26 17:51:04,389 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:51:04,780 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:51:05,782 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:51:05,783 INFO  mapreduce.Job - Job job_local98974347_0001 completed successfully
2021-12-26 17:51:05,816 INFO  mapreduce.Job - Counters: 33
	File System Counters
		FILE: Number of bytes read=1917774
		FILE: Number of bytes written=3134660
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=2
		Map output records=3
		Map output bytes=12722
		Map output materialized bytes=12738
		Input split bytes=190
		Combine input records=0
		Combine output records=0
		Reduce input groups=2
		Reduce shuffle bytes=12738
		Reduce input records=3
		Reduce output records=3
		Spilled Records=6
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=55
		Total committed heap usage (bytes)=279969792
	FetcherStatus
		bytes_downloaded=11628
		notfound=1
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=324
	File Output Format Counters 
		Bytes Written=5008
2021-12-26 17:51:05,816 INFO  fetcher.Fetcher - Fetcher: finished at 2021-12-26 17:51:05, elapsed: 00:00:14
2021-12-26 17:51:13,934 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:51:14,808 INFO  parse.ParseSegment - ParseSegment: starting at 2021-12-26 17:51:14
2021-12-26 17:51:14,808 INFO  parse.ParseSegment - ParseSegment: segment: crawl/segments/20211226175029
2021-12-26 17:51:15,050 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:51:17,400 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:51:17,401 INFO  mapreduce.Job - Running job: job_local1383967332_0001
2021-12-26 17:51:18,447 INFO  mapreduce.Job - Job job_local1383967332_0001 running in uber mode : false
2021-12-26 17:51:18,449 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:51:19,250 INFO  crawl.SignatureFactory - Using Signature impl: org.apache.nutch.crawl.MD5Signature
2021-12-26 17:51:19,271 INFO  parse.ParseSegment - Parsed (509ms): http://192.168.240.25:5501/food.html
2021-12-26 17:51:19,629 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:51:20,091 INFO  net.URLExemptionFilters - Found 0 extensions at point:'org.apache.nutch.net.URLExemptionFilter'
2021-12-26 17:51:20,460 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:51:20,474 INFO  regex.RegexURLNormalizer - can't find rules for scope 'outlink', using default
2021-12-26 17:51:21,461 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:51:21,462 INFO  mapreduce.Job - Job job_local1383967332_0001 completed successfully
2021-12-26 17:51:21,501 INFO  mapreduce.Job - Counters: 31
	File System Counters
		FILE: Number of bytes read=1906076
		FILE: Number of bytes written=3118298
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=1
		Map output records=1
		Map output bytes=3284
		Map output materialized bytes=3294
		Input split bytes=188
		Combine input records=0
		Combine output records=0
		Reduce input groups=1
		Reduce shuffle bytes=3294
		Reduce input records=1
		Reduce output records=1
		Spilled Records=2
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=24
		Total committed heap usage (bytes)=497025024
	ParserStatus
		success=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3911
	File Output Format Counters 
		Bytes Written=0
2021-12-26 17:51:21,527 INFO  parse.ParseSegment - ParseSegment: finished at 2021-12-26 17:51:21, elapsed: 00:00:06
2021-12-26 17:51:31,558 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:51:32,537 INFO  crawl.CrawlDb - CrawlDb update: starting at 2021-12-26 17:51:32
2021-12-26 17:51:32,538 INFO  crawl.CrawlDb - CrawlDb update: db: crawl/crawldb
2021-12-26 17:51:32,538 INFO  crawl.CrawlDb - CrawlDb update: segments: [crawl/segments/20211226175029]
2021-12-26 17:51:32,538 INFO  crawl.CrawlDb - CrawlDb update: additions allowed: true
2021-12-26 17:51:32,539 INFO  crawl.CrawlDb - CrawlDb update: URL normalizing: false
2021-12-26 17:51:32,539 INFO  crawl.CrawlDb - CrawlDb update: URL filtering: false
2021-12-26 17:51:32,539 INFO  crawl.CrawlDb - CrawlDb update: 404 purging: false
2021-12-26 17:51:32,545 INFO  crawl.CrawlDb - CrawlDb update: Merging segment data into db.
2021-12-26 17:51:32,766 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:51:35,902 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:51:35,903 INFO  mapreduce.Job - Running job: job_local2036599627_0001
2021-12-26 17:51:36,942 INFO  mapreduce.Job - Job job_local2036599627_0001 running in uber mode : false
2021-12-26 17:51:36,948 INFO  mapreduce.Job -  map 33% reduce 0%
2021-12-26 17:51:37,248 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:51:37,953 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:51:38,541 INFO  crawl.FetchScheduleFactory - Using FetchSchedule impl: org.apache.nutch.crawl.DefaultFetchSchedule
2021-12-26 17:51:38,544 INFO  crawl.AbstractFetchSchedule - defaultInterval=2592000
2021-12-26 17:51:38,544 INFO  crawl.AbstractFetchSchedule - maxInterval=7776000
2021-12-26 17:51:38,954 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:51:38,955 INFO  mapreduce.Job - Job job_local2036599627_0001 completed successfully
2021-12-26 17:51:38,996 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=3804564
		FILE: Number of bytes written=6226091
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=25
		Map output records=25
		Map output bytes=2834
		Map output materialized bytes=2909
		Input split bytes=551
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=2909
		Reduce input records=25
		Reduce output records=7
		Spilled Records=50
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=32
		Total committed heap usage (bytes)=835715072
	CrawlDB status
		db_fetched=6
		db_gone=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=3377
	File Output Format Counters 
		Bytes Written=1975
2021-12-26 17:51:39,034 INFO  crawl.CrawlDb - CrawlDb update: finished at 2021-12-26 17:51:39, elapsed: 00:00:06
2021-12-26 17:51:52,359 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:51:53,396 INFO  crawl.LinkDb - LinkDb: starting at 2021-12-26 17:51:53
2021-12-26 17:51:53,397 INFO  crawl.LinkDb - LinkDb: linkdb: crawl/linkdb
2021-12-26 17:51:53,397 INFO  crawl.LinkDb - LinkDb: URL normalize: true
2021-12-26 17:51:53,397 INFO  crawl.LinkDb - LinkDb: URL filter: true
2021-12-26 17:51:53,397 INFO  crawl.LinkDb - LinkDb: internal links will be ignored.
2021-12-26 17:51:53,397 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174351
2021-12-26 17:51:53,403 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226174843
2021-12-26 17:51:53,408 INFO  crawl.LinkDb - LinkDb: adding segment: file:/home/dhinesh/Desktop/barat/projects/searchEngine/search/nutch/crawl/segments/20211226175029
2021-12-26 17:51:53,620 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:51:55,792 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:51:55,793 INFO  mapreduce.Job - Running job: job_local960343234_0001
2021-12-26 17:51:56,806 INFO  mapreduce.Job - Job job_local960343234_0001 running in uber mode : false
2021-12-26 17:51:56,809 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:51:57,327 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2021-12-26 17:51:57,637 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2021-12-26 17:51:57,824 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:51:57,858 INFO  regex.RegexURLNormalizer - can't find rules for scope 'linkdb', using default
2021-12-26 17:51:57,952 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:51:58,825 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:51:58,826 INFO  mapreduce.Job - Job job_local960343234_0001 completed successfully
2021-12-26 17:51:58,859 INFO  mapreduce.Job - Counters: 30
	File System Counters
		FILE: Number of bytes read=3803693
		FILE: Number of bytes written=6205527
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=6
		Map output records=0
		Map output bytes=0
		Map output materialized bytes=18
		Input split bytes=573
		Combine input records=0
		Combine output records=0
		Reduce input groups=0
		Reduce shuffle bytes=18
		Reduce input records=0
		Reduce output records=0
		Spilled Records=0
		Shuffled Maps =3
		Failed Shuffles=0
		Merged Map outputs=3
		GC time elapsed (ms)=53
		Total committed heap usage (bytes)=830472192
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=4549
	File Output Format Counters 
		Bytes Written=279
2021-12-26 17:51:58,874 INFO  crawl.LinkDb - LinkDb: finished at 2021-12-26 17:51:58, elapsed: 00:00:05
2021-12-26 17:52:20,312 WARN  util.NativeCodeLoader - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2021-12-26 17:52:21,491 INFO  segment.SegmentChecker - Segment dir is complete: crawl/segments/20211226175029.
2021-12-26 17:52:21,504 INFO  indexer.IndexingJob - Indexer: starting at 2021-12-26 17:52:21
2021-12-26 17:52:21,555 INFO  indexer.IndexingJob - Indexer: deleting gone documents: true
2021-12-26 17:52:21,559 INFO  indexer.IndexingJob - Indexer: URL filtering: true
2021-12-26 17:52:21,561 INFO  indexer.IndexingJob - Indexer: URL normalizing: true
2021-12-26 17:52:21,563 INFO  indexer.IndexerMapReduce - IndexerMapReduce: crawldb: crawl/crawldb
2021-12-26 17:52:21,589 INFO  indexer.IndexerMapReduce - IndexerMapReduces: adding segment: crawl/segments/20211226175029
2021-12-26 17:52:21,614 INFO  indexer.IndexerMapReduce - IndexerMapReduce: linkdb: crawl/linkdb
2021-12-26 17:52:21,864 WARN  impl.MetricsConfig - Cannot locate configuration: tried hadoop-metrics2-jobtracker.properties,hadoop-metrics2.properties
2021-12-26 17:52:25,049 INFO  mapreduce.Job - The url to track the job: http://localhost:8080/
2021-12-26 17:52:25,050 INFO  mapreduce.Job - Running job: job_local2108901603_0001
2021-12-26 17:52:26,103 INFO  mapreduce.Job - Job job_local2108901603_0001 running in uber mode : false
2021-12-26 17:52:26,108 INFO  mapreduce.Job -  map 0% reduce 0%
2021-12-26 17:52:26,593 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-26 17:52:26,951 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-26 17:52:27,143 INFO  mapreduce.Job -  map 100% reduce 0%
2021-12-26 17:52:27,199 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-26 17:52:27,377 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-26 17:52:27,536 INFO  regex.RegexURLNormalizer - can't find rules for scope 'indexer', using default
2021-12-26 17:52:27,831 WARN  impl.MetricsSystemImpl - JobTracker metrics system already initialized!
2021-12-26 17:52:28,217 INFO  indexer.IndexWriters - Index writer org.apache.nutch.indexwriter.solr.SolrIndexWriter identified.
2021-12-26 17:52:28,736 WARN  exchange.Exchanges - No exchange was configured. The documents will be routed to all index writers.
2021-12-26 17:52:29,824 INFO  indexer.IndexerOutputFormat - Active IndexWriters :
SolrIndexWriter:
┌────────────┬────────────────────────────────────────────────────────────────────────────┬────────────────────────────────┐
│type        │Specifies the SolrClient implementation to use. This is a  string  value  of│http                            │
│            │one of the following "cloud" or "http". The values represent CloudSolrServer│                                │
│            │or HttpSolrServer respectively.                                             │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│url         │Defines the fully qualified URL of Solr into which data should  be  indexed.│http://localhost:8983/solr/nutch│
│            │Multiple URL can be provided using comma as a delimiter. When the  value  of│                                │
│            │type property is cloud, the URL should not include any collections or cores;│                                │
│            │just the root Solr path.                                                    │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│collection  │The collection used in requests. Only used when the value of  type  property│                                │
│            │is cloud.                                                                   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│commitSize  │Defines the number of documents to send to Solr in a  single  update  batch.│1000                            │
│            │Decrease when handling very large documents to prevent  Nutch  from  running│                                │
│            │out of memory. Note: It does not explicitly trigger a server side commit.   │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│weight.field│Field's name where the weight of the documents will be  written.  If  it  is│                                │
│            │empty no field will be used.                                                │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│auth        │Whether to enable HTTP basic authentication for communicating with Solr. Use│false                           │
│            │the username and password properties to configure your credentials.         │                                │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│username    │The username of Solr server.                                                │username                        │
├────────────┼────────────────────────────────────────────────────────────────────────────┼────────────────────────────────┤
│password    │The password of Solr server.                                                │password                        │
└────────────┴────────────────────────────────────────────────────────────────────────────┴────────────────────────────────┘


2021-12-26 17:52:29,886 INFO  anchor.AnchorIndexingFilter - Anchor deduplication is: off
2021-12-26 17:52:30,058 INFO  solr.SolrIndexWriter - Indexing 1/1 documents
2021-12-26 17:52:30,062 INFO  solr.SolrIndexWriter - Deleting 0 documents
2021-12-26 17:52:31,507 INFO  solr.SolrIndexWriter - SolrIndexer: deleting 1/1 documents
2021-12-26 17:52:33,154 INFO  mapreduce.Job -  map 100% reduce 100%
2021-12-26 17:52:33,158 INFO  mapreduce.Job - Job job_local2108901603_0001 completed successfully
2021-12-26 17:52:33,215 INFO  mapreduce.Job - Counters: 32
	File System Counters
		FILE: Number of bytes read=6686136
		FILE: Number of bytes written=10930837
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
	Map-Reduce Framework
		Map input records=27
		Map output records=27
		Map output bytes=5354
		Map output materialized bytes=5457
		Input split bytes=1104
		Combine input records=0
		Combine output records=0
		Reduce input groups=7
		Reduce shuffle bytes=5457
		Reduce input records=27
		Reduce output records=2
		Spilled Records=54
		Shuffled Maps =6
		Failed Shuffles=0
		Merged Map outputs=6
		GC time elapsed (ms)=79
		Total committed heap usage (bytes)=1582301184
	IndexerStatus
		deleted (gone)=1
		indexed (add/update)=1
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters 
		Bytes Read=5348
	File Output Format Counters 
		Bytes Written=0
2021-12-26 17:52:33,216 INFO  indexer.IndexingJob - Indexer: number of documents indexed, deleted, or skipped:
2021-12-26 17:52:33,269 INFO  indexer.IndexingJob - Indexer:      1  deleted (gone)
2021-12-26 17:52:33,269 INFO  indexer.IndexingJob - Indexer:      1  indexed (add/update)
2021-12-26 17:52:33,271 INFO  indexer.IndexingJob - Indexer: finished at 2021-12-26 17:52:33, elapsed: 00:00:11
